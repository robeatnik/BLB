#  tf_scan.py --data_file data_energy --validate_frequency 100 --training_redundance 10 --learning_rate 0.01 --learning_rate_decay 0.9999 --h_range 0.125
# Importing data_energy ...
# 45361 entries between 0.0 and 0.25
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
0.125 100 0.9594 0.408679 3.14767 0.129835 0.1 0.009900493386913728
0.125 200 0.987 0.201943 2.90228 0.0695808 0.1 0.009801976930432239
0.125 300 0.9878 0.164556 2.67128 0.061602 0.1 0.00970444077784252
0.125 400 0.9978 0.146616 2.44392 0.0599921 0.1 0.009607875174472565
0.125 500 0.9968 0.107271 2.23398 0.0480181 0.1 0.009512270462715812
0.125 600 0.9926 0.10478 2.04695 0.0511883 0.1 0.009417617081065264
0.125 700 0.9848 0.112075 1.88667 0.0594032 0.1 0.009323905563157238
0.125 800 0.995 0.100629 1.74954 0.0575176 0.1 0.009231126536824622
0.125 900 0.9988 0.0882178 1.63179 0.0540621 0.1 0.009139270723159591
0.125 1000 0.9982 0.103211 1.53125 0.0674032 0.1 0.009048328935585565
0.125 1100 0.9986 0.10027 1.44861 0.0692184 0.1 0.008958292078938489
0.125 1200 0.9968 0.104207 1.38058 0.0754807 0.1 0.0088691511485572
0.125 1300 0.9978 0.105995 1.3236 0.0800805 0.1 0.008780897229382877
0.125 1400 0.991 0.108532 1.27634 0.0850335 0.1 0.008693521495067419
0.125 1500 0.9962 0.0758706 1.23521 0.0614235 0.1 0.008607015207090722
0.125 1600 0.9912 0.0982692 1.20343 0.0816579 0.1 0.008521369713886751
0.125 1700 0.9986 0.0904622 1.17707 0.0768537 0.1 0.008436576449978266
0.125 1800 0.9942 0.0707888 1.15522 0.0612771 0.1 0.008352626935120183
0.125 1900 0.9988 0.105222 1.13382 0.092803 0.1 0.008269512773451476
0.125 2000 0.9988 0.113565 1.11852 0.101532 0.1 0.008187225652655481
0.125 2100 0.989 0.0910108 1.10722 0.0821978 0.1 0.008105757343128598
0.125 2200 0.991 0.0980791 1.09699 0.0894077 0.1 0.008025099697157206
0.125 2300 0.9924 0.0980434 1.08801 0.0901124 0.1 0.007945244648102822
0.125 2400 0.9882 0.077083 1.08003 0.0713714 0.1 0.007866184209595362
0.125 2500 0.991 0.0966068 1.07424 0.0899305 0.1 0.007787910474734398
0.125 2600 0.9972 0.112107 1.07025 0.104749 0.1 0.007710415615298401
0.125 2700 0.991 0.110127 1.06718 0.103194 0.1 0.0076336918809618085
0.125 2800 0.999 0.0848879 1.06064 0.0800347 0.1 0.007557731598519933
0.125 2900 1.0 0.0961777 1.05791 0.0909128 0.1 0.007482527171121546
0.125 3000 0.9966 0.0859708 1.05691 0.0813419 0.1 0.007408071077509108
0.125 3100 0.9894 0.0986436 1.05535 0.0934697 0.1 0.0073343558712665735
0.125 3200 0.9976 0.0986654 1.05327 0.0936752 0.1 0.007261374180074655
0.125 3300 0.9924 0.107987 1.05095 0.102752 0.1 0.007189118704973517
0.125 3400 0.9934 0.0923106 1.04928 0.0879753 0.1 0.007117582219632801
0.125 3500 0.9984 0.120636 1.04982 0.114911 0.1 0.007046757569628924
0.125 3600 0.9964 0.129478 1.0499 0.123324 0.1 0.00697663767172953
0.125 3700 0.9954 0.0876326 1.0467 0.0837228 0.1 0.006907215513185129
0.125 3800 0.9982 0.0758147 1.04563 0.0725063 0.1 0.00683848415102772
0.125 3900 0.9976 0.078284 1.04659 0.0747994 0.1 0.006770436711376421
0.125 4000 0.9988 0.103409 1.04667 0.098798 0.1 0.006703066388750011
0.125 4100 0.991 0.113398 1.04551 0.108462 0.1 0.006636366445386311
0.125 4200 0.9988 0.112984 1.04406 0.108216 0.1 0.006570330210568327
0.125 4300 0.9976 0.0643239 1.04409 0.0616074 0.1 0.006504951079957117
0.125 4400 0.9976 0.104111 1.04505 0.0996229 0.1 0.006440222514931274
0.125 4500 0.9976 0.0992845 1.04561 0.0949534 0.1 0.006376138041932989
# Train result: 0.125 0.992097
# Test result: 0.125 0.9936
# 45361 entries between 0.03125 and 0.28125
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
0.15625 100 0.9542 0.495015 3.11277 0.159027 0.1 0.009900493386913728
0.15625 200 0.9764 0.266746 2.86483 0.0931109 0.1 0.009801976930432239
0.15625 300 0.9786 0.171612 2.66074 0.0644976 0.1 0.00970444077784252
0.15625 400 0.9826 0.150558 2.4551 0.0613246 0.1 0.009607875174472565
0.15625 500 0.9966 0.140499 2.26184 0.0621171 0.1 0.009512270462715812
0.15625 600 0.9954 0.113629 2.08685 0.0544501 0.1 0.009417617081065264
0.15625 700 0.9962 0.122689 1.93587 0.0633764 0.1 0.009323905563157238
0.15625 800 0.999 0.132782 1.80402 0.0736034 0.1 0.009231126536824622
0.15625 900 0.9954 0.114062 1.69057 0.0674696 0.1 0.009139270723159591
0.15625 1000 0.9974 0.120246 1.59337 0.0754666 0.1 0.009048328935585565
0.15625 1100 0.9894 0.0928148 1.51473 0.0612748 0.1 0.008958292078938489
0.15625 1200 0.9964 0.0793158 1.448 0.054776 0.1 0.0088691511485572
0.15625 1300 0.984 0.12649 1.39058 0.0909622 0.1 0.008780897229382877
0.15625 1400 0.9984 0.092234 1.3429 0.0686825 0.1 0.008693521495067419
0.15625 1500 0.9936 0.0880636 1.3027 0.0676008 0.1 0.008607015207090722
0.15625 1600 0.9976 0.123317 1.27083 0.0970365 0.1 0.008521369713886751
0.15625 1700 0.994 0.129374 1.24435 0.103969 0.1 0.008436576449978266
0.15625 1800 0.9936 0.118563 1.221 0.0971032 0.1 0.008352626935120183
0.15625 1900 0.9814 0.097675 1.20229 0.081241 0.1 0.008269512773451476
0.15625 2000 0.991 0.119244 1.18715 0.100446 0.1 0.008187225652655481
0.15625 2100 0.9856 0.120651 1.17582 0.10261 0.1 0.008105757343128598
0.15625 2200 0.9922 0.113076 1.16427 0.0971213 0.1 0.008025099697157206
0.15625 2300 0.993 0.125103 1.15543 0.108274 0.1 0.007945244648102822
0.15625 2400 0.9936 0.0999365 1.14666 0.0871546 0.1 0.007866184209595362
0.15625 2500 0.998 0.0994344 1.14127 0.0871262 0.1 0.007787910474734398
0.15625 2600 0.9898 0.0751098 1.1369 0.0660654 0.1 0.007710415615298401
0.15625 2700 0.9972 0.103789 1.13108 0.0917617 0.1 0.0076336918809618085
0.15625 2800 0.9968 0.116877 1.12762 0.103649 0.1 0.007557731598519933
0.15625 2900 0.9966 0.0947207 1.12462 0.0842246 0.1 0.007482527171121546
0.15625 3000 0.9982 0.103131 1.124 0.091753 0.1 0.007408071077509108
0.15625 3100 0.9898 0.0811625 1.12114 0.0723926 0.1 0.0073343558712665735
0.15625 3200 0.9964 0.127061 1.11868 0.11358 0.1 0.007261374180074655
0.15625 3300 0.992 0.0983605 1.11701 0.0880566 0.1 0.007189118704973517
0.15625 3400 0.9884 0.11039 1.1161 0.0989067 0.1 0.007117582219632801
0.15625 3500 0.9998 0.067546 1.11459 0.0606016 0.1 0.007046757569628924
0.15625 3600 0.9904 0.0792365 1.11278 0.071206 0.1 0.00697663767172953
0.15625 3700 0.9942 0.121003 1.11288 0.10873 0.1 0.006907215513185129
0.15625 3800 0.9974 0.0914602 1.1114 0.0822926 0.1 0.00683848415102772
0.15625 3900 0.9976 0.127256 1.11243 0.114395 0.1 0.006770436711376421
0.15625 4000 0.993 0.131565 1.11155 0.118361 0.1 0.006703066388750011
0.15625 4100 0.9994 0.0854991 1.11025 0.077009 0.1 0.006636366445386311
0.15625 4200 0.9998 0.115509 1.10992 0.104069 0.1 0.006570330210568327
0.15625 4300 0.986 0.0983971 1.1102 0.0886299 0.1 0.006504951079957117
0.15625 4400 0.9948 0.121297 1.10954 0.109322 0.1 0.006440222514931274
0.15625 4500 0.9936 0.0865964 1.10838 0.0781291 0.1 0.006376138041932989
# Train result: 0.15625 0.996512
# Test result: 0.15625 0.9965
# 45361 entries between 0.0625 and 0.3125
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
0.1875 100 0.9346 0.560743 3.05683 0.183439 0.1 0.009900493386913728
0.1875 200 0.9638 0.344491 2.77567 0.124111 0.1 0.009801976930432239
0.1875 300 0.982 0.217585 2.60525 0.083518 0.1 0.00970444077784252
0.1875 400 0.9826 0.179351 2.43999 0.0735048 0.1 0.009607875174472565
0.1875 500 0.9988 0.13712 2.27465 0.0602816 0.1 0.009512270462715812
0.1875 600 0.9842 0.145336 2.12444 0.0684113 0.1 0.009417617081065264
0.1875 700 0.9906 0.128879 1.9887 0.0648059 0.1 0.009323905563157238
0.1875 800 0.9892 0.11463 1.86753 0.0613805 0.1 0.009231126536824622
0.1875 900 0.9864 0.130973 1.76085 0.0743805 0.1 0.009139270723159591
0.1875 1000 0.9952 0.121155 1.67069 0.0725182 0.1 0.009048328935585565
0.1875 1100 0.9928 0.107014 1.59548 0.067073 0.1 0.008958292078938489
0.1875 1200 0.9992 0.142281 1.53261 0.0928357 0.1 0.0088691511485572
0.1875 1300 0.9912 0.111037 1.47743 0.0751552 0.1 0.008780897229382877
0.1875 1400 0.9896 0.117856 1.42934 0.0824544 0.1 0.008693521495067419
0.1875 1500 0.9906 0.0974364 1.39194 0.0700004 0.1 0.008607015207090722
0.1875 1600 0.993 0.124081 1.36196 0.0911048 0.1 0.008521369713886751
0.1875 1700 0.987 0.117571 1.33484 0.0880784 0.1 0.008436576449978266
0.1875 1800 1.0 0.113371 1.31132 0.0864554 0.1 0.008352626935120183
0.1875 1900 0.9914 0.104277 1.29243 0.0806829 0.1 0.008269512773451476
0.1875 2000 0.9994 0.120236 1.27802 0.0940801 0.1 0.008187225652655481
0.1875 2100 0.9946 0.0942955 1.26731 0.0744058 0.1 0.008105757343128598
0.1875 2200 0.9914 0.0917163 1.25596 0.0730251 0.1 0.008025099697157206
0.1875 2300 0.9826 0.0987175 1.24464 0.0793141 0.1 0.007945244648102822
0.1875 2400 0.9992 0.115247 1.23753 0.0931273 0.1 0.007866184209595362
0.1875 2500 0.9882 0.105207 1.23365 0.0852815 0.1 0.007787910474734398
0.1875 2600 0.987 0.0970051 1.22749 0.079027 0.1 0.007710415615298401
0.1875 2700 0.9926 0.0937387 1.22241 0.0766837 0.1 0.0076336918809618085
0.1875 2800 0.9872 0.109386 1.21766 0.0898327 0.1 0.007557731598519933
0.1875 2900 0.9968 0.115805 1.21557 0.0952681 0.1 0.007482527171121546
0.1875 3000 0.9898 0.121126 1.21495 0.0996959 0.1 0.007408071077509108
0.1875 3100 0.992 0.103647 1.21263 0.0854735 0.1 0.0073343558712665735
0.1875 3200 0.9956 0.106116 1.20768 0.087867 0.1 0.007261374180074655
0.1875 3300 0.9914 0.110608 1.20638 0.0916859 0.1 0.007189118704973517
0.1875 3400 0.9906 0.0904578 1.20712 0.0749371 0.1 0.007117582219632801
0.1875 3500 0.99 0.0930495 1.20488 0.0772273 0.1 0.007046757569628924
0.1875 3600 0.9894 0.112442 1.20359 0.0934221 0.1 0.00697663767172953
0.1875 3700 0.986 0.0976134 1.20098 0.0812784 0.1 0.006907215513185129
0.1875 3800 0.9862 0.0996306 1.20228 0.0828682 0.1 0.00683848415102772
0.1875 3900 0.9936 0.109951 1.20231 0.0914501 0.1 0.006770436711376421
0.1875 4000 0.9926 0.120737 1.20214 0.100435 0.1 0.006703066388750011
0.1875 4100 0.997 0.128126 1.19873 0.106885 0.1 0.006636366445386311
0.1875 4200 0.997 0.120299 1.19775 0.100438 0.1 0.006570330210568327
0.1875 4300 0.9904 0.114686 1.20041 0.0955387 0.1 0.006504951079957117
0.1875 4400 0.9898 0.125301 1.19882 0.10452 0.1 0.006440222514931274
0.1875 4500 0.9848 0.0961411 1.19813 0.0802426 0.1 0.006376138041932989
# Train result: 0.1875 0.987196
# Test result: 0.1875 0.9871
# 45361 entries between 0.09375 and 0.34375
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
0.21875 100 0.9316 0.618366 3.02936 0.204124 0.1 0.009900493386913728
0.21875 200 0.942 0.437302 2.68443 0.162903 0.1 0.009801976930432239
0.21875 300 0.975 0.290273 2.52628 0.114902 0.1 0.00970444077784252
0.21875 400 0.9758 0.240195 2.40165 0.100013 0.1 0.009607875174472565
0.21875 500 0.971 0.1636 2.27904 0.0717849 0.1 0.009512270462715812
0.21875 600 0.9958 0.167717 2.15544 0.0778114 0.1 0.009417617081065264
0.21875 700 0.9786 0.152064 2.04129 0.0744943 0.1 0.009323905563157238
0.21875 800 0.9738 0.14265 1.93693 0.0736475 0.1 0.009231126536824622
0.21875 900 0.978 0.139766 1.8453 0.0757419 0.1 0.009139270723159591
0.21875 1000 0.9842 0.123223 1.7645 0.0698345 0.1 0.009048328935585565
0.21875 1100 0.9798 0.132315 1.69345 0.0781336 0.1 0.008958292078938489
0.21875 1200 0.9802 0.121044 1.63211 0.0741639 0.1 0.0088691511485572
0.21875 1300 0.9942 0.136154 1.58166 0.0860827 0.1 0.008780897229382877
0.21875 1400 0.998 0.129033 1.54116 0.0837244 0.1 0.008693521495067419
0.21875 1500 0.9764 0.114639 1.50311 0.0762678 0.1 0.008607015207090722
0.21875 1600 0.9832 0.133755 1.47306 0.0908008 0.1 0.008521369713886751
0.21875 1700 0.9984 0.133645 1.4468 0.0923729 0.1 0.008436576449978266
0.21875 1800 0.9804 0.117755 1.42733 0.0825006 0.1 0.008352626935120183
0.21875 1900 0.9886 0.126599 1.41031 0.0897664 0.1 0.008269512773451476
0.21875 2000 0.9924 0.113167 1.3939 0.0811872 0.1 0.008187225652655481
0.21875 2100 0.9652 0.0998379 1.38147 0.0722695 0.1 0.008105757343128598
0.21875 2200 0.9778 0.130161 1.37127 0.0949197 0.1 0.008025099697157206
0.21875 2300 0.9866 0.128109 1.3649 0.0938597 0.1 0.007945244648102822
0.21875 2400 0.9824 0.129485 1.35572 0.09551 0.1 0.007866184209595362
0.21875 2500 0.993 0.104969 1.35019 0.077744 0.1 0.007787910474734398
0.21875 2600 0.966 0.137271 1.34513 0.10205 0.1 0.007710415615298401
0.21875 2700 0.9804 0.132063 1.34151 0.0984438 0.1 0.0076336918809618085
0.21875 2800 0.9908 0.132745 1.33878 0.0991543 0.1 0.007557731598519933
0.21875 2900 0.9654 0.104477 1.33519 0.0782489 0.1 0.007482527171121546
0.21875 3000 0.9796 0.126809 1.33135 0.0952486 0.1 0.007408071077509108
0.21875 3100 0.9802 0.112963 1.32982 0.0849462 0.1 0.0073343558712665735
0.21875 3200 0.9842 0.0970242 1.32919 0.0729951 0.1 0.007261374180074655
0.21875 3300 0.9866 0.132537 1.32715 0.099866 0.1 0.007189118704973517
0.21875 3400 0.9822 0.124524 1.32592 0.0939151 0.1 0.007117582219632801
0.21875 3500 0.9676 0.119489 1.32364 0.0902727 0.1 0.007046757569628924
0.21875 3600 0.99 0.128481 1.32276 0.0971307 0.1 0.00697663767172953
0.21875 3700 0.9954 0.116015 1.32373 0.0876423 0.1 0.006907215513185129
0.21875 3800 0.993 0.129828 1.3216 0.0982356 0.1 0.00683848415102772
0.21875 3900 0.9878 0.156625 1.31956 0.118695 0.1 0.006770436711376421
0.21875 4000 0.9802 0.106756 1.32008 0.0808707 0.1 0.006703066388750011
0.21875 4100 0.9756 0.0967985 1.32068 0.0732943 0.1 0.006636366445386311
0.21875 4200 0.9986 0.121471 1.31942 0.0920638 0.1 0.006570330210568327
0.21875 4300 0.9854 0.105155 1.31895 0.0797269 0.1 0.006504951079957117
0.21875 4400 0.9952 0.116748 1.3179 0.088586 0.1 0.006440222514931274
0.21875 4500 0.996 0.108794 1.31737 0.0825842 0.1 0.006376138041932989
# Train result: 0.21875 0.9983
# Test result: 0.21875 0.9981
# 45361 entries between 0.125 and 0.375
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
0.25 100 0.752 0.641375 3.00478 0.213451 0.1 0.009900493386913728
0.25 200 0.9044 0.517582 2.5938 0.199546 0.1 0.009801976930432239
0.25 300 0.918 0.381136 2.40252 0.15864 0.1 0.00970444077784252
0.25 400 0.9708 0.333859 2.30631 0.144759 0.1 0.009607875174472565
0.25 500 0.9526 0.245188 2.22393 0.11025 0.1 0.009512270462715812
0.25 600 0.9768 0.201534 2.14465 0.0939703 0.1 0.009417617081065264
0.25 700 0.9638 0.160657 2.06371 0.0778488 0.1 0.009323905563157238
0.25 800 0.9742 0.181352 1.98475 0.0913729 0.1 0.009231126536824622
0.25 900 0.9598 0.192159 1.91591 0.100297 0.1 0.009139270723159591
0.25 1000 0.9698 0.169467 1.84972 0.0916177 0.1 0.009048328935585565
0.25 1100 0.9796 0.16212 1.79327 0.0904046 0.1 0.008958292078938489
0.25 1200 0.9782 0.160238 1.74211 0.0919791 0.1 0.0088691511485572
0.25 1300 0.9858 0.143092 1.69835 0.0842536 0.1 0.008780897229382877
0.25 1400 0.9704 0.160203 1.65878 0.0965785 0.1 0.008693521495067419
0.25 1500 0.9956 0.158307 1.62989 0.0971272 0.1 0.008607015207090722
0.25 1600 0.9892 0.160921 1.60273 0.100404 0.1 0.008521369713886751
0.25 1700 0.9626 0.115698 1.57839 0.0733008 0.1 0.008436576449978266
0.25 1800 0.9808 0.121527 1.56171 0.0778169 0.1 0.008352626935120183
0.25 1900 0.975 0.143202 1.54422 0.092734 0.1 0.008269512773451476
0.25 2000 0.9744 0.146511 1.53187 0.0956422 0.1 0.008187225652655481
0.25 2100 0.9914 0.140739 1.51953 0.0926197 0.1 0.008105757343128598
0.25 2200 0.9678 0.167246 1.51012 0.11075 0.1 0.008025099697157206
0.25 2300 0.9768 0.120772 1.49984 0.080523 0.1 0.007945244648102822
0.25 2400 0.9744 0.142924 1.49599 0.0955378 0.1 0.007866184209595362
0.25 2500 0.9812 0.139145 1.49021 0.0933727 0.1 0.007787910474734398
0.25 2600 0.9798 0.172334 1.4843 0.116104 0.1 0.007710415615298401
0.25 2700 0.983 0.153747 1.48314 0.103663 0.1 0.0076336918809618085
0.25 2800 0.9682 0.110989 1.47814 0.0750871 0.1 0.007557731598519933
0.25 2900 0.9904 0.162801 1.4765 0.110262 0.1 0.007482527171121546
0.25 3000 0.9996 0.146319 1.4729 0.0993409 0.1 0.007408071077509108
0.25 3100 0.989 0.148967 1.47046 0.101307 0.1 0.0073343558712665735
0.25 3200 0.9768 0.136183 1.46722 0.0928166 0.1 0.007261374180074655
0.25 3300 0.994 0.170035 1.46776 0.115846 0.1 0.007189118704973517
0.25 3400 0.9778 0.117294 1.46616 0.0800003 0.1 0.007117582219632801
0.25 3500 0.973 0.127778 1.46435 0.0872596 0.1 0.007046757569628924
0.25 3600 0.9856 0.124584 1.46609 0.0849767 0.1 0.00697663767172953
0.25 3700 0.9842 0.144844 1.4638 0.0989506 0.1 0.006907215513185129
0.25 3800 0.9974 0.160418 1.46377 0.109593 0.1 0.00683848415102772
0.25 3900 0.9738 0.137401 1.46238 0.0939573 0.1 0.006770436711376421
0.25 4000 0.9916 0.132977 1.46086 0.0910265 0.1 0.006703066388750011
0.25 4100 0.9678 0.136776 1.45999 0.0936831 0.1 0.006636366445386311
0.25 4200 0.9858 0.152253 1.46101 0.104211 0.1 0.006570330210568327
0.25 4300 0.9844 0.163525 1.46063 0.111955 0.1 0.006504951079957117
0.25 4400 0.9942 0.201504 1.45895 0.138116 0.1 0.006440222514931274
0.25 4500 0.9654 0.183819 1.46079 0.125835 0.1 0.006376138041932989
# Train result: 0.25 0.965717
# Test result: 0.25 0.9675
# 45361 entries between 0.15625 and 0.40625
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
0.28125 100 0.6552 0.668827 3.00243 0.222762 0.1 0.009900493386913728
0.28125 200 0.9644 0.616953 2.52421 0.244414 0.1 0.009801976930432239
0.28125 300 0.8974 0.5296 2.23615 0.236836 0.1 0.00970444077784252
0.28125 400 0.9452 0.392177 2.108 0.186042 0.1 0.009607875174472565
0.28125 500 0.944 0.365348 2.06372 0.177034 0.1 0.009512270462715812
0.28125 600 0.993 0.282243 2.03948 0.13839 0.1 0.009417617081065264
0.28125 700 0.9596 0.251885 2.01259 0.125154 0.1 0.009323905563157238
0.28125 800 0.9776 0.251753 1.98567 0.126784 0.1 0.009231126536824622
0.28125 900 0.9712 0.211304 1.95478 0.108096 0.1 0.009139270723159591
0.28125 1000 0.963 0.199788 1.92237 0.103928 0.1 0.009048328935585565
0.28125 1100 0.97 0.169234 1.88605 0.0897293 0.1 0.008958292078938489
0.28125 1200 0.9454 0.143039 1.85382 0.0771589 0.1 0.0088691511485572
0.28125 1300 0.9306 0.168098 1.8294 0.0918867 0.1 0.008780897229382877
0.28125 1400 0.9406 0.192834 1.803 0.106952 0.1 0.008693521495067419
0.28125 1500 0.9854 0.175621 1.77974 0.0986779 0.1 0.008607015207090722
0.28125 1600 0.979 0.1667 1.75535 0.0949669 0.1 0.008521369713886751
0.28125 1700 0.9592 0.163185 1.74124 0.0937179 0.1 0.008436576449978266
0.28125 1800 0.953 0.177167 1.72798 0.102529 0.1 0.008352626935120183
0.28125 1900 0.9972 0.195869 1.71525 0.114193 0.1 0.008269512773451476
0.28125 2000 0.9918 0.1867 1.70144 0.109731 0.1 0.008187225652655481
0.28125 2100 0.9552 0.170213 1.69135 0.100637 0.1 0.008105757343128598
0.28125 2200 0.9452 0.153352 1.68837 0.0908281 0.1 0.008025099697157206
0.28125 2300 0.9506 0.157338 1.68181 0.0935526 0.1 0.007945244648102822
0.28125 2400 0.9644 0.173369 1.67638 0.103419 0.1 0.007866184209595362
0.28125 2500 0.9644 0.147206 1.66699 0.0883068 0.1 0.007787910474734398
0.28125 2600 0.98 0.192018 1.6665 0.115222 0.1 0.007710415615298401
0.28125 2700 0.9966 0.151917 1.66435 0.0912767 0.1 0.0076336918809618085
0.28125 2800 0.9814 0.160377 1.66286 0.0964462 0.1 0.007557731598519933
0.28125 2900 0.9982 0.147183 1.65755 0.0887953 0.1 0.007482527171121546
0.28125 3000 0.9276 0.163429 1.65554 0.0987169 0.1 0.007408071077509108
0.28125 3100 0.9918 0.158146 1.65733 0.0954226 0.1 0.0073343558712665735
0.28125 3200 0.9276 0.180628 1.65634 0.109053 0.1 0.007261374180074655
0.28125 3300 0.9994 0.19349 1.65473 0.116931 0.1 0.007189118704973517
0.28125 3400 0.9702 0.144711 1.6495 0.0877303 0.1 0.007117582219632801
0.28125 3500 0.9656 0.159295 1.6517 0.0964431 0.1 0.007046757569628924
0.28125 3600 0.9656 0.140739 1.65224 0.0851811 0.1 0.00697663767172953
0.28125 3700 0.9828 0.194351 1.65359 0.117533 0.1 0.006907215513185129
0.28125 3800 0.963 0.162111 1.64953 0.0982774 0.1 0.00683848415102772
0.28125 3900 0.9586 0.143369 1.64821 0.0869843 0.1 0.006770436711376421
0.28125 4000 0.9934 0.172113 1.65144 0.10422 0.1 0.006703066388750011
0.28125 4100 0.9728 0.156026 1.65037 0.0945398 0.1 0.006636366445386311
0.28125 4200 0.9442 0.161215 1.65019 0.0976949 0.1 0.006570330210568327
0.28125 4300 0.9718 0.210461 1.64575 0.127882 0.1 0.006504951079957117
0.28125 4400 0.9184 0.215966 1.64848 0.13101 0.1 0.006440222514931274
0.28125 4500 0.9742 0.172471 1.64983 0.104538 0.1 0.006376138041932989
# Train result: 0.28125 0.999249
# Test result: 0.28125 0.9991
# 45361 entries between 0.1875 and 0.4375
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
0.3125 100 0.713 0.678485 3.00782 0.225574 0.1 0.009900493386913728
0.3125 200 0.788 0.656791 2.49609 0.263128 0.1 0.009801976930432239
0.3125 300 0.9878 0.604138 2.12571 0.284205 0.1 0.00970444077784252
0.3125 400 0.959 0.563175 1.90623 0.295438 0.1 0.009607875174472565
0.3125 500 0.9314 0.46537 1.82045 0.255635 0.1 0.009512270462715812
0.3125 600 0.983 0.3776 1.81257 0.208324 0.1 0.009417617081065264
0.3125 700 0.969 0.302159 1.83318 0.164828 0.1 0.009323905563157238
0.3125 800 0.8518 0.353865 1.85851 0.190403 0.1 0.009231126536824622
0.3125 900 0.916 0.262382 1.87262 0.140115 0.1 0.009139270723159591
0.3125 1000 0.9756 0.254421 1.88226 0.135168 0.1 0.009048328935585565
0.3125 1100 0.9626 0.26286 1.88343 0.139564 0.1 0.008958292078938489
0.3125 1200 0.9652 0.204637 1.87734 0.109004 0.1 0.0088691511485572
0.3125 1300 0.9586 0.23206 1.86942 0.124134 0.1 0.008780897229382877
0.3125 1400 0.9974 0.210725 1.85991 0.113298 0.1 0.008693521495067419
0.3125 1500 0.932 0.216651 1.85497 0.116795 0.1 0.008607015207090722
0.3125 1600 0.9726 0.18488 1.84328 0.100299 0.1 0.008521369713886751
0.3125 1700 0.9676 0.204038 1.83315 0.111304 0.1 0.008436576449978266
0.3125 1800 0.9704 0.215554 1.82318 0.11823 0.1 0.008352626935120183
0.3125 1900 0.9906 0.20108 1.81873 0.110561 0.1 0.008269512773451476
0.3125 2000 0.9516 0.216753 1.81291 0.119561 0.1 0.008187225652655481
0.3125 2100 0.9234 0.217224 1.80597 0.120281 0.1 0.008105757343128598
0.3125 2200 0.991 0.188444 1.799 0.104749 0.1 0.008025099697157206
0.3125 2300 0.9778 0.19716 1.79437 0.109877 0.1 0.007945244648102822
0.3125 2400 0.9724 0.18088 1.795 0.100769 0.1 0.007866184209595362
0.3125 2500 0.984 0.209171 1.79068 0.116811 0.1 0.007787910474734398
0.3125 2600 0.9942 0.178763 1.7864 0.100069 0.1 0.007710415615298401
0.3125 2700 0.9724 0.207775 1.7824 0.11657 0.1 0.0076336918809618085
0.3125 2800 0.9632 0.190776 1.78464 0.106899 0.1 0.007557731598519933
0.3125 2900 0.9276 0.236303 1.78385 0.132468 0.1 0.007482527171121546
0.3125 3000 0.887 0.208735 1.78184 0.117146 0.1 0.007408071077509108
0.3125 3100 0.9324 0.190429 1.77949 0.107013 0.1 0.0073343558712665735
0.3125 3200 0.9778 0.209666 1.77733 0.117967 0.1 0.007261374180074655
0.3125 3300 0.9986 0.165004 1.78069 0.0926628 0.1 0.007189118704973517
0.3125 3400 0.9682 0.167941 1.77871 0.0944173 0.1 0.007117582219632801
0.3125 3500 0.9436 0.218372 1.7766 0.122916 0.1 0.007046757569628924
0.3125 3600 0.9238 0.220882 1.77529 0.12442 0.1 0.00697663767172953
0.3125 3700 0.9902 0.169884 1.77782 0.0955576 0.1 0.006907215513185129
0.3125 3800 0.8944 0.231794 1.78023 0.130205 0.1 0.00683848415102772
0.3125 3900 0.9992 0.148765 1.77713 0.083711 0.1 0.006770436711376421
0.3125 4000 0.9822 0.223248 1.77521 0.125759 0.1 0.006703066388750011
0.3125 4100 0.9068 0.214341 1.77539 0.120729 0.1 0.006636366445386311
0.3125 4200 0.9628 0.186055 1.77896 0.104587 0.1 0.006570330210568327
0.3125 4300 0.9406 0.184583 1.7776 0.103839 0.1 0.006504951079957117
0.3125 4400 0.9618 0.194789 1.77634 0.109658 0.1 0.006440222514931274
0.3125 4500 0.8278 0.309973 1.77465 0.174667 0.1 0.006376138041932989
# Train result: 0.3125 0.930795
# Test result: 0.3125 0.9291
# 45361 entries between 0.21875 and 0.46875
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
0.34375 100 0.505 0.680567 3.00207 0.226699 0.1 0.009900493386913728
0.34375 200 0.6034 0.672431 2.47894 0.271257 0.1 0.009801976930432239
0.34375 300 0.9364 0.644834 2.07787 0.310334 0.1 0.00970444077784252
0.34375 400 0.9662 0.594979 1.80412 0.329789 0.1 0.009607875174472565
0.34375 500 0.9452 0.533062 1.65904 0.321308 0.1 0.009512270462715812
0.34375 600 0.8602 0.467432 1.62561 0.287542 0.1 0.009417617081065264
0.34375 700 0.8318 0.430167 1.65552 0.259838 0.1 0.009323905563157238
0.34375 800 0.8314 0.382452 1.70423 0.224413 0.1 0.009231126536824622
0.34375 900 0.857 0.341625 1.75066 0.195141 0.1 0.009139270723159591
0.34375 1000 0.9428 0.308961 1.78227 0.173353 0.1 0.009048328935585565
0.34375 1100 0.9976 0.271797 1.81107 0.150075 0.1 0.008958292078938489
0.34375 1200 0.9334 0.26272 1.83085 0.143496 0.1 0.0088691511485572
0.34375 1300 0.8766 0.316924 1.84409 0.171859 0.1 0.008780897229382877
0.34375 1400 0.964 0.222112 1.8539 0.119808 0.1 0.008693521495067419
0.34375 1500 0.984 0.217223 1.85616 0.117028 0.1 0.008607015207090722
0.34375 1600 0.972 0.2339 1.85564 0.126048 0.1 0.008521369713886751
0.34375 1700 0.8766 0.273874 1.85777 0.147421 0.1 0.008436576449978266
0.34375 1800 0.9094 0.235369 1.86067 0.126497 0.1 0.008352626935120183
0.34375 1900 0.9984 0.205641 1.85511 0.110851 0.1 0.008269512773451476
0.34375 2000 0.9538 0.19446 1.85421 0.104875 0.1 0.008187225652655481
0.34375 2100 0.9838 0.187034 1.85089 0.101051 0.1 0.008105757343128598
0.34375 2200 0.9034 0.268988 1.85177 0.14526 0.1 0.008025099697157206
0.34375 2300 0.9604 0.202796 1.84945 0.109652 0.1 0.007945244648102822
0.34375 2400 0.9214 0.227178 1.84486 0.123141 0.1 0.007866184209595362
0.34375 2500 0.856 0.294536 1.84211 0.159891 0.1 0.007787910474734398
0.34375 2600 0.8864 0.225394 1.84243 0.122336 0.1 0.007710415615298401
0.34375 2700 0.9808 0.188034 1.8436 0.101992 0.1 0.0076336918809618085
0.34375 2800 0.779 0.283782 1.8401 0.154221 0.1 0.007557731598519933
0.34375 2900 0.9808 0.20296 1.83905 0.110361 0.1 0.007482527171121546
0.34375 3000 0.9422 0.225152 1.83605 0.122629 0.1 0.007408071077509108
0.34375 3100 0.9424 0.206664 1.83895 0.112382 0.1 0.0073343558712665735
0.34375 3200 0.9074 0.237406 1.83782 0.129178 0.1 0.007261374180074655
0.34375 3300 0.896 0.212411 1.83632 0.115672 0.1 0.007189118704973517
0.34375 3400 0.8476 0.273535 1.83624 0.148965 0.1 0.007117582219632801
0.34375 3500 0.9464 0.204075 1.83522 0.111199 0.1 0.007046757569628924
0.34375 3600 0.9838 0.232855 1.83731 0.126737 0.1 0.00697663767172953
0.34375 3700 0.9408 0.248756 1.83476 0.13558 0.1 0.006907215513185129
0.34375 3800 0.9806 0.215556 1.83488 0.117477 0.1 0.00683848415102772
0.34375 3900 0.9944 0.202565 1.83166 0.110591 0.1 0.006770436711376421
0.34375 4000 0.984 0.194651 1.83577 0.106032 0.1 0.006703066388750011
0.34375 4100 0.94 0.184108 1.8364 0.100255 0.1 0.006636366445386311
0.34375 4200 0.9914 0.196407 1.83382 0.107103 0.1 0.006570330210568327
0.34375 4300 0.9266 0.225295 1.83618 0.122698 0.1 0.006504951079957117
0.34375 4400 0.895 0.309091 1.83403 0.168532 0.1 0.006440222514931274
0.34375 4500 0.8876 0.233275 1.83537 0.1271 0.1 0.006376138041932989
# Train result: 0.34375 0.908609
# Test result: 0.34375 0.907
# 45361 entries between 0.25 and 0.5
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
0.375 100 0.517 0.687657 2.97556 0.231102 0.1 0.009900493386913728
0.375 200 0.8974 0.667684 2.45903 0.271523 0.1 0.009801976930432239
0.375 300 0.9048 0.639699 2.06932 0.309136 0.1 0.00970444077784252
0.375 400 0.8446 0.567079 1.81595 0.312277 0.1 0.009607875174472565
0.375 500 0.9652 0.501768 1.69968 0.295213 0.1 0.009512270462715812
0.375 600 0.9662 0.403617 1.68931 0.238924 0.1 0.009417617081065264
0.375 700 0.8504 0.449919 1.70669 0.26362 0.1 0.009323905563157238
0.375 800 0.8068 0.360851 1.73995 0.207392 0.1 0.009231126536824622
0.375 900 0.9888 0.298237 1.78731 0.166864 0.1 0.009139270723159591
0.375 1000 0.73 0.528878 1.81745 0.291 0.1 0.009048328935585565
0.375 1100 0.8 0.310381 1.83351 0.169282 0.1 0.008958292078938489
0.375 1200 0.9128 0.275865 1.84177 0.149782 0.1 0.0088691511485572
0.375 1300 0.8936 0.23959 1.85703 0.129018 0.1 0.008780897229382877
0.375 1400 0.9142 0.266971 1.8634 0.143271 0.1 0.008693521495067419
0.375 1500 0.8514 0.325588 1.86343 0.174725 0.1 0.008607015207090722
0.375 1600 0.9596 0.24744 1.85994 0.133037 0.1 0.008521369713886751
0.375 1700 0.9096 0.206238 1.86006 0.110877 0.1 0.008436576449978266
0.375 1800 0.9182 0.204382 1.86207 0.109761 0.1 0.008352626935120183
0.375 1900 0.8462 0.26256 1.86081 0.141099 0.1 0.008269512773451476
0.375 2000 0.8304 0.265177 1.85477 0.14297 0.1 0.008187225652655481
0.375 2100 0.8988 0.236257 1.84651 0.127948 0.1 0.008105757343128598
0.375 2200 0.9534 0.178476 1.84742 0.0966078 0.1 0.008025099697157206
0.375 2300 0.883 0.220998 1.84517 0.119771 0.1 0.007945244648102822
0.375 2400 0.933 0.219847 1.8435 0.119255 0.1 0.007866184209595362
0.375 2500 0.9176 0.298137 1.83582 0.1624 0.1 0.007787910474734398
0.375 2600 0.8514 0.263687 1.83492 0.143704 0.1 0.007710415615298401
0.375 2700 0.9342 0.181042 1.83736 0.0985338 0.1 0.0076336918809618085
0.375 2800 0.9286 0.214464 1.83631 0.116791 0.1 0.007557731598519933
0.375 2900 0.8872 0.240294 1.83338 0.131066 0.1 0.007482527171121546
0.375 3000 0.8638 0.279924 1.82868 0.153074 0.1 0.007408071077509108
0.375 3100 0.9398 0.210758 1.83027 0.115151 0.1 0.0073343558712665735
0.375 3200 0.953 0.212232 1.83075 0.115927 0.1 0.007261374180074655
0.375 3300 0.9282 0.233388 1.83327 0.127307 0.1 0.007189118704973517
0.375 3400 0.9176 0.233469 1.82365 0.128023 0.1 0.007117582219632801
0.375 3500 0.8146 0.357048 1.82561 0.195577 0.1 0.007046757569628924
0.375 3600 0.9962 0.21417 1.82867 0.117118 0.1 0.00697663767172953
0.375 3700 0.9548 0.179684 1.82835 0.0982764 0.1 0.006907215513185129
0.375 3800 0.9712 0.184934 1.82649 0.101251 0.1 0.00683848415102772
0.375 3900 0.8452 0.271727 1.82433 0.148947 0.1 0.006770436711376421
0.375 4000 0.9506 0.197249 1.82496 0.108084 0.1 0.006703066388750011
0.375 4100 0.9684 0.179973 1.82646 0.0985366 0.1 0.006636366445386311
0.375 4200 0.9016 0.299456 1.82961 0.163673 0.1 0.006570330210568327
0.375 4300 0.8578 0.305825 1.82221 0.167832 0.1 0.006504951079957117
0.375 4400 0.9096 0.208254 1.82327 0.11422 0.1 0.006440222514931274
0.375 4500 0.9968 0.172841 1.82569 0.0946713 0.1 0.006376138041932989
# Train result: 0.375 0.89426
# Test result: 0.375 0.8874
# 45361 entries between 0.28125 and 0.53125
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
0.40625 100 0.4916 0.681699 2.99055 0.227951 0.1 0.009900493386913728
0.40625 200 0.9136 0.669352 2.47268 0.2707 0.1 0.009801976930432239
0.40625 300 0.9 0.626292 2.09381 0.299115 0.1 0.00970444077784252
0.40625 400 0.9882 0.544146 1.87161 0.290737 0.1 0.009607875174472565
0.40625 500 0.9702 0.43971 1.79689 0.244706 0.1 0.009512270462715812
0.40625 600 0.8596 0.419562 1.79863 0.233267 0.1 0.009417617081065264
0.40625 700 0.9028 0.341295 1.82677 0.18683 0.1 0.009323905563157238
0.40625 800 0.8916 0.336087 1.85667 0.181016 0.1 0.009231126536824622
0.40625 900 0.9116 0.273036 1.87326 0.145755 0.1 0.009139270723159591
0.40625 1000 0.8856 0.27971 1.88812 0.148142 0.1 0.009048328935585565
0.40625 1100 0.9494 0.219461 1.88574 0.116379 0.1 0.008958292078938489
0.40625 1200 0.9978 0.185494 1.88451 0.0984307 0.1 0.0088691511485572
0.40625 1300 0.8132 0.27027 1.88264 0.143559 0.1 0.008780897229382877
0.40625 1400 0.9634 0.198193 1.87092 0.105934 0.1 0.008693521495067419
0.40625 1500 0.8674 0.296348 1.86092 0.159249 0.1 0.008607015207090722
0.40625 1600 0.9652 0.168858 1.847 0.0914227 0.1 0.008521369713886751
0.40625 1700 0.8904 0.294548 1.83912 0.160157 0.1 0.008436576449978266
0.40625 1800 0.951 0.201499 1.83106 0.110045 0.1 0.008352626935120183
0.40625 1900 0.9134 0.257755 1.82349 0.141352 0.1 0.008269512773451476
0.40625 2000 0.9038 0.27979 1.81112 0.154485 0.1 0.008187225652655481
0.40625 2100 0.9362 0.158906 1.8045 0.0880607 0.1 0.008105757343128598
0.40625 2200 0.8882 0.272531 1.80432 0.151044 0.1 0.008025099697157206
0.40625 2300 0.991 0.173751 1.79504 0.0967946 0.1 0.007945244648102822
0.40625 2400 0.8352 0.32358 1.79105 0.180665 0.1 0.007866184209595362
0.40625 2500 0.9182 0.215149 1.78227 0.120716 0.1 0.007787910474734398
0.40625 2600 0.8738 0.28823 1.78097 0.161838 0.1 0.007710415615298401
0.40625 2700 0.9712 0.183218 1.77908 0.102984 0.1 0.0076336918809618085
0.40625 2800 0.994 0.156958 1.77752 0.0883014 0.1 0.007557731598519933
0.40625 2900 0.8978 0.269113 1.7736 0.151733 0.1 0.007482527171121546
0.40625 3000 0.9156 0.232119 1.77063 0.131094 0.1 0.007408071077509108
0.40625 3100 0.9 0.243498 1.77385 0.137271 0.1 0.0073343558712665735
0.40625 3200 0.9564 0.172459 1.76994 0.0974376 0.1 0.007261374180074655
0.40625 3300 0.9172 0.242129 1.76949 0.136836 0.1 0.007189118704973517
0.40625 3400 0.952 0.180085 1.7632 0.102135 0.1 0.007117582219632801
0.40625 3500 0.9572 0.156411 1.76357 0.0886901 0.1 0.007046757569628924
0.40625 3600 0.98 0.198774 1.76524 0.112605 0.1 0.00697663767172953
0.40625 3700 0.9834 0.199335 1.76529 0.11292 0.1 0.006907215513185129
0.40625 3800 0.9524 0.192311 1.76292 0.109087 0.1 0.00683848415102772
0.40625 3900 0.9696 0.162653 1.76163 0.0923312 0.1 0.006770436711376421
0.40625 4000 0.9186 0.189983 1.76393 0.107705 0.1 0.006703066388750011
0.40625 4100 0.9128 0.247364 1.76178 0.140406 0.1 0.006636366445386311
0.40625 4200 0.8536 0.316022 1.76256 0.179297 0.1 0.006570330210568327
0.40625 4300 0.9186 0.245411 1.75867 0.139543 0.1 0.006504951079957117
0.40625 4400 0.9994 0.174367 1.75825 0.0991708 0.1 0.006440222514931274
0.40625 4500 0.8964 0.247314 1.76157 0.140394 0.1 0.006376138041932989
# Train result: 0.40625 0.884481
# Test result: 0.40625 0.886
# 45361 entries between 0.3125 and 0.5625
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
0.4375 100 0.5072 0.681909 3.00341 0.227045 0.1 0.009900493386913728
0.4375 200 0.915 0.66491 2.48546 0.26752 0.1 0.009801976930432239
0.4375 300 0.8754 0.609711 2.11482 0.288304 0.1 0.00970444077784252
0.4375 400 0.9528 0.534318 1.91248 0.279385 0.1 0.009607875174472565
0.4375 500 0.8594 0.432509 1.86352 0.232093 0.1 0.009512270462715812
0.4375 600 0.9734 0.330173 1.87845 0.175769 0.1 0.009417617081065264
0.4375 700 0.9058 0.280641 1.90247 0.147514 0.1 0.009323905563157238
0.4375 800 0.9962 0.255061 1.9208 0.132789 0.1 0.009231126536824622
0.4375 900 0.9968 0.211308 1.93569 0.109164 0.1 0.009139270723159591
0.4375 1000 0.9216 0.24654 1.93758 0.127241 0.1 0.009048328935585565
0.4375 1100 0.9428 0.219073 1.92907 0.113564 0.1 0.008958292078938489
0.4375 1200 1.0 0.195198 1.91497 0.101933 0.1 0.0088691511485572
0.4375 1300 0.9262 0.211852 1.89555 0.111763 0.1 0.008780897229382877
0.4375 1400 0.9798 0.176122 1.87826 0.0937689 0.1 0.008693521495067419
0.4375 1500 0.8404 0.327343 1.86368 0.175643 0.1 0.008607015207090722
0.4375 1600 0.9546 0.16883 1.8493 0.0912941 0.1 0.008521369713886751
0.4375 1700 0.859 0.27464 1.83238 0.149881 0.1 0.008436576449978266
0.4375 1800 0.9572 0.220692 1.81817 0.121381 0.1 0.008352626935120183
0.4375 1900 0.926 0.217437 1.80374 0.120548 0.1 0.008269512773451476
0.4375 2000 0.9392 0.19095 1.79624 0.106305 0.1 0.008187225652655481
0.4375 2100 0.8484 0.274225 1.78625 0.15352 0.1 0.008105757343128598
0.4375 2200 0.9368 0.20459 1.7777 0.115087 0.1 0.008025099697157206
0.4375 2300 0.999 0.167942 1.77013 0.0948759 0.1 0.007945244648102822
0.4375 2400 0.8926 0.278155 1.76306 0.157768 0.1 0.007866184209595362
0.4375 2500 0.9336 0.149847 1.76301 0.0849951 0.1 0.007787910474734398
0.4375 2600 0.9778 0.170752 1.75823 0.0971158 0.1 0.007710415615298401
0.4375 2700 0.9836 0.185046 1.7535 0.10553 0.1 0.0076336918809618085
0.4375 2800 0.9976 0.172262 1.7477 0.0985649 0.1 0.007557731598519933
0.4375 2900 0.9046 0.205675 1.74681 0.117743 0.1 0.007482527171121546
0.4375 3000 0.8672 0.227615 1.74345 0.130555 0.1 0.007408071077509108
0.4375 3100 0.9742 0.156952 1.74346 0.0900234 0.1 0.0073343558712665735
0.4375 3200 0.8772 0.295738 1.74045 0.169921 0.1 0.007261374180074655
0.4375 3300 0.9636 0.168163 1.73743 0.0967887 0.1 0.007189118704973517
0.4375 3400 0.9828 0.164648 1.74139 0.0945496 0.1 0.007117582219632801
0.4375 3500 0.9516 0.196799 1.7401 0.113096 0.1 0.007046757569628924
0.4375 3600 0.9954 0.162839 1.73826 0.0936794 0.1 0.00697663767172953
0.4375 3700 0.9496 0.199879 1.73376 0.115287 0.1 0.006907215513185129
0.4375 3800 0.9508 0.23573 1.7335 0.135985 0.1 0.00683848415102772
0.4375 3900 0.982 0.174899 1.73278 0.100935 0.1 0.006770436711376421
0.4375 4000 0.9606 0.135245 1.73466 0.0779663 0.1 0.006703066388750011
0.4375 4100 0.9866 0.161259 1.73209 0.0931005 0.1 0.006636366445386311
0.4375 4200 0.886 0.285738 1.73135 0.165038 0.1 0.006570330210568327
0.4375 4300 0.9798 0.139276 1.73609 0.0802239 0.1 0.006504951079957117
0.4375 4400 0.9262 0.184385 1.73448 0.106306 0.1 0.006440222514931274
0.4375 4500 0.9682 0.150433 1.73388 0.0867612 0.1 0.006376138041932989
# Train result: 0.4375 0.969536
# Test result: 0.4375 0.9692
# 45361 entries between 0.34375 and 0.59375
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
0.46875 100 0.4974 0.682896 3.02266 0.225925 0.1 0.009900493386913728
0.46875 200 0.6692 0.664733 2.50099 0.265788 0.1 0.009801976930432239
0.46875 300 0.96 0.625104 2.12346 0.29438 0.1 0.00970444077784252
0.46875 400 0.9592 0.54682 1.91359 0.285755 0.1 0.009607875174472565
0.46875 500 0.9506 0.425393 1.84998 0.229945 0.1 0.009512270462715812
0.46875 600 0.85 0.417332 1.84848 0.22577 0.1 0.009417617081065264
0.46875 700 0.9352 0.311233 1.8711 0.166337 0.1 0.009323905563157238
0.46875 800 0.9822 0.272679 1.89408 0.143964 0.1 0.009231126536824622
0.46875 900 0.829 0.352898 1.91332 0.184443 0.1 0.009139270723159591
0.46875 1000 0.9182 0.27194 1.92484 0.141279 0.1 0.009048328935585565
0.46875 1100 0.9594 0.229211 1.92871 0.118842 0.1 0.008958292078938489
0.46875 1200 0.965 0.240513 1.92526 0.124925 0.1 0.0088691511485572
0.46875 1300 0.96 0.186962 1.91454 0.0976537 0.1 0.008780897229382877
0.46875 1400 0.947 0.195364 1.90323 0.102648 0.1 0.008693521495067419
0.46875 1500 0.9416 0.22306 1.89416 0.117762 0.1 0.008607015207090722
0.46875 1600 0.8978 0.205128 1.88464 0.108842 0.1 0.008521369713886751
0.46875 1700 0.9714 0.185016 1.87443 0.0987054 0.1 0.008436576449978266
0.46875 1800 0.9268 0.192382 1.85995 0.103434 0.1 0.008352626935120183
0.46875 1900 0.9286 0.23841 1.85342 0.128632 0.1 0.008269512773451476
0.46875 2000 0.938 0.221701 1.84655 0.120062 0.1 0.008187225652655481
0.46875 2100 0.9516 0.185941 1.83929 0.101094 0.1 0.008105757343128598
0.46875 2200 0.993 0.140566 1.83145 0.0767515 0.1 0.008025099697157206
0.46875 2300 1.0 0.154217 1.82152 0.0846636 0.1 0.007945244648102822
0.46875 2400 0.8958 0.254107 1.81792 0.139779 0.1 0.007866184209595362
0.46875 2500 0.8384 0.380755 1.81741 0.209505 0.1 0.007787910474734398
0.46875 2600 0.9588 0.176658 1.81519 0.0973222 0.1 0.007710415615298401
0.46875 2700 0.8984 0.208388 1.80725 0.115307 0.1 0.0076336918809618085
0.46875 2800 0.835 0.317163 1.80534 0.17568 0.1 0.007557731598519933
0.46875 2900 0.8078 0.371964 1.80503 0.206071 0.1 0.007482527171121546
0.46875 3000 0.968 0.20474 1.80401 0.113491 0.1 0.007408071077509108
0.46875 3100 0.9462 0.161765 1.80267 0.0897363 0.1 0.0073343558712665735
0.46875 3200 0.843 0.293349 1.79647 0.163292 0.1 0.007261374180074655
0.46875 3300 0.9946 0.13739 1.79496 0.0765419 0.1 0.007189118704973517
0.46875 3400 0.9184 0.238269 1.79709 0.132586 0.1 0.007117582219632801
0.46875 3500 0.9682 0.177793 1.79714 0.098931 0.1 0.007046757569628924
0.46875 3600 0.9496 0.193821 1.79254 0.108127 0.1 0.00697663767172953
0.46875 3700 0.6806 0.528444 1.79303 0.294721 0.1 0.006907215513185129
0.46875 3800 0.9566 0.145561 1.7912 0.0812647 0.1 0.00683848415102772
0.46875 3900 0.9908 0.154066 1.7942 0.085869 0.1 0.006770436711376421
0.46875 4000 0.933 0.16239 1.79321 0.0905578 0.1 0.006703066388750011
0.46875 4100 0.9732 0.165039 1.78653 0.0923799 0.1 0.006636366445386311
0.46875 4200 0.9836 0.193259 1.78781 0.108098 0.1 0.006570330210568327
0.46875 4300 0.9268 0.159646 1.79011 0.0891821 0.1 0.006504951079957117
0.46875 4400 0.9124 0.249648 1.7897 0.139492 0.1 0.006440222514931274
0.46875 4500 0.9698 0.15952 1.78768 0.089233 0.1 0.006376138041932989
# Train result: 0.46875 0.954128
# Test result: 0.46875 0.9518
# 45361 entries between 0.375 and 0.625
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
0.5 100 0.9992 0.68608 2.99339 0.229198 0.1 0.009900493386913728
0.5 200 0.8264 0.665632 2.47585 0.26885 0.1 0.009801976930432239
0.5 300 0.9444 0.612774 2.10626 0.29093 0.1 0.00970444077784252
0.5 400 0.9308 0.539813 1.90443 0.283452 0.1 0.009607875174472565
0.5 500 0.905 0.448218 1.84266 0.243244 0.1 0.009512270462715812
0.5 600 0.7906 0.457737 1.83598 0.249315 0.1 0.009417617081065264
0.5 700 0.9028 0.330849 1.83851 0.179955 0.1 0.009323905563157238
0.5 800 0.9628 0.271752 1.85397 0.146578 0.1 0.009231126536824622
0.5 900 0.9492 0.218332 1.85701 0.117572 0.1 0.009139270723159591
0.5 1000 0.9098 0.25996 1.85087 0.140453 0.1 0.009048328935585565
0.5 1100 0.8926 0.304373 1.83961 0.165456 0.1 0.008958292078938489
0.5 1200 0.9622 0.192694 1.82959 0.105321 0.1 0.0088691511485572
0.5 1300 0.9492 0.218976 1.82539 0.119961 0.1 0.008780897229382877
0.5 1400 0.9936 0.18886 1.81019 0.104331 0.1 0.008693521495067419
0.5 1500 0.9874 0.179377 1.79145 0.100129 0.1 0.008607015207090722
0.5 1600 0.9604 0.213332 1.7776 0.120011 0.1 0.008521369713886751
0.5 1700 0.9098 0.231401 1.77207 0.130582 0.1 0.008436576449978266
0.5 1800 0.958 0.179603 1.76368 0.101834 0.1 0.008352626935120183
0.5 1900 0.975 0.221846 1.74737 0.12696 0.1 0.008269512773451476
0.5 2000 0.9192 0.240491 1.73755 0.138409 0.1 0.008187225652655481
0.5 2100 0.9082 0.220143 1.73019 0.127236 0.1 0.008105757343128598
0.5 2200 0.985 0.183281 1.72952 0.105972 0.1 0.008025099697157206
0.5 2300 0.8414 0.281258 1.72221 0.163313 0.1 0.007945244648102822
0.5 2400 0.9936 0.191821 1.71157 0.112073 0.1 0.007866184209595362
0.5 2500 0.9512 0.154973 1.70641 0.0908182 0.1 0.007787910474734398
0.5 2600 0.9296 0.253994 1.70896 0.148625 0.1 0.007710415615298401
0.5 2700 0.8798 0.237099 1.70855 0.138772 0.1 0.0076336918809618085
0.5 2800 0.9734 0.141913 1.69836 0.0835587 0.1 0.007557731598519933
0.5 2900 0.8754 0.237326 1.69654 0.139889 0.1 0.007482527171121546
0.5 3000 0.8998 0.233915 1.69475 0.138023 0.1 0.007408071077509108
0.5 3100 0.9546 0.183056 1.69761 0.107832 0.1 0.0073343558712665735
0.5 3200 0.8094 0.30939 1.69598 0.182426 0.1 0.007261374180074655
0.5 3300 0.8962 0.218833 1.68778 0.129657 0.1 0.007189118704973517
0.5 3400 0.8278 0.319317 1.68747 0.189228 0.1 0.007117582219632801
0.5 3500 0.8952 0.2661 1.69021 0.157436 0.1 0.007046757569628924
0.5 3600 0.8424 0.330164 1.69401 0.194901 0.1 0.00697663767172953
0.5 3700 0.9522 0.239387 1.68488 0.14208 0.1 0.006907215513185129
0.5 3800 0.869 0.226325 1.68509 0.13431 0.1 0.00683848415102772
0.5 3900 0.9144 0.226237 1.68559 0.134218 0.1 0.006770436711376421
0.5 4000 0.9734 0.175103 1.68817 0.103724 0.1 0.006703066388750011
0.5 4100 0.9094 0.285652 1.6879 0.169235 0.1 0.006636366445386311
0.5 4200 0.8134 0.381459 1.68141 0.226868 0.1 0.006570330210568327
0.5 4300 0.7736 0.249133 1.68175 0.148139 0.1 0.006504951079957117
0.5 4400 0.8218 0.313579 1.68373 0.186241 0.1 0.006440222514931274
0.5 4500 0.9298 0.223613 1.68662 0.13258 0.1 0.006376138041932989
# Train result: 0.5 0.928433
# Test result: 0.5 0.9269
# 45361 entries between 0.40625 and 0.65625
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
0.53125 100 0.4988 0.683284 3.01137 0.226902 0.1 0.009900493386913728
0.53125 200 0.9596 0.647728 2.50928 0.258133 0.1 0.009801976930432239
0.53125 300 0.9084 0.565624 2.18883 0.258413 0.1 0.00970444077784252
0.53125 400 0.94 0.458601 2.04959 0.223753 0.1 0.009607875174472565
0.53125 500 0.9178 0.34389 2.01741 0.170461 0.1 0.009512270462715812
0.53125 600 0.992 0.306875 2.0118 0.152538 0.1 0.009417617081065264
0.53125 700 0.9082 0.281735 2.00176 0.140744 0.1 0.009323905563157238
0.53125 800 0.9074 0.269311 1.98372 0.135761 0.1 0.009231126536824622
0.53125 900 0.9526 0.201115 1.96218 0.102496 0.1 0.009139270723159591
0.53125 1000 0.9174 0.253784 1.93865 0.130908 0.1 0.009048328935585565
0.53125 1100 0.7968 0.282821 1.90872 0.148173 0.1 0.008958292078938489
0.53125 1200 0.9218 0.143171 1.87953 0.0761737 0.1 0.0088691511485572
0.53125 1300 0.8946 0.263231 1.85259 0.142088 0.1 0.008780897229382877
0.53125 1400 0.9588 0.213842 1.83042 0.116827 0.1 0.008693521495067419
0.53125 1500 0.9788 0.153207 1.8061 0.0848275 0.1 0.008607015207090722
0.53125 1600 0.928 0.224363 1.78524 0.125677 0.1 0.008521369713886751
0.53125 1700 0.9726 0.169419 1.76912 0.095765 0.1 0.008436576449978266
0.53125 1800 0.9598 0.152065 1.75418 0.0866871 0.1 0.008352626935120183
0.53125 1900 0.9668 0.166659 1.74056 0.0957506 0.1 0.008269512773451476
0.53125 2000 0.8884 0.208399 1.72618 0.120729 0.1 0.008187225652655481
0.53125 2100 0.9692 0.160552 1.71794 0.0934562 0.1 0.008105757343128598
0.53125 2200 0.9952 0.18386 1.70848 0.107616 0.1 0.008025099697157206
0.53125 2300 0.9788 0.137655 1.70402 0.0807825 0.1 0.007945244648102822
0.53125 2400 0.9948 0.164301 1.69598 0.0968766 0.1 0.007866184209595362
0.53125 2500 0.9702 0.140619 1.68969 0.0832218 0.1 0.007787910474734398
0.53125 2600 0.9466 0.204038 1.68609 0.121013 0.1 0.007710415615298401
0.53125 2700 0.9444 0.196335 1.68395 0.116592 0.1 0.0076336918809618085
0.53125 2800 0.9262 0.147692 1.67975 0.0879251 0.1 0.007557731598519933
0.53125 2900 0.8974 0.280889 1.67475 0.16772 0.1 0.007482527171121546
0.53125 3000 0.9254 0.213798 1.67252 0.12783 0.1 0.007408071077509108
0.53125 3100 0.841 0.33806 1.67133 0.20227 0.1 0.0073343558712665735
0.53125 3200 0.9602 0.184689 1.67234 0.110437 0.1 0.007261374180074655
0.53125 3300 0.93 0.204783 1.66908 0.122692 0.1 0.007189118704973517
0.53125 3400 0.9534 0.173858 1.66638 0.104333 0.1 0.007117582219632801
0.53125 3500 0.9724 0.151391 1.66549 0.0908991 0.1 0.007046757569628924
0.53125 3600 0.9268 0.153036 1.66697 0.0918049 0.1 0.00697663767172953
0.53125 3700 0.9932 0.154919 1.66445 0.0930752 0.1 0.006907215513185129
0.53125 3800 0.929 0.19154 1.66147 0.115283 0.1 0.00683848415102772
0.53125 3900 0.8988 0.196109 1.66129 0.118046 0.1 0.006770436711376421
0.53125 4000 0.9652 0.188488 1.66076 0.113495 0.1 0.006703066388750011
0.53125 4100 0.9532 0.166359 1.66251 0.100065 0.1 0.006636366445386311
0.53125 4200 0.8688 0.208522 1.65948 0.125655 0.1 0.006570330210568327
0.53125 4300 0.9476 0.140609 1.65933 0.0847386 0.1 0.006504951079957117
0.53125 4400 0.9496 0.209432 1.65869 0.126263 0.1 0.006440222514931274
0.53125 4500 0.9694 0.138863 1.66119 0.0835923 0.1 0.006376138041932989
# Train result: 0.53125 0.974547
# Test result: 0.53125 0.9738
# 45361 entries between 0.4375 and 0.6875
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
0.5625 100 0.8844 0.668367 3.00237 0.222613 0.1 0.009900493386913728
0.5625 200 0.9218 0.597203 2.54961 0.234233 0.1 0.009801976930432239
0.5625 300 0.976 0.467849 2.32215 0.201473 0.1 0.00970444077784252
0.5625 400 0.8882 0.360385 2.24333 0.160648 0.1 0.009607875174472565
0.5625 500 0.908 0.282905 2.19902 0.12865 0.1 0.009512270462715812
0.5625 600 0.8258 0.284921 2.15079 0.132473 0.1 0.009417617081065264
0.5625 700 0.9284 0.208301 2.09432 0.0994599 0.1 0.009323905563157238
0.5625 800 0.9048 0.214683 2.03315 0.105591 0.1 0.009231126536824622
0.5625 900 0.9754 0.165311 1.97506 0.0836994 0.1 0.009139270723159591
0.5625 1000 0.9954 0.164562 1.91921 0.0857449 0.1 0.009048328935585565
0.5625 1100 0.9716 0.170541 1.86602 0.0913927 0.1 0.008958292078938489
0.5625 1200 0.96 0.138376 1.81505 0.0762383 0.1 0.0088691511485572
0.5625 1300 0.9816 0.161374 1.7747 0.0909302 0.1 0.008780897229382877
0.5625 1400 0.9798 0.185258 1.73937 0.106509 0.1 0.008693521495067419
0.5625 1500 0.9946 0.148698 1.70946 0.0869854 0.1 0.008607015207090722
0.5625 1600 0.9288 0.195299 1.68247 0.116079 0.1 0.008521369713886751
0.5625 1700 0.939 0.126287 1.65651 0.0762367 0.1 0.008436576449978266
0.5625 1800 0.8764 0.255918 1.63944 0.156101 0.1 0.008352626935120183
0.5625 1900 0.956 0.136436 1.6248 0.0839713 0.1 0.008269512773451476
0.5625 2000 0.9794 0.148702 1.60957 0.0923859 0.1 0.008187225652655481
0.5625 2100 0.9016 0.167006 1.59483 0.104717 0.1 0.008105757343128598
0.5625 2200 0.9664 0.14277 1.58501 0.0900748 0.1 0.008025099697157206
0.5625 2300 0.9758 0.149307 1.57748 0.0946488 0.1 0.007945244648102822
0.5625 2400 0.9694 0.141917 1.57258 0.0902451 0.1 0.007866184209595362
0.5625 2500 0.9714 0.139609 1.56678 0.0891053 0.1 0.007787910474734398
0.5625 2600 0.955 0.148813 1.5576 0.0955401 0.1 0.007710415615298401
0.5625 2700 0.9584 0.169886 1.55601 0.10918 0.1 0.0076336918809618085
0.5625 2800 0.9574 0.176157 1.55573 0.113231 0.1 0.007557731598519933
0.5625 2900 0.9706 0.125596 1.55061 0.0809979 0.1 0.007482527171121546
0.5625 3000 0.9622 0.172287 1.54485 0.111524 0.1 0.007408071077509108
0.5625 3100 0.9692 0.13836 1.54281 0.0896807 0.1 0.0073343558712665735
0.5625 3200 0.849 0.213786 1.54256 0.138592 0.1 0.007261374180074655
0.5625 3300 0.976 0.165695 1.5418 0.107468 0.1 0.007189118704973517
0.5625 3400 0.9838 0.118823 1.54093 0.0771112 0.1 0.007117582219632801
0.5625 3500 0.9982 0.157147 1.5351 0.102369 0.1 0.007046757569628924
0.5625 3600 0.9162 0.175723 1.53696 0.114331 0.1 0.00697663767172953
0.5625 3700 0.9164 0.158446 1.53866 0.102976 0.1 0.006907215513185129
0.5625 3800 0.9498 0.141297 1.53617 0.0919805 0.1 0.00683848415102772
0.5625 3900 0.9472 0.148002 1.53187 0.0966157 0.1 0.006770436711376421
0.5625 4000 0.9452 0.120796 1.53232 0.0788319 0.1 0.006703066388750011
0.5625 4100 0.9218 0.199059 1.53104 0.130016 0.1 0.006636366445386311
0.5625 4200 0.9658 0.130845 1.53321 0.0853407 0.1 0.006570330210568327
0.5625 4300 0.965 0.126969 1.53308 0.0828194 0.1 0.006504951079957117
0.5625 4400 0.9544 0.152726 1.5283 0.0999319 0.1 0.006440222514931274
0.5625 4500 0.9902 0.11783 1.52922 0.0770519 0.1 0.006376138041932989
# Train result: 0.5625 0.992141
# Test result: 0.5625 0.9913
# 45361 entries between 0.46875 and 0.71875
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
0.59375 100 0.7488 0.665743 3.00155 0.2218 0.1 0.009900493386913728
0.59375 200 0.9812 0.580754 2.55781 0.227051 0.1 0.009801976930432239
0.59375 300 0.945 0.451822 2.34616 0.192579 0.1 0.00970444077784252
0.59375 400 0.9418 0.317858 2.26244 0.140493 0.1 0.009607875174472565
0.59375 500 0.989 0.245214 2.20599 0.111159 0.1 0.009512270462715812
0.59375 600 0.878 0.28781 2.14227 0.134348 0.1 0.009417617081065264
0.59375 700 0.9904 0.225572 2.07301 0.108813 0.1 0.009323905563157238
0.59375 800 0.9934 0.164688 2.00327 0.0822096 0.1 0.009231126536824622
0.59375 900 0.9434 0.17655 1.93419 0.0912788 0.1 0.009139270723159591
0.59375 1000 0.9016 0.195284 1.8703 0.104414 0.1 0.009048328935585565
0.59375 1100 0.9366 0.173831 1.81513 0.0957682 0.1 0.008958292078938489
0.59375 1200 0.9828 0.140952 1.76583 0.0798219 0.1 0.0088691511485572
0.59375 1300 0.9626 0.134031 1.7198 0.0779341 0.1 0.008780897229382877
0.59375 1400 0.961 0.178803 1.68245 0.106276 0.1 0.008693521495067419
0.59375 1500 0.9674 0.156435 1.6482 0.0949126 0.1 0.008607015207090722
0.59375 1600 0.9324 0.158725 1.62289 0.0978037 0.1 0.008521369713886751
0.59375 1700 0.968 0.141085 1.59922 0.0882209 0.1 0.008436576449978266
0.59375 1800 0.9442 0.155473 1.5774 0.0985631 0.1 0.008352626935120183
0.59375 1900 0.984 0.11538 1.55964 0.0739783 0.1 0.008269512773451476
0.59375 2000 0.9424 0.186844 1.54661 0.120808 0.1 0.008187225652655481
0.59375 2100 0.979 0.155921 1.5359 0.101518 0.1 0.008105757343128598
0.59375 2200 0.9982 0.157253 1.52379 0.103199 0.1 0.008025099697157206
0.59375 2300 0.9752 0.171223 1.51545 0.112985 0.1 0.007945244648102822
0.59375 2400 0.9548 0.156639 1.50679 0.103955 0.1 0.007866184209595362
0.59375 2500 0.9652 0.15679 1.50302 0.104317 0.1 0.007787910474734398
0.59375 2600 0.987 0.148304 1.49827 0.0989832 0.1 0.007710415615298401
0.59375 2700 0.9956 0.142592 1.49235 0.0955486 0.1 0.0076336918809618085
0.59375 2800 0.982 0.162049 1.48744 0.108945 0.1 0.007557731598519933
0.59375 2900 0.9322 0.218095 1.48455 0.146909 0.1 0.007482527171121546
0.59375 3000 0.989 0.128096 1.48376 0.0863318 0.1 0.007408071077509108
0.59375 3100 0.951 0.189279 1.48008 0.127884 0.1 0.0073343558712665735
0.59375 3200 0.9682 0.145597 1.47795 0.0985127 0.1 0.007261374180074655
0.59375 3300 0.9772 0.140774 1.47343 0.0955418 0.1 0.007189118704973517
0.59375 3400 0.9976 0.150842 1.47519 0.102253 0.1 0.007117582219632801
0.59375 3500 0.9906 0.116605 1.47354 0.0791329 0.1 0.007046757569628924
0.59375 3600 0.9832 0.158951 1.4706 0.108086 0.1 0.00697663767172953
0.59375 3700 0.956 0.147869 1.46869 0.100681 0.1 0.006907215513185129
0.59375 3800 0.9532 0.155295 1.46896 0.105718 0.1 0.00683848415102772
0.59375 3900 0.989 0.137307 1.46958 0.0934324 0.1 0.006770436711376421
0.59375 4000 0.972 0.147219 1.46776 0.100302 0.1 0.006703066388750011
0.59375 4100 0.9306 0.175575 1.46678 0.119701 0.1 0.006636366445386311
0.59375 4200 0.9824 0.165431 1.46288 0.113086 0.1 0.006570330210568327
0.59375 4300 0.9104 0.141696 1.46587 0.0966632 0.1 0.006504951079957117
0.59375 4400 0.9768 0.125128 1.46529 0.0853944 0.1 0.006440222514931274
0.59375 4500 0.9658 0.146147 1.46271 0.0999156 0.1 0.006376138041932989
# Train result: 0.59375 0.981744
# Test result: 0.59375 0.981
# 45361 entries between 0.5 and 0.75
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
0.625 100 0.8738 0.671596 2.9973 0.224067 0.1 0.009900493386913728
0.625 200 0.8674 0.580343 2.54675 0.227876 0.1 0.009801976930432239
0.625 300 0.9476 0.420283 2.3362 0.1799 0.1 0.00970444077784252
0.625 400 0.9978 0.312551 2.25858 0.138384 0.1 0.009607875174472565
0.625 500 0.9184 0.269072 2.19743 0.122449 0.1 0.009512270462715812
0.625 600 0.9874 0.198746 2.13122 0.0932546 0.1 0.009417617081065264
0.625 700 0.9986 0.182242 2.0586 0.0885273 0.1 0.009323905563157238
0.625 800 0.9436 0.194997 1.98449 0.0982601 0.1 0.009231126536824622
0.625 900 0.9768 0.194351 1.91244 0.101625 0.1 0.009139270723159591
0.625 1000 0.912 0.231143 1.84689 0.125153 0.1 0.009048328935585565
0.625 1100 0.96 0.203639 1.78994 0.113769 0.1 0.008958292078938489
0.625 1200 0.9856 0.116782 1.73853 0.0671729 0.1 0.0088691511485572
0.625 1300 0.981 0.153684 1.69236 0.0908105 0.1 0.008780897229382877
0.625 1400 0.8914 0.191249 1.65328 0.115679 0.1 0.008693521495067419
0.625 1500 0.9554 0.140999 1.62096 0.0869849 0.1 0.008607015207090722
0.625 1600 0.935 0.179646 1.59436 0.112676 0.1 0.008521369713886751
0.625 1700 0.9814 0.133404 1.56929 0.0850093 0.1 0.008436576449978266
0.625 1800 0.9768 0.141364 1.54796 0.0913228 0.1 0.008352626935120183
0.625 1900 0.991 0.140534 1.52993 0.0918564 0.1 0.008269512773451476
0.625 2000 0.959 0.161083 1.51706 0.106181 0.1 0.008187225652655481
0.625 2100 0.9956 0.141128 1.50511 0.0937657 0.1 0.008105757343128598
0.625 2200 0.9892 0.13628 1.49405 0.0912154 0.1 0.008025099697157206
0.625 2300 0.9816 0.130486 1.48442 0.0879039 0.1 0.007945244648102822
0.625 2400 0.9328 0.140443 1.47853 0.094988 0.1 0.007866184209595362
0.625 2500 0.9746 0.125902 1.47347 0.0854457 0.1 0.007787910474734398
0.625 2600 0.9758 0.147152 1.46769 0.100261 0.1 0.007710415615298401
0.625 2700 0.962 0.147068 1.46203 0.100592 0.1 0.0076336918809618085
0.625 2800 0.9936 0.141753 1.45806 0.0972209 0.1 0.007557731598519933
0.625 2900 0.9942 0.176319 1.45623 0.121079 0.1 0.007482527171121546
0.625 3000 0.9828 0.154581 1.45392 0.10632 0.1 0.007408071077509108
0.625 3100 0.9788 0.155289 1.45108 0.107016 0.1 0.0073343558712665735
0.625 3200 0.9844 0.135396 1.44771 0.093524 0.1 0.007261374180074655
0.625 3300 0.9954 0.127184 1.44697 0.0878974 0.1 0.007189118704973517
0.625 3400 0.9174 0.15742 1.44616 0.108854 0.1 0.007117582219632801
0.625 3500 0.9974 0.146066 1.44496 0.101086 0.1 0.007046757569628924
0.625 3600 0.9784 0.129057 1.44172 0.0895158 0.1 0.00697663767172953
0.625 3700 0.9804 0.143821 1.4404 0.099848 0.1 0.006907215513185129
0.625 3800 0.9588 0.157825 1.44077 0.109542 0.1 0.00683848415102772
0.625 3900 0.9674 0.144067 1.44056 0.100008 0.1 0.006770436711376421
0.625 4000 0.914 0.160539 1.43857 0.111596 0.1 0.006703066388750011
0.625 4100 0.9512 0.173479 1.43687 0.120734 0.1 0.006636366445386311
0.625 4200 0.9996 0.134925 1.43751 0.0938606 0.1 0.006570330210568327
0.625 4300 0.96 0.147491 1.43619 0.102696 0.1 0.006504951079957117
0.625 4400 0.9516 0.185129 1.43706 0.128825 0.1 0.006440222514931274
0.625 4500 0.9444 0.127754 1.43488 0.0890347 0.1 0.006376138041932989
# Train result: 0.625 0.954879
# Test result: 0.625 0.9542
# 45361 entries between 0.53125 and 0.78125
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
0.65625 100 0.8268 0.662024 3.03291 0.21828 0.1 0.009900493386913728
0.65625 200 0.9976 0.54481 2.6124 0.208548 0.1 0.009801976930432239
0.65625 300 0.9572 0.371806 2.43525 0.152677 0.1 0.00970444077784252
0.65625 400 0.9946 0.274615 2.34626 0.117044 0.1 0.009607875174472565
0.65625 500 0.9682 0.224757 2.26141 0.0993878 0.1 0.009512270462715812
0.65625 600 0.9438 0.237686 2.17092 0.109486 0.1 0.009417617081065264
0.65625 700 0.9838 0.172019 2.07731 0.0828084 0.1 0.009323905563157238
0.65625 800 0.9736 0.146221 1.98899 0.0735155 0.1 0.009231126536824622
0.65625 900 0.976 0.148738 1.90944 0.0778963 0.1 0.009139270723159591
0.65625 1000 0.9288 0.20999 1.83744 0.114284 0.1 0.009048328935585565
0.65625 1100 0.984 0.156845 1.7755 0.0883383 0.1 0.008958292078938489
0.65625 1200 0.9672 0.131959 1.71727 0.0768424 0.1 0.0088691511485572
0.65625 1300 0.9854 0.146676 1.66825 0.087922 0.1 0.008780897229382877
0.65625 1400 0.9722 0.162659 1.62828 0.0998963 0.1 0.008693521495067419
0.65625 1500 0.961 0.150552 1.59645 0.0943046 0.1 0.008607015207090722
0.65625 1600 0.9748 0.113538 1.56479 0.0725579 0.1 0.008521369713886751
0.65625 1700 0.9934 0.152389 1.53919 0.0990056 0.1 0.008436576449978266
0.65625 1800 0.9678 0.15305 1.51861 0.100783 0.1 0.008352626935120183
0.65625 1900 0.9866 0.124783 1.50088 0.0831398 0.1 0.008269512773451476
0.65625 2000 0.986 0.125233 1.48941 0.0840827 0.1 0.008187225652655481
0.65625 2100 0.9922 0.124838 1.47419 0.0846824 0.1 0.008105757343128598
0.65625 2200 0.9932 0.154268 1.46246 0.105485 0.1 0.008025099697157206
0.65625 2300 0.9668 0.157731 1.45481 0.10842 0.1 0.007945244648102822
0.65625 2400 0.991 0.158169 1.44811 0.109225 0.1 0.007866184209595362
0.65625 2500 0.976 0.115387 1.44165 0.0800383 0.1 0.007787910474734398
0.65625 2600 0.9562 0.163019 1.43515 0.11359 0.1 0.007710415615298401
0.65625 2700 0.9656 0.134997 1.43052 0.0943694 0.1 0.0076336918809618085
0.65625 2800 0.9966 0.136988 1.42574 0.096082 0.1 0.007557731598519933
0.65625 2900 0.9808 0.154399 1.4259 0.108282 0.1 0.007482527171121546
0.65625 3000 0.9662 0.120513 1.41927 0.0849119 0.1 0.007408071077509108
0.65625 3100 0.9604 0.132768 1.41638 0.0937374 0.1 0.0073343558712665735
0.65625 3200 0.9574 0.145655 1.41541 0.102906 0.1 0.007261374180074655
0.65625 3300 0.995 0.141086 1.41429 0.0997573 0.1 0.007189118704973517
0.65625 3400 0.8788 0.188073 1.41391 0.133016 0.1 0.007117582219632801
0.65625 3500 0.9522 0.124277 1.40981 0.0881515 0.1 0.007046757569628924
0.65625 3600 0.9666 0.1305 1.40822 0.0926702 0.1 0.00697663767172953
0.65625 3700 0.9838 0.135281 1.40589 0.0962248 0.1 0.006907215513185129
0.65625 3800 0.9928 0.140098 1.40824 0.0994846 0.1 0.00683848415102772
0.65625 3900 0.9832 0.152011 1.40345 0.108312 0.1 0.006770436711376421
0.65625 4000 0.9908 0.137095 1.40133 0.097832 0.1 0.006703066388750011
0.65625 4100 0.9654 0.105002 1.40294 0.0748444 0.1 0.006636366445386311
0.65625 4200 0.9998 0.132933 1.40227 0.094798 0.1 0.006570330210568327
0.65625 4300 0.9922 0.120549 1.40277 0.0859368 0.1 0.006504951079957117
0.65625 4400 0.9832 0.111339 1.39964 0.0795481 0.1 0.006440222514931274
0.65625 4500 0.9716 0.135623 1.39939 0.096916 0.1 0.006376138041932989
# Train result: 0.65625 0.953157
# Test result: 0.65625 0.9537
# 45361 entries between 0.5625 and 0.8125
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
0.6875 100 0.949 0.657376 3.02807 0.217094 0.1 0.009900493386913728
0.6875 200 0.9802 0.506646 2.62167 0.193253 0.1 0.009801976930432239
0.6875 300 0.9612 0.338358 2.45277 0.13795 0.1 0.00970444077784252
0.6875 400 0.9802 0.260461 2.35918 0.110403 0.1 0.009607875174472565
0.6875 500 0.956 0.229661 2.26577 0.101361 0.1 0.009512270462715812
0.6875 600 0.9414 0.151666 2.16593 0.0700237 0.1 0.009417617081065264
0.6875 700 0.9872 0.189951 2.06924 0.0917977 0.1 0.009323905563157238
0.6875 800 0.9902 0.187567 1.97345 0.0950451 0.1 0.009231126536824622
0.6875 900 0.9988 0.155332 1.88816 0.0822665 0.1 0.009139270723159591
0.6875 1000 0.9896 0.12695 1.81455 0.0699622 0.1 0.009048328935585565
0.6875 1100 0.9622 0.151807 1.74895 0.0867994 0.1 0.008958292078938489
0.6875 1200 0.9804 0.15153 1.69143 0.0895869 0.1 0.0088691511485572
0.6875 1300 0.9914 0.148927 1.6408 0.0907651 0.1 0.008780897229382877
0.6875 1400 0.9994 0.138514 1.59876 0.0866387 0.1 0.008693521495067419
0.6875 1500 0.9738 0.139308 1.56429 0.0890549 0.1 0.008607015207090722
0.6875 1600 0.976 0.136854 1.5371 0.0890339 0.1 0.008521369713886751
0.6875 1700 0.9724 0.148873 1.50895 0.0986604 0.1 0.008436576449978266
0.6875 1800 0.9858 0.113956 1.48673 0.076649 0.1 0.008352626935120183
0.6875 1900 0.9756 0.157879 1.47082 0.107341 0.1 0.008269512773451476
0.6875 2000 0.9544 0.146138 1.45656 0.100331 0.1 0.008187225652655481
0.6875 2100 0.9968 0.15479 1.4434 0.10724 0.1 0.008105757343128598
0.6875 2200 0.9862 0.151728 1.43116 0.106017 0.1 0.008025099697157206
0.6875 2300 0.9944 0.113646 1.42228 0.079904 0.1 0.007945244648102822
0.6875 2400 0.9816 0.12605 1.41659 0.0889808 0.1 0.007866184209595362
0.6875 2500 0.9864 0.125996 1.41261 0.0891942 0.1 0.007787910474734398
0.6875 2600 0.949 0.121869 1.40469 0.0867588 0.1 0.007710415615298401
0.6875 2700 0.9816 0.142983 1.39875 0.102222 0.1 0.0076336918809618085
0.6875 2800 0.9712 0.132046 1.39626 0.0945716 0.1 0.007557731598519933
0.6875 2900 0.9834 0.148171 1.39367 0.106317 0.1 0.007482527171121546
0.6875 3000 0.9984 0.107232 1.39112 0.077083 0.1 0.007408071077509108
0.6875 3100 0.971 0.11218 1.38622 0.0809247 0.1 0.0073343558712665735
0.6875 3200 0.9982 0.136564 1.38364 0.0986991 0.1 0.007261374180074655
0.6875 3300 0.9854 0.142498 1.38361 0.102991 0.1 0.007189118704973517
0.6875 3400 0.9674 0.124022 1.38458 0.0895742 0.1 0.007117582219632801
0.6875 3500 0.9704 0.142056 1.38059 0.102895 0.1 0.007046757569628924
0.6875 3600 0.9924 0.135414 1.37764 0.098294 0.1 0.00697663767172953
0.6875 3700 0.9856 0.152856 1.37753 0.110964 0.1 0.006907215513185129
0.6875 3800 0.9952 0.154703 1.37736 0.112319 0.1 0.00683848415102772
0.6875 3900 0.9802 0.114186 1.37778 0.0828768 0.1 0.006770436711376421
0.6875 4000 0.9946 0.136559 1.37295 0.0994645 0.1 0.006703066388750011
0.6875 4100 0.9856 0.121226 1.37242 0.08833 0.1 0.006636366445386311
0.6875 4200 0.986 0.133358 1.37326 0.0971111 0.1 0.006570330210568327
0.6875 4300 0.9812 0.141368 1.37442 0.102857 0.1 0.006504951079957117
0.6875 4400 0.9906 0.125099 1.37192 0.0911855 0.1 0.006440222514931274
0.6875 4500 0.9734 0.161926 1.36995 0.118199 0.1 0.006376138041932989
# Train result: 0.6875 0.986534
# Test result: 0.6875 0.9888
# 45361 entries between 0.59375 and 0.84375
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
0.71875 100 0.9482 0.62963 3.02139 0.208391 0.1 0.009900493386913728
0.71875 200 0.9166 0.45328 2.67502 0.169449 0.1 0.009801976930432239
0.71875 300 0.9522 0.291317 2.52988 0.115151 0.1 0.00970444077784252
0.71875 400 0.9868 0.23581 2.41497 0.0976451 0.1 0.009607875174472565
0.71875 500 0.98 0.222284 2.29591 0.0968173 0.1 0.009512270462715812
0.71875 600 0.9974 0.176397 2.17443 0.081123 0.1 0.009417617081065264
0.71875 700 0.994 0.149497 2.06126 0.0725269 0.1 0.009323905563157238
0.71875 800 0.9698 0.142855 1.95654 0.073014 0.1 0.009231126536824622
0.71875 900 0.994 0.134083 1.8632 0.071964 0.1 0.009139270723159591
0.71875 1000 0.9822 0.150034 1.78126 0.0842289 0.1 0.009048328935585565
0.71875 1100 0.9994 0.164714 1.71271 0.096172 0.1 0.008958292078938489
0.71875 1200 0.9874 0.138005 1.65197 0.0835398 0.1 0.0088691511485572
0.71875 1300 0.997 0.130173 1.60109 0.0813025 0.1 0.008780897229382877
0.71875 1400 0.999 0.138447 1.55953 0.0887747 0.1 0.008693521495067419
0.71875 1500 1.0 0.148797 1.5223 0.0977451 0.1 0.008607015207090722
0.71875 1600 0.9926 0.126169 1.49213 0.0845563 0.1 0.008521369713886751
0.71875 1700 0.9928 0.12435 1.46735 0.0847449 0.1 0.008436576449978266
0.71875 1800 0.9954 0.134849 1.44499 0.0933214 0.1 0.008352626935120183
0.71875 1900 0.9952 0.134382 1.42708 0.0941658 0.1 0.008269512773451476
0.71875 2000 0.9786 0.0921495 1.41337 0.0651983 0.1 0.008187225652655481
0.71875 2100 0.979 0.121139 1.40024 0.0865126 0.1 0.008105757343128598
0.71875 2200 0.9966 0.142357 1.38963 0.102442 0.1 0.008025099697157206
0.71875 2300 0.9774 0.150766 1.382 0.109093 0.1 0.007945244648102822
0.71875 2400 0.9754 0.121462 1.37353 0.0884304 0.1 0.007866184209595362
0.71875 2500 0.9922 0.156785 1.36863 0.114556 0.1 0.007787910474734398
0.71875 2600 0.9672 0.142363 1.3639 0.104379 0.1 0.007710415615298401
0.71875 2700 0.9944 0.165354 1.35836 0.12173 0.1 0.0076336918809618085
0.71875 2800 0.9892 0.104054 1.35494 0.0767959 0.1 0.007557731598519933
0.71875 2900 0.9966 0.144416 1.35268 0.106763 0.1 0.007482527171121546
0.71875 3000 0.9822 0.111193 1.34909 0.0824209 0.1 0.007408071077509108
0.71875 3100 0.9684 0.116309 1.34697 0.0863485 0.1 0.0073343558712665735
0.71875 3200 0.9804 0.136378 1.34543 0.101364 0.1 0.007261374180074655
0.71875 3300 0.925 0.121637 1.34252 0.0906035 0.1 0.007189118704973517
0.71875 3400 0.9976 0.0936003 1.34264 0.0697136 0.1 0.007117582219632801
0.71875 3500 0.97 0.148031 1.34092 0.110394 0.1 0.007046757569628924
0.71875 3600 0.9948 0.118117 1.33894 0.0882168 0.1 0.00697663767172953
0.71875 3700 0.9996 0.115874 1.3388 0.0865507 0.1 0.006907215513185129
0.71875 3800 0.9918 0.114754 1.33751 0.0857964 0.1 0.00683848415102772
0.71875 3900 0.9878 0.147371 1.3364 0.110275 0.1 0.006770436711376421
0.71875 4000 0.9878 0.112943 1.33592 0.0845434 0.1 0.006703066388750011
0.71875 4100 0.9572 0.128398 1.3354 0.0961495 0.1 0.006636366445386311
0.71875 4200 0.98 0.123177 1.33288 0.0924143 0.1 0.006570330210568327
0.71875 4300 0.9654 0.125627 1.33454 0.0941349 0.1 0.006504951079957117
0.71875 4400 0.9936 0.164285 1.3335 0.123198 0.1 0.006440222514931274
0.71875 4500 0.9924 0.112767 1.33181 0.0846718 0.1 0.006376138041932989
# Train result: 0.71875 0.994371
# Test result: 0.71875 0.9938
# 45361 entries between 0.625 and 0.875
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
0.75 100 0.9886 0.626146 3.02784 0.206796 0.1 0.009900493386913728
0.75 200 0.978 0.435921 2.69117 0.161982 0.1 0.009801976930432239
0.75 300 0.9814 0.288732 2.54251 0.113562 0.1 0.00970444077784252
0.75 400 0.9868 0.235765 2.4169 0.0975484 0.1 0.009607875174472565
0.75 500 0.995 0.174373 2.28685 0.0762502 0.1 0.009512270462715812
0.75 600 0.9884 0.142469 2.15698 0.0660504 0.1 0.009417617081065264
0.75 700 0.9938 0.134093 2.03344 0.065944 0.1 0.009323905563157238
0.75 800 0.9826 0.141845 1.92551 0.0736663 0.1 0.009231126536824622
0.75 900 0.9834 0.134596 1.82851 0.0736098 0.1 0.009139270723159591
0.75 1000 0.976 0.142914 1.74593 0.0818553 0.1 0.009048328935585565
0.75 1100 0.9898 0.12219 1.67153 0.0731005 0.1 0.008958292078938489
0.75 1200 0.9952 0.0857493 1.60985 0.0532655 0.1 0.0088691511485572
0.75 1300 0.9876 0.139271 1.55844 0.0893657 0.1 0.008780897229382877
0.75 1400 0.9982 0.142739 1.51571 0.0941728 0.1 0.008693521495067419
0.75 1500 0.987 0.158591 1.47801 0.1073 0.1 0.008607015207090722
0.75 1600 0.9856 0.0980872 1.44445 0.0679063 0.1 0.008521369713886751
0.75 1700 0.9896 0.111795 1.4201 0.0787231 0.1 0.008436576449978266
0.75 1800 0.9984 0.133986 1.39825 0.0958241 0.1 0.008352626935120183
0.75 1900 0.9832 0.142748 1.38134 0.10334 0.1 0.008269512773451476
0.75 2000 0.9952 0.0981469 1.36418 0.0719457 0.1 0.008187225652655481
0.75 2100 0.9802 0.161406 1.35195 0.119387 0.1 0.008105757343128598
0.75 2200 0.9924 0.119276 1.34156 0.0889087 0.1 0.008025099697157206
0.75 2300 0.9834 0.11736 1.33382 0.0879878 0.1 0.007945244648102822
0.75 2400 0.9846 0.122977 1.32642 0.0927133 0.1 0.007866184209595362
0.75 2500 0.9782 0.143045 1.31755 0.108569 0.1 0.007787910474734398
0.75 2600 0.9906 0.125298 1.31425 0.0953382 0.1 0.007710415615298401
0.75 2700 0.9938 0.126585 1.30825 0.0967589 0.1 0.0076336918809618085
0.75 2800 0.9906 0.11878 1.3069 0.0908865 0.1 0.007557731598519933
0.75 2900 0.9946 0.108187 1.30235 0.0830705 0.1 0.007482527171121546
0.75 3000 0.98 0.118961 1.30005 0.0915049 0.1 0.007408071077509108
0.75 3100 0.9968 0.120045 1.29733 0.0925323 0.1 0.0073343558712665735
0.75 3200 0.9956 0.132204 1.29593 0.102015 0.1 0.007261374180074655
0.75 3300 0.9982 0.117849 1.29503 0.0910009 0.1 0.007189118704973517
0.75 3400 0.9982 0.145599 1.29067 0.112809 0.1 0.007117582219632801
0.75 3500 0.9828 0.130775 1.29141 0.101265 0.1 0.007046757569628924
0.75 3600 0.9988 0.139567 1.28924 0.108255 0.1 0.00697663767172953
0.75 3700 0.9938 0.0965814 1.28933 0.0749084 0.1 0.006907215513185129
0.75 3800 0.9716 0.134792 1.28855 0.104608 0.1 0.00683848415102772
0.75 3900 0.9946 0.0806415 1.28618 0.0626984 0.1 0.006770436711376421
0.75 4000 0.9934 0.149399 1.28601 0.116172 0.1 0.006703066388750011
0.75 4100 0.987 0.10572 1.28586 0.0822174 0.1 0.006636366445386311
0.75 4200 0.9806 0.107479 1.28627 0.0835589 0.1 0.006570330210568327
0.75 4300 0.993 0.133487 1.28296 0.104046 0.1 0.006504951079957117
0.75 4400 1.0 0.132236 1.28406 0.102982 0.1 0.006440222514931274
0.75 4500 0.9958 0.163615 1.28258 0.127567 0.1 0.006376138041932989
# Train result: 0.75 0.995475
# Test result: 0.75 0.9946
# 45361 entries between 0.65625 and 0.90625
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
0.78125 100 0.8636 0.587518 3.0492 0.19268 0.1 0.009900493386913728
0.78125 200 0.9746 0.359301 2.75423 0.130454 0.1 0.009801976930432239
0.78125 300 0.9758 0.251117 2.60005 0.0965815 0.1 0.00970444077784252
0.78125 400 0.9878 0.162961 2.44879 0.0665476 0.1 0.009607875174472565
0.78125 500 0.987 0.166315 2.29487 0.0724727 0.1 0.009512270462715812
0.78125 600 0.9876 0.153313 2.15049 0.0712923 0.1 0.009417617081065264
0.78125 700 0.9978 0.117586 2.01835 0.0582583 0.1 0.009323905563157238
0.78125 800 0.9902 0.130812 1.89922 0.0688771 0.1 0.009231126536824622
0.78125 900 0.9948 0.129378 1.79413 0.0721121 0.1 0.009139270723159591
0.78125 1000 0.9948 0.122868 1.70641 0.072004 0.1 0.009048328935585565
0.78125 1100 0.9948 0.129696 1.63332 0.0794065 0.1 0.008958292078938489
0.78125 1200 0.9974 0.12923 1.57016 0.0823034 0.1 0.0088691511485572
0.78125 1300 0.9758 0.108783 1.51408 0.0718479 0.1 0.008780897229382877
0.78125 1400 0.9884 0.14111 1.46728 0.0961714 0.1 0.008693521495067419
0.78125 1500 0.9864 0.0828143 1.43123 0.0578624 0.1 0.008607015207090722
0.78125 1600 0.9876 0.118934 1.40131 0.0848736 0.1 0.008521369713886751
0.78125 1700 0.983 0.126785 1.37454 0.0922378 0.1 0.008436576449978266
0.78125 1800 0.9958 0.138706 1.3504 0.102715 0.1 0.008352626935120183
0.78125 1900 0.9988 0.142034 1.33309 0.106545 0.1 0.008269512773451476
0.78125 2000 0.9918 0.119318 1.32023 0.090377 0.1 0.008187225652655481
0.78125 2100 0.9942 0.129026 1.30838 0.098615 0.1 0.008105757343128598
0.78125 2200 0.9952 0.104317 1.29526 0.080538 0.1 0.008025099697157206
0.78125 2300 0.9904 0.113715 1.28508 0.0884891 0.1 0.007945244648102822
0.78125 2400 0.9976 0.132591 1.2796 0.10362 0.1 0.007866184209595362
0.78125 2500 0.9926 0.161702 1.27476 0.126849 0.1 0.007787910474734398
0.78125 2600 0.994 0.127736 1.2693 0.100635 0.1 0.007710415615298401
0.78125 2700 0.9796 0.120769 1.26266 0.0956472 0.1 0.0076336918809618085
0.78125 2800 0.9904 0.114867 1.25959 0.0911934 0.1 0.007557731598519933
0.78125 2900 0.9854 0.112725 1.2592 0.0895213 0.1 0.007482527171121546
0.78125 3000 0.9788 0.129313 1.25698 0.102876 0.1 0.007408071077509108
0.78125 3100 0.998 0.135292 1.25218 0.108045 0.1 0.0073343558712665735
0.78125 3200 0.992 0.123413 1.24889 0.0988179 0.1 0.007261374180074655
0.78125 3300 0.991 0.115585 1.24912 0.092533 0.1 0.007189118704973517
0.78125 3400 0.9816 0.102189 1.24936 0.0817934 0.1 0.007117582219632801
0.78125 3500 0.9974 0.0918565 1.24707 0.073658 0.1 0.007046757569628924
0.78125 3600 0.9908 0.120664 1.24359 0.0970292 0.1 0.00697663767172953
0.78125 3700 0.9864 0.13115 1.24349 0.10547 0.1 0.006907215513185129
0.78125 3800 0.9794 0.149554 1.24519 0.120106 0.1 0.00683848415102772
0.78125 3900 0.985 0.134781 1.24502 0.108256 0.1 0.006770436711376421
0.78125 4000 0.998 0.145937 1.24145 0.117554 0.1 0.006703066388750011
0.78125 4100 0.9946 0.111106 1.23997 0.0896035 0.1 0.006636366445386311
0.78125 4200 0.9906 0.151186 1.24092 0.121834 0.1 0.006570330210568327
0.78125 4300 0.9892 0.13821 1.24238 0.111246 0.1 0.006504951079957117
0.78125 4400 0.9894 0.105703 1.24075 0.0851929 0.1 0.006440222514931274
0.78125 4500 0.9936 0.10351 1.23804 0.083608 0.1 0.006376138041932989
# Train result: 0.78125 0.986181
# Test result: 0.78125 0.9855
# 45361 entries between 0.6875 and 0.9375
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
0.8125 100 0.936 0.558869 3.07093 0.181987 0.1 0.009900493386913728
0.8125 200 0.9922 0.33585 2.79893 0.119992 0.1 0.009801976930432239
0.8125 300 0.9908 0.219658 2.62608 0.0836448 0.1 0.00970444077784252
0.8125 400 0.9942 0.170368 2.45685 0.0693442 0.1 0.009607875174472565
0.8125 500 0.9984 0.16929 2.28903 0.0739571 0.1 0.009512270462715812
0.8125 600 0.9922 0.119911 2.13396 0.0561918 0.1 0.009417617081065264
0.8125 700 0.988 0.138169 1.99214 0.069357 0.1 0.009323905563157238
0.8125 800 0.999 0.11883 1.8675 0.0636305 0.1 0.009231126536824622
0.8125 900 1.0 0.116557 1.76072 0.0661983 0.1 0.009139270723159591
0.8125 1000 0.9784 0.112045 1.66999 0.0670936 0.1 0.009048328935585565
0.8125 1100 0.9952 0.127137 1.59442 0.0797386 0.1 0.008958292078938489
0.8125 1200 0.9892 0.107963 1.52698 0.0707034 0.1 0.0088691511485572
0.8125 1300 0.9926 0.0906295 1.47154 0.0615883 0.1 0.008780897229382877
0.8125 1400 0.998 0.117006 1.42553 0.0820794 0.1 0.008693521495067419
0.8125 1500 0.9986 0.103816 1.38985 0.0746956 0.1 0.008607015207090722
0.8125 1600 0.9986 0.125561 1.35605 0.0925933 0.1 0.008521369713886751
0.8125 1700 0.989 0.103122 1.32893 0.0775973 0.1 0.008436576449978266
0.8125 1800 0.9922 0.130375 1.30629 0.0998053 0.1 0.008352626935120183
0.8125 1900 0.9846 0.131369 1.28736 0.102045 0.1 0.008269512773451476
0.8125 2000 0.9994 0.135998 1.27505 0.106661 0.1 0.008187225652655481
0.8125 2100 0.9992 0.142819 1.25953 0.113391 0.1 0.008105757343128598
0.8125 2200 0.9842 0.119724 1.24932 0.095832 0.1 0.008025099697157206
0.8125 2300 0.9864 0.108541 1.23928 0.0875837 0.1 0.007945244648102822
0.8125 2400 0.9976 0.112399 1.23514 0.0910014 0.1 0.007866184209595362
0.8125 2500 0.999 0.10773 1.22658 0.0878296 0.1 0.007787910474734398
0.8125 2600 0.995 0.0936211 1.2204 0.0767134 0.1 0.007710415615298401
0.8125 2700 0.9818 0.1089 1.21663 0.0895094 0.1 0.0076336918809618085
0.8125 2800 0.989 0.0790011 1.21145 0.065212 0.1 0.007557731598519933
0.8125 2900 0.9976 0.0937064 1.2114 0.0773539 0.1 0.007482527171121546
0.8125 3000 0.9764 0.109239 1.20669 0.0905282 0.1 0.007408071077509108
0.8125 3100 0.9894 0.0900611 1.20442 0.0747755 0.1 0.0073343558712665735
0.8125 3200 0.996 0.1403 1.20169 0.116752 0.1 0.007261374180074655
0.8125 3300 0.9892 0.0889787 1.20298 0.0739654 0.1 0.007189118704973517
0.8125 3400 0.9938 0.118159 1.19963 0.0984959 0.1 0.007117582219632801
0.8125 3500 0.9976 0.114859 1.19778 0.0958931 0.1 0.007046757569628924
0.8125 3600 0.9854 0.0843441 1.19634 0.0705019 0.1 0.00697663767172953
0.8125 3700 0.9884 0.107134 1.19464 0.0896791 0.1 0.006907215513185129
0.8125 3800 0.9952 0.123861 1.19681 0.103492 0.1 0.00683848415102772
0.8125 3900 0.9826 0.125369 1.19455 0.104951 0.1 0.006770436711376421
0.8125 4000 0.9766 0.132026 1.19322 0.110647 0.1 0.006703066388750011
0.8125 4100 0.9998 0.107738 1.19199 0.0903853 0.1 0.006636366445386311
0.8125 4200 0.9934 0.122408 1.19434 0.10249 0.1 0.006570330210568327
0.8125 4300 0.9892 0.124742 1.19221 0.104631 0.1 0.006504951079957117
0.8125 4400 0.9996 0.144584 1.19086 0.121411 0.1 0.006440222514931274
0.8125 4500 0.9816 0.11458 1.18993 0.0962914 0.1 0.006376138041932989
# Train result: 0.8125 0.994327
# Test result: 0.8125 0.995
# 45361 entries between 0.71875 and 0.96875
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
0.84375 100 0.93 0.524145 3.10773 0.168659 0.1 0.009900493386913728
0.84375 200 0.99 0.288688 2.85402 0.101151 0.1 0.009801976930432239
0.84375 300 0.994 0.195341 2.66041 0.0734253 0.1 0.00970444077784252
0.84375 400 0.9952 0.162572 2.46745 0.0658866 0.1 0.009607875174472565
0.84375 500 0.9914 0.14054 2.28033 0.0616315 0.1 0.009512270462715812
0.84375 600 0.9794 0.128024 2.11121 0.0606402 0.1 0.009417617081065264
0.84375 700 0.984 0.11126 1.95917 0.0567893 0.1 0.009323905563157238
0.84375 800 0.9872 0.138738 1.83413 0.0756424 0.1 0.009231126536824622
0.84375 900 0.9886 0.117094 1.72175 0.0680087 0.1 0.009139270723159591
0.84375 1000 0.9966 0.0909267 1.62637 0.0559076 0.1 0.009048328935585565
0.84375 1100 1.0 0.127558 1.54606 0.0825054 0.1 0.008958292078938489
0.84375 1200 0.998 0.132712 1.47947 0.0897025 0.1 0.0088691511485572
0.84375 1300 0.9968 0.10331 1.42584 0.0724558 0.1 0.008780897229382877
0.84375 1400 0.9878 0.114515 1.37713 0.0831551 0.1 0.008693521495067419
0.84375 1500 0.9968 0.113518 1.3373 0.0848864 0.1 0.008607015207090722
0.84375 1600 0.9962 0.139055 1.30169 0.106827 0.1 0.008521369713886751
0.84375 1700 0.9992 0.0943941 1.27961 0.073768 0.1 0.008436576449978266
0.84375 1800 0.9912 0.103957 1.25679 0.0827163 0.1 0.008352626935120183
0.84375 1900 0.9934 0.105076 1.23712 0.0849362 0.1 0.008269512773451476
0.84375 2000 0.9992 0.0959468 1.22157 0.0785437 0.1 0.008187225652655481
0.84375 2100 0.986 0.10648 1.20778 0.0881613 0.1 0.008105757343128598
0.84375 2200 0.9986 0.110611 1.2005 0.0921376 0.1 0.008025099697157206
0.84375 2300 0.9996 0.100924 1.18922 0.0848657 0.1 0.007945244648102822
0.84375 2400 0.9928 0.0948268 1.18127 0.0802754 0.1 0.007866184209595362
0.84375 2500 0.9968 0.123403 1.17224 0.105271 0.1 0.007787910474734398
0.84375 2600 0.996 0.0842435 1.17164 0.0719024 0.1 0.007710415615298401
0.84375 2700 0.997 0.08965 1.16695 0.0768242 0.1 0.0076336918809618085
0.84375 2800 0.993 0.121027 1.16243 0.104116 0.1 0.007557731598519933
0.84375 2900 0.9976 0.117389 1.1592 0.101267 0.1 0.007482527171121546
0.84375 3000 0.9848 0.124042 1.15539 0.107359 0.1 0.007408071077509108
0.84375 3100 0.9932 0.117305 1.15632 0.101447 0.1 0.0073343558712665735
0.84375 3200 0.9992 0.0992029 1.15175 0.0861325 0.1 0.007261374180074655
0.84375 3300 0.9932 0.128508 1.15012 0.111734 0.1 0.007189118704973517
0.84375 3400 0.9992 0.0974405 1.14568 0.0850503 0.1 0.007117582219632801
0.84375 3500 0.9922 0.107768 1.14919 0.0937772 0.1 0.007046757569628924
0.84375 3600 0.9958 0.0884323 1.14831 0.0770107 0.1 0.00697663767172953
0.84375 3700 0.9936 0.12697 1.14609 0.110786 0.1 0.006907215513185129
0.84375 3800 0.9966 0.115039 1.14495 0.100475 0.1 0.00683848415102772
0.84375 3900 0.995 0.112439 1.14299 0.0983724 0.1 0.006770436711376421
0.84375 4000 0.9848 0.10596 1.14549 0.0925017 0.1 0.006703066388750011
0.84375 4100 0.9968 0.106311 1.14317 0.0929963 0.1 0.006636366445386311
0.84375 4200 0.993 0.106421 1.14238 0.0931575 0.1 0.006570330210568327
0.84375 4300 0.9936 0.117505 1.13864 0.103197 0.1 0.006504951079957117
0.84375 4400 0.9902 0.0947933 1.14257 0.0829651 0.1 0.006440222514931274
0.84375 4500 1.0 0.111586 1.14302 0.097624 0.1 0.006376138041932989
# Train result: 0.84375 0.998212
# Test result: 0.84375 0.9983
# 45361 entries between 0.75 and 1.0
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
0.875 100 0.9948 0.488224 3.1085 0.157061 0.1 0.009900493386913728
0.875 200 0.9942 0.261331 2.85997 0.0913755 0.1 0.009801976930432239
0.875 300 0.9868 0.194014 2.65465 0.0730845 0.1 0.00970444077784252
0.875 400 0.9994 0.159651 2.44697 0.0652445 0.1 0.009607875174472565
0.875 500 0.998 0.116713 2.25334 0.0517955 0.1 0.009512270462715812
0.875 600 0.9992 0.125162 2.07566 0.0602998 0.1 0.009417617081065264
0.875 700 0.9936 0.10625 1.92272 0.0552602 0.1 0.009323905563157238
0.875 800 0.9964 0.15866 1.78959 0.0886573 0.1 0.009231126536824622
0.875 900 0.9956 0.107648 1.67697 0.064192 0.1 0.009139270723159591
0.875 1000 0.9962 0.100051 1.5802 0.0633154 0.1 0.009048328935585565
0.875 1100 0.9918 0.110565 1.49879 0.0737691 0.1 0.008958292078938489
0.875 1200 0.9972 0.0947166 1.43196 0.0661447 0.1 0.0088691511485572
0.875 1300 0.9848 0.106515 1.37502 0.0774643 0.1 0.008780897229382877
0.875 1400 0.9972 0.105902 1.32934 0.0796654 0.1 0.008693521495067419
0.875 1500 0.9966 0.0842951 1.28773 0.0654604 0.1 0.008607015207090722
0.875 1600 0.9982 0.116345 1.25651 0.0925933 0.1 0.008521369713886751
0.875 1700 0.9998 0.0952862 1.22802 0.0775933 0.1 0.008436576449978266
0.875 1800 0.9982 0.0835291 1.20742 0.0691798 0.1 0.008352626935120183
0.875 1900 0.999 0.122851 1.18799 0.103411 0.1 0.008269512773451476
0.875 2000 0.9982 0.115477 1.17216 0.0985162 0.1 0.008187225652655481
0.875 2100 0.9966 0.0938486 1.1598 0.0809177 0.1 0.008105757343128598
0.875 2200 0.9992 0.0977487 1.14928 0.0850519 0.1 0.008025099697157206
0.875 2300 0.9854 0.0988856 1.14179 0.0866056 0.1 0.007945244648102822
0.875 2400 0.996 0.0951369 1.13261 0.0839977 0.1 0.007866184209595362
0.875 2500 0.9966 0.11525 1.12646 0.102311 0.1 0.007787910474734398
0.875 2600 0.9994 0.104414 1.12075 0.0931647 0.1 0.007710415615298401
0.875 2700 0.9966 0.0790176 1.11833 0.0706566 0.1 0.0076336918809618085
0.875 2800 0.9982 0.0863959 1.11407 0.0775495 0.1 0.007557731598519933
0.875 2900 0.9988 0.076719 1.11023 0.0691019 0.1 0.007482527171121546
0.875 3000 0.9916 0.0933498 1.10832 0.0842265 0.1 0.007408071077509108
0.875 3100 0.9998 0.123699 1.1068 0.111763 0.1 0.0073343558712665735
0.875 3200 1.0 0.102519 1.10547 0.0927381 0.1 0.007261374180074655
0.875 3300 0.9934 0.0988126 1.1021 0.0896585 0.1 0.007189118704973517
0.875 3400 1.0 0.105474 1.10108 0.0957914 0.1 0.007117582219632801
0.875 3500 0.9974 0.0913544 1.09913 0.0831155 0.1 0.007046757569628924
0.875 3600 0.9938 0.0852632 1.10068 0.0774641 0.1 0.00697663767172953
0.875 3700 0.9868 0.115616 1.09963 0.105141 0.1 0.006907215513185129
0.875 3800 0.9972 0.0875253 1.09693 0.0797913 0.1 0.00683848415102772
0.875 3900 0.9974 0.103832 1.09672 0.0946753 0.1 0.006770436711376421
0.875 4000 0.9894 0.0999323 1.09677 0.0911148 0.1 0.006703066388750011
0.875 4100 0.9984 0.0863589 1.09638 0.0787673 0.1 0.006636366445386311
0.875 4200 0.9966 0.103333 1.09431 0.0944273 0.1 0.006570330210568327
0.875 4300 0.9918 0.0732211 1.09506 0.0668647 0.1 0.006504951079957117
0.875 4400 0.998 0.110183 1.09377 0.100737 0.1 0.006440222514931274
0.875 4500 0.9986 0.0973807 1.09562 0.0888822 0.1 0.006376138041932989
# Train result: 0.875 0.983091
# Test result: 0.875 0.9833
# 45361 entries between 0.78125 and 1.03125
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
0.90625 100 0.958 0.448341 3.10563 0.144364 0.1 0.009900493386913728
0.90625 200 0.9694 0.224818 2.86279 0.0785312 0.1 0.009801976930432239
0.90625 300 0.9958 0.195038 2.64334 0.0737844 0.1 0.00970444077784252
0.90625 400 0.987 0.12742 2.42549 0.052534 0.1 0.009607875174472565
0.90625 500 0.9978 0.0957388 2.22073 0.0431114 0.1 0.009512270462715812
0.90625 600 0.9996 0.144762 2.0369 0.0710699 0.1 0.009417617081065264
0.90625 700 0.995 0.133158 1.87976 0.0708375 0.1 0.009323905563157238
0.90625 800 0.9972 0.113989 1.74443 0.0653448 0.1 0.009231126536824622
0.90625 900 0.9928 0.105686 1.62726 0.0649471 0.1 0.009139270723159591
0.90625 1000 0.9996 0.112941 1.52941 0.073846 0.1 0.009048328935585565
0.90625 1100 0.9874 0.102312 1.44896 0.070611 0.1 0.008958292078938489
0.90625 1200 0.997 0.0778963 1.37926 0.0564768 0.1 0.0088691511485572
0.90625 1300 0.9988 0.137634 1.32277 0.104049 0.1 0.008780897229382877
0.90625 1400 0.997 0.0876415 1.27542 0.0687158 0.1 0.008693521495067419
0.90625 1500 0.998 0.0699921 1.23384 0.0567271 0.1 0.008607015207090722
0.90625 1600 0.9872 0.105711 1.20288 0.0878817 0.1 0.008521369713886751
0.90625 1700 0.9996 0.0818275 1.17602 0.0695798 0.1 0.008436576449978266
0.90625 1800 0.9974 0.0960132 1.15199 0.0833458 0.1 0.008352626935120183
0.90625 1900 0.995 0.0951592 1.13375 0.0839334 0.1 0.008269512773451476
0.90625 2000 0.9976 0.0963953 1.11935 0.0861176 0.1 0.008187225652655481
0.90625 2100 0.9978 0.10877 1.10552 0.0983881 0.1 0.008105757343128598
0.90625 2200 0.9904 0.084734 1.09633 0.077289 0.1 0.008025099697157206
0.90625 2300 0.9996 0.099948 1.08774 0.0918861 0.1 0.007945244648102822
0.90625 2400 0.9988 0.103031 1.07729 0.0956389 0.1 0.007866184209595362
0.90625 2500 0.9948 0.0962616 1.07321 0.0896949 0.1 0.007787910474734398
0.90625 2600 0.9972 0.0925193 1.069 0.0865475 0.1 0.007710415615298401
0.90625 2700 0.9958 0.0838593 1.06366 0.0788401 0.1 0.0076336918809618085
0.90625 2800 0.989 0.0933311 1.0602 0.0880318 0.1 0.007557731598519933
0.90625 2900 0.9966 0.117712 1.05755 0.111306 0.1 0.007482527171121546
0.90625 3000 0.9998 0.0885187 1.05446 0.083947 0.1 0.007408071077509108
0.90625 3100 0.9944 0.0969058 1.05372 0.0919652 0.1 0.0073343558712665735
0.90625 3200 0.9946 0.0922059 1.0518 0.0876646 0.1 0.007261374180074655
0.90625 3300 0.995 0.066968 1.04712 0.0639543 0.1 0.007189118704973517
0.90625 3400 0.9998 0.10091 1.04781 0.0963061 0.1 0.007117582219632801
0.90625 3500 0.9888 0.106554 1.0478 0.101693 0.1 0.007046757569628924
0.90625 3600 0.9998 0.0931224 1.0451 0.0891035 0.1 0.00697663767172953
0.90625 3700 0.9918 0.0867266 1.04462 0.0830226 0.1 0.006907215513185129
0.90625 3800 0.9976 0.098063 1.04447 0.0938875 0.1 0.00683848415102772
0.90625 3900 0.9996 0.0919181 1.04337 0.0880973 0.1 0.006770436711376421
0.90625 4000 0.988 0.0890537 1.04455 0.0852558 0.1 0.006703066388750011
0.90625 4100 0.9976 0.098581 1.04345 0.0944761 0.1 0.006636366445386311
0.90625 4200 0.997 0.100213 1.04038 0.0963234 0.1 0.006570330210568327
0.90625 4300 0.9958 0.0931036 1.0421 0.0893421 0.1 0.006504951079957117
0.90625 4400 0.9982 0.0810811 1.04256 0.0777711 0.1 0.006440222514931274
0.90625 4500 0.9974 0.0871511 1.04085 0.0837307 0.1 0.006376138041932989
# Train result: 0.90625 0.993201
# Test result: 0.90625 0.9926
# 45361 entries between 0.8125 and 1.0625
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
0.9375 100 0.9614 0.413702 3.14974 0.131345 0.1 0.009900493386913728
0.9375 200 0.9856 0.213628 2.89903 0.0736897 0.1 0.009801976930432239
0.9375 300 0.9914 0.15697 2.65725 0.0590721 0.1 0.00970444077784252
0.9375 400 0.9926 0.121169 2.42213 0.0500256 0.1 0.009607875174472565
0.9375 500 0.9974 0.1303 2.20654 0.0590518 0.1 0.009512270462715812
0.9375 600 0.9922 0.106003 2.01698 0.0525555 0.1 0.009417617081065264
0.9375 700 0.9988 0.0917999 1.85325 0.0495347 0.1 0.009323905563157238
0.9375 800 0.9998 0.104342 1.71069 0.0609942 0.1 0.009231126536824622
0.9375 900 0.991 0.103741 1.59095 0.0652072 0.1 0.009139270723159591
0.9375 1000 0.9992 0.105628 1.49078 0.0708543 0.1 0.009048328935585565
0.9375 1100 0.9996 0.100896 1.40856 0.0716306 0.1 0.008958292078938489
0.9375 1200 0.9998 0.0950755 1.33831 0.0710414 0.1 0.0088691511485572
0.9375 1300 0.9936 0.089966 1.27892 0.0703455 0.1 0.008780897229382877
0.9375 1400 0.9928 0.0999341 1.23083 0.0811926 0.1 0.008693521495067419
0.9375 1500 0.9962 0.066417 1.19009 0.0558081 0.1 0.008607015207090722
0.9375 1600 0.992 0.0883451 1.15871 0.0762442 0.1 0.008521369713886751
0.9375 1700 0.9972 0.0774361 1.12942 0.0685625 0.1 0.008436576449978266
0.9375 1800 0.9986 0.0870384 1.10583 0.0787084 0.1 0.008352626935120183
0.9375 1900 0.9984 0.0969054 1.08671 0.0891735 0.1 0.008269512773451476
0.9375 2000 0.9956 0.0899908 1.07339 0.0838381 0.1 0.008187225652655481
0.9375 2100 0.9932 0.0911338 1.06063 0.0859246 0.1 0.008105757343128598
0.9375 2200 0.9932 0.0994084 1.0478 0.0948731 0.1 0.008025099697157206
0.9375 2300 0.9914 0.100219 1.03921 0.0964381 0.1 0.007945244648102822
0.9375 2400 0.9946 0.0810596 1.03209 0.0785392 0.1 0.007866184209595362
0.9375 2500 0.9956 0.0771225 1.02703 0.0750924 0.1 0.007787910474734398
0.9375 2600 0.9932 0.0903497 1.0208 0.0885091 0.1 0.007710415615298401
0.9375 2700 0.9994 0.103726 1.01574 0.102118 0.1 0.0076336918809618085
0.9375 2800 0.993 0.0987765 1.01171 0.0976333 0.1 0.007557731598519933
0.9375 2900 0.9994 0.0806412 1.01111 0.0797555 0.1 0.007482527171121546
0.9375 3000 0.9984 0.112515 1.00852 0.111565 0.1 0.007408071077509108
0.9375 3100 0.9976 0.0841094 1.00506 0.083686 0.1 0.0073343558712665735
0.9375 3200 0.9944 0.100858 1.00361 0.100495 0.1 0.007261374180074655
0.9375 3300 0.9976 0.07037 1.00179 0.0702439 0.1 0.007189118704973517
0.9375 3400 0.9956 0.0701414 1.00248 0.0699679 0.1 0.007117582219632801
0.9375 3500 1.0 0.0900196 0.999852 0.090033 0.1 0.007046757569628924
0.9375 3600 1.0 0.0898958 0.999197 0.0899681 0.1 0.00697663767172953
0.9375 3700 0.9976 0.0949748 0.997131 0.095248 0.1 0.006907215513185129
0.9375 3800 0.9944 0.0938065 0.998344 0.0939621 0.1 0.00683848415102772
0.9375 3900 0.9928 0.0988691 0.99846 0.0990216 0.1 0.006770436711376421
0.9375 4000 0.999 0.0604149 0.996413 0.0606324 0.1 0.006703066388750011
0.9375 4100 0.9928 0.0904103 0.995803 0.0907913 0.1 0.006636366445386311
0.9375 4200 0.9936 0.0877052 0.995894 0.0880669 0.1 0.006570330210568327
0.9375 4300 0.988 0.100225 0.997792 0.100447 0.1 0.006504951079957117
0.9375 4400 0.999 0.0706891 0.995965 0.0709755 0.1 0.006440222514931274
0.9375 4500 0.9936 0.101551 0.995012 0.10206 0.1 0.006376138041932989
# Train result: 0.9375 0.995166
# Test result: 0.9375 0.9948
# 45361 entries between 0.84375 and 1.09375
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
0.96875 100 0.9844 0.349355 3.17355 0.110083 0.1 0.009900493386913728
0.96875 200 0.986 0.190294 2.91553 0.065269 0.1 0.009801976930432239
0.96875 300 0.9978 0.132138 2.65923 0.0496903 0.1 0.00970444077784252
0.96875 400 0.9964 0.104798 2.41295 0.0434313 0.1 0.009607875174472565
0.96875 500 0.9906 0.104356 2.18873 0.0476789 0.1 0.009512270462715812
0.96875 600 0.9936 0.107468 1.99374 0.0539026 0.1 0.009417617081065264
0.96875 700 0.997 0.0904743 1.82401 0.0496019 0.1 0.009323905563157238
0.96875 800 0.996 0.0912657 1.68227 0.0542515 0.1 0.009231126536824622
0.96875 900 0.998 0.0812366 1.56122 0.0520339 0.1 0.009139270723159591
0.96875 1000 0.9956 0.0803336 1.45769 0.0551102 0.1 0.009048328935585565
0.96875 1100 0.9948 0.0804337 1.37357 0.058558 0.1 0.008958292078938489
0.96875 1200 0.9984 0.100433 1.3035 0.0770486 0.1 0.0088691511485572
0.96875 1300 0.9998 0.092613 1.24475 0.0744032 0.1 0.008780897229382877
0.96875 1400 0.9954 0.074195 1.19514 0.0620808 0.1 0.008693521495067419
0.96875 1500 0.993 0.0821971 1.1547 0.071185 0.1 0.008607015207090722
0.96875 1600 0.998 0.0723559 1.12038 0.0645815 0.1 0.008521369713886751
0.96875 1700 0.9984 0.0703376 1.09413 0.0642864 0.1 0.008436576449978266
0.96875 1800 0.9994 0.0921529 1.07177 0.0859824 0.1 0.008352626935120183
0.96875 1900 0.9942 0.0915984 1.05072 0.0871768 0.1 0.008269512773451476
0.96875 2000 0.996 0.0833922 1.03608 0.0804879 0.1 0.008187225652655481
0.96875 2100 0.9992 0.10729 1.02381 0.104796 0.1 0.008105757343128598
0.96875 2200 0.9964 0.0835317 1.01318 0.0824448 0.1 0.008025099697157206
0.96875 2300 0.9962 0.0810683 1.00323 0.0808076 0.1 0.007945244648102822
0.96875 2400 0.9932 0.0769799 0.99538 0.0773372 0.1 0.007866184209595362
0.96875 2500 0.9992 0.0777763 0.988529 0.0786788 0.1 0.007787910474734398
0.96875 2600 0.9998 0.0800193 0.984947 0.0812422 0.1 0.007710415615298401
0.96875 2700 0.9978 0.0937007 0.980956 0.0955198 0.1 0.0076336918809618085
0.96875 2800 0.9956 0.0685522 0.975928 0.0702431 0.1 0.007557731598519933
0.96875 2900 0.9978 0.0905111 0.974325 0.0928962 0.1 0.007482527171121546
0.96875 3000 0.9998 0.0837447 0.972292 0.0861312 0.1 0.007408071077509108
0.96875 3100 0.9956 0.0821837 0.970386 0.0846918 0.1 0.0073343558712665735
0.96875 3200 0.998 0.0829148 0.967734 0.0856794 0.1 0.007261374180074655
0.96875 3300 0.996 0.0876087 0.964747 0.0908101 0.1 0.007189118704973517
0.96875 3400 0.9978 0.0725789 0.963679 0.0753144 0.1 0.007117582219632801
0.96875 3500 0.9994 0.0900912 0.964398 0.093417 0.1 0.007046757569628924
0.96875 3600 0.9986 0.0981055 0.963076 0.101867 0.1 0.00697663767172953
0.96875 3700 0.9992 0.0880897 0.961384 0.0916281 0.1 0.006907215513185129
0.96875 3800 0.997 0.0950218 0.961855 0.0987901 0.1 0.00683848415102772
0.96875 3900 0.998 0.108893 0.961834 0.113214 0.1 0.006770436711376421
0.96875 4000 0.9954 0.0754779 0.961778 0.0784774 0.1 0.006703066388750011
0.96875 4100 0.9956 0.0917844 0.961125 0.0954969 0.1 0.006636366445386311
0.96875 4200 0.9978 0.0887897 0.958973 0.0925883 0.1 0.006570330210568327
0.96875 4300 0.9978 0.0866111 0.958071 0.0904015 0.1 0.006504951079957117
0.96875 4400 0.9992 0.0808548 0.95964 0.0842554 0.1 0.006440222514931274
0.96875 4500 0.9948 0.0981081 0.958835 0.10232 0.1 0.006376138041932989
# Train result: 0.96875 0.998256
# Test result: 0.96875 0.9987
# 45361 entries between 0.875 and 1.125
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
1.0 100 0.9978 0.355044 3.20634 0.110732 0.1 0.009900493386913728
1.0 200 0.9948 0.188134 2.93888 0.0640155 0.1 0.009801976930432239
1.0 300 0.9996 0.111914 2.66908 0.0419298 0.1 0.00970444077784252
1.0 400 0.9998 0.0991885 2.40963 0.0411633 0.1 0.009607875174472565
1.0 500 0.996 0.110604 2.18037 0.0507271 0.1 0.009512270462715812
1.0 600 0.9974 0.0914883 1.9802 0.0462016 0.1 0.009417617081065264
1.0 700 0.9998 0.092026 1.8078 0.050905 0.1 0.009323905563157238
1.0 800 0.9958 0.100145 1.66102 0.0602912 0.1 0.009231126536824622
1.0 900 0.996 0.0998896 1.53756 0.0649665 0.1 0.009139270723159591
1.0 1000 0.9974 0.0945581 1.43475 0.0659057 0.1 0.009048328935585565
1.0 1100 0.9978 0.067233 1.34982 0.0498088 0.1 0.008958292078938489
1.0 1200 0.995 0.074032 1.27948 0.0578613 0.1 0.0088691511485572
1.0 1300 0.9994 0.0654694 1.21817 0.0537439 0.1 0.008780897229382877
1.0 1400 0.9992 0.0709776 1.16998 0.0606655 0.1 0.008693521495067419
1.0 1500 0.9986 0.0823947 1.12979 0.0729294 0.1 0.008607015207090722
1.0 1600 0.995 0.0848189 1.09673 0.0773376 0.1 0.008521369713886751
1.0 1700 0.9992 0.0941891 1.06839 0.0881595 0.1 0.008436576449978266
1.0 1800 0.9954 0.116804 1.04485 0.11179 0.1 0.008352626935120183
1.0 1900 0.9964 0.0748348 1.0256 0.0729668 0.1 0.008269512773451476
1.0 2000 0.9952 0.0724792 1.01092 0.0716963 0.1 0.008187225652655481
1.0 2100 0.9998 0.0713167 0.998785 0.0714034 0.1 0.008105757343128598
1.0 2200 0.9974 0.0939845 0.985859 0.0953327 0.1 0.008025099697157206
1.0 2300 0.9998 0.0754227 0.978219 0.077102 0.1 0.007945244648102822
1.0 2400 0.9988 0.111354 0.970622 0.114724 0.1 0.007866184209595362
1.0 2500 0.9976 0.0981803 0.965313 0.101708 0.1 0.007787910474734398
1.0 2600 0.9996 0.0810711 0.960117 0.0844387 0.1 0.007710415615298401
1.0 2700 0.995 0.105694 0.955536 0.110613 0.1 0.0076336918809618085
1.0 2800 0.9966 0.070815 0.951224 0.0744462 0.1 0.007557731598519933
1.0 2900 1.0 0.0839465 0.950445 0.0883234 0.1 0.007482527171121546
1.0 3000 0.9996 0.0882172 0.948123 0.093044 0.1 0.007408071077509108
1.0 3100 0.9974 0.054166 0.943511 0.057409 0.1 0.0073343558712665735
1.0 3200 0.9968 0.0761055 0.943109 0.0806964 0.1 0.007261374180074655
1.0 3300 0.9978 0.0638623 0.941661 0.0678188 0.1 0.007189118704973517
1.0 3400 0.9998 0.074969 0.941227 0.0796503 0.1 0.007117582219632801
1.0 3500 1.0 0.0943961 0.940369 0.100382 0.1 0.007046757569628924
1.0 3600 0.9932 0.0919361 0.938966 0.0979121 0.1 0.00697663767172953
1.0 3700 0.9992 0.057847 0.937747 0.0616872 0.1 0.006907215513185129
1.0 3800 0.9968 0.090841 0.938986 0.0967437 0.1 0.00683848415102772
1.0 3900 0.998 0.0525698 0.93831 0.0560261 0.1 0.006770436711376421
1.0 4000 0.9998 0.0637225 0.93646 0.0680462 0.1 0.006703066388750011
1.0 4100 0.9978 0.0877176 0.936071 0.0937083 0.1 0.006636366445386311
1.0 4200 0.9952 0.0899047 0.936322 0.0960191 0.1 0.006570330210568327
1.0 4300 1.0 0.0803894 0.936469 0.085843 0.1 0.006504951079957117
1.0 4400 0.9954 0.0852464 0.936787 0.0909987 0.1 0.006440222514931274
1.0 4500 0.9968 0.0678736 0.935382 0.0725625 0.1 0.006376138041932989
# Train result: 1.0 0.99936
# Test result: 1.0 0.9995
# 45361 entries between 0.90625 and 1.15625
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
1.03125 100 0.9906 0.308609 3.19505 0.0965897 0.1 0.009900493386913728
1.03125 200 0.998 0.171859 2.92879 0.0586791 0.1 0.009801976930432239
1.03125 300 0.9988 0.110231 2.654 0.0415339 0.1 0.00970444077784252
1.03125 400 0.9994 0.118351 2.39699 0.0493748 0.1 0.009607875174472565
1.03125 500 1.0 0.117346 2.16756 0.0541373 0.1 0.009512270462715812
1.03125 600 0.9988 0.0884734 1.96868 0.0449404 0.1 0.009417617081065264
1.03125 700 0.998 0.0974269 1.7969 0.0542196 0.1 0.009323905563157238
1.03125 800 0.9976 0.0765253 1.65068 0.0463598 0.1 0.009231126536824622
1.03125 900 0.996 0.0857033 1.52984 0.056021 0.1 0.009139270723159591
1.03125 1000 0.9988 0.0632374 1.42981 0.0442278 0.1 0.009048328935585565
1.03125 1100 0.9982 0.0819976 1.3433 0.0610417 0.1 0.008958292078938489
1.03125 1200 0.9986 0.0485806 1.27217 0.0381873 0.1 0.0088691511485572
1.03125 1300 1.0 0.0896068 1.21456 0.0737774 0.1 0.008780897229382877
1.03125 1400 0.998 0.0810286 1.16601 0.0694925 0.1 0.008693521495067419
1.03125 1500 0.998 0.0984989 1.12725 0.0873794 0.1 0.008607015207090722
1.03125 1600 0.9976 0.11419 1.09356 0.104421 0.1 0.008521369713886751
1.03125 1700 0.9958 0.0913063 1.06446 0.0857773 0.1 0.008436576449978266
1.03125 1800 0.9976 0.102451 1.04243 0.0982803 0.1 0.008352626935120183
1.03125 1900 0.9976 0.0761584 1.02534 0.0742762 0.1 0.008269512773451476
1.03125 2000 0.9972 0.10896 1.00894 0.107995 0.1 0.008187225652655481
1.03125 2100 0.9998 0.0931287 0.995578 0.0935423 0.1 0.008105757343128598
1.03125 2200 0.9978 0.0706098 0.984857 0.0716955 0.1 0.008025099697157206
1.03125 2300 0.9988 0.0775897 0.976312 0.0794723 0.1 0.007945244648102822
1.03125 2400 0.9948 0.100791 0.97087 0.103816 0.1 0.007866184209595362
1.03125 2500 1.0 0.0731174 0.963498 0.0758874 0.1 0.007787910474734398
1.03125 2600 0.9968 0.0855411 0.957097 0.0893756 0.1 0.007710415615298401
1.03125 2700 0.9952 0.0860728 0.95386 0.0902363 0.1 0.0076336918809618085
1.03125 2800 0.9994 0.0801349 0.95207 0.0841691 0.1 0.007557731598519933
1.03125 2900 0.998 0.0699051 0.948328 0.073714 0.1 0.007482527171121546
1.03125 3000 0.9992 0.0807874 0.945426 0.0854508 0.1 0.007408071077509108
1.03125 3100 0.9988 0.0756264 0.943228 0.0801783 0.1 0.0073343558712665735
1.03125 3200 0.9984 0.0819613 0.941494 0.0870545 0.1 0.007261374180074655
1.03125 3300 0.9976 0.0935058 0.942034 0.0992595 0.1 0.007189118704973517
1.03125 3400 0.9982 0.0653496 0.939314 0.0695716 0.1 0.007117582219632801
1.03125 3500 0.9992 0.0888681 0.937322 0.0948107 0.1 0.007046757569628924
1.03125 3600 0.9988 0.0767783 0.937292 0.081915 0.1 0.00697663767172953
1.03125 3700 0.9988 0.0862205 0.937887 0.0919306 0.1 0.006907215513185129
1.03125 3800 0.998 0.0736663 0.93679 0.0786369 0.1 0.00683848415102772
1.03125 3900 0.9994 0.0988929 0.936188 0.105634 0.1 0.006770436711376421
1.03125 4000 0.9998 0.0674726 0.934845 0.0721751 0.1 0.006703066388750011
1.03125 4100 0.9962 0.0962083 0.935342 0.102859 0.1 0.006636366445386311
1.03125 4200 0.998 0.0819479 0.936353 0.0875182 0.1 0.006570330210568327
1.03125 4300 0.9964 0.0753097 0.934798 0.0805626 0.1 0.006504951079957117
1.03125 4400 0.9976 0.0837481 0.93274 0.0897871 0.1 0.006440222514931274
1.03125 4500 0.9976 0.0975393 0.933765 0.104458 0.1 0.006376138041932989
# Train result: 1.03125 0.997638
# Test result: 1.03125 0.9982
# 45361 entries between 0.9375 and 1.1875
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
1.0625 100 0.98 0.353149 3.17601 0.111193 0.1 0.009900493386913728
1.0625 200 0.9924 0.20362 2.91852 0.0697682 0.1 0.009801976930432239
1.0625 300 0.9936 0.166914 2.65628 0.0628376 0.1 0.00970444077784252
1.0625 400 0.9976 0.11315 2.40279 0.0470909 0.1 0.009607875174472565
1.0625 500 0.9946 0.113612 2.17922 0.0521343 0.1 0.009512270462715812
1.0625 600 0.999 0.0920774 1.98133 0.0464724 0.1 0.009417617081065264
1.0625 700 0.9982 0.0932731 1.81518 0.0513851 0.1 0.009323905563157238
1.0625 800 0.9926 0.0771415 1.6695 0.0462062 0.1 0.009231126536824622
1.0625 900 0.998 0.0810472 1.5472 0.052383 0.1 0.009139270723159591
1.0625 1000 0.9972 0.0771605 1.44782 0.0532942 0.1 0.009048328935585565
1.0625 1100 0.9974 0.0869363 1.36466 0.0637055 0.1 0.008958292078938489
1.0625 1200 0.9972 0.0865719 1.29418 0.0668932 0.1 0.0088691511485572
1.0625 1300 0.9968 0.0956746 1.23271 0.0776135 0.1 0.008780897229382877
1.0625 1400 1.0 0.107112 1.18558 0.0903453 0.1 0.008693521495067419
1.0625 1500 0.9978 0.0691439 1.14474 0.0604013 0.1 0.008607015207090722
1.0625 1600 0.9982 0.0810834 1.11473 0.0727381 0.1 0.008521369713886751
1.0625 1700 0.996 0.0871318 1.08531 0.0802825 0.1 0.008436576449978266
1.0625 1800 1.0 0.0993193 1.06059 0.0936454 0.1 0.008352626935120183
1.0625 1900 0.9968 0.1174 1.04456 0.112392 0.1 0.008269512773451476
1.0625 2000 0.9996 0.0793001 1.02936 0.0770381 0.1 0.008187225652655481
1.0625 2100 0.9926 0.0813446 1.01733 0.0799589 0.1 0.008105757343128598
1.0625 2200 1.0 0.0959787 1.00298 0.0956933 0.1 0.008025099697157206
1.0625 2300 0.9958 0.0799254 0.995253 0.0803066 0.1 0.007945244648102822
1.0625 2400 0.9996 0.0751484 0.987862 0.0760718 0.1 0.007866184209595362
1.0625 2500 0.9968 0.110486 0.984489 0.112226 0.1 0.007787910474734398
1.0625 2600 0.9942 0.0813749 0.978445 0.0831676 0.1 0.007710415615298401
1.0625 2700 0.999 0.0732837 0.971517 0.0754323 0.1 0.0076336918809618085
1.0625 2800 0.9972 0.0752014 0.970487 0.0774883 0.1 0.007557731598519933
1.0625 2900 0.997 0.0859791 0.968176 0.0888052 0.1 0.007482527171121546
1.0625 3000 0.9976 0.068868 0.967142 0.0712078 0.1 0.007408071077509108
1.0625 3100 0.9972 0.0824309 0.961581 0.0857243 0.1 0.0073343558712665735
1.0625 3200 0.9926 0.0977348 0.960016 0.101805 0.1 0.007261374180074655
1.0625 3300 0.9984 0.0820886 0.959112 0.0855881 0.1 0.007189118704973517
1.0625 3400 0.9986 0.104742 0.959985 0.109108 0.1 0.007117582219632801
1.0625 3500 0.9942 0.0782247 0.958328 0.0816262 0.1 0.007046757569628924
1.0625 3600 0.9996 0.0816602 0.955392 0.085473 0.1 0.00697663767172953
1.0625 3700 0.996 0.0965458 0.956288 0.100959 0.1 0.006907215513185129
1.0625 3800 0.9972 0.0743879 0.955588 0.0778451 0.1 0.00683848415102772
1.0625 3900 0.993 0.0866729 0.95731 0.0905379 0.1 0.006770436711376421
1.0625 4000 0.9958 0.0949977 0.953601 0.0996199 0.1 0.006703066388750011
1.0625 4100 0.9992 0.104018 0.953014 0.109147 0.1 0.006636366445386311
1.0625 4200 0.9982 0.0773878 0.952949 0.0812087 0.1 0.006570330210568327
1.0625 4300 0.9946 0.0856153 0.955116 0.0896387 0.1 0.006504951079957117
1.0625 4400 0.9926 0.0685736 0.954662 0.0718302 0.1 0.006440222514931274
1.0625 4500 0.9982 0.0614898 0.951886 0.0645979 0.1 0.006376138041932989
# Train result: 1.0625 0.997748
# Test result: 1.0625 0.9979
# 45361 entries between 0.96875 and 1.21875
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
1.09375 100 0.9832 0.38044 3.17152 0.119955 0.1 0.009900493386913728
1.09375 200 0.9842 0.191587 2.91772 0.0656633 0.1 0.009801976930432239
1.09375 300 0.9986 0.111284 2.66628 0.0417377 0.1 0.00970444077784252
1.09375 400 0.992 0.102456 2.42203 0.0423015 0.1 0.009607875174472565
1.09375 500 0.9914 0.112576 2.199 0.0511944 0.1 0.009512270462715812
1.09375 600 0.9996 0.0918807 2.00691 0.0457822 0.1 0.009417617081065264
1.09375 700 0.9964 0.0752878 1.84014 0.0409142 0.1 0.009323905563157238
1.09375 800 1.0 0.108057 1.69984 0.0635687 0.1 0.009231126536824622
1.09375 900 0.9958 0.0806082 1.57834 0.0510716 0.1 0.009139270723159591
1.09375 1000 0.9908 0.0850325 1.47763 0.0575465 0.1 0.009048328935585565
1.09375 1100 0.9936 0.0889031 1.39486 0.0637361 0.1 0.008958292078938489
1.09375 1200 0.9936 0.105854 1.32566 0.0798502 0.1 0.0088691511485572
1.09375 1300 0.997 0.0914025 1.26813 0.0720765 0.1 0.008780897229382877
1.09375 1400 0.9986 0.0666873 1.2172 0.0547876 0.1 0.008693521495067419
1.09375 1500 0.9958 0.0817012 1.17891 0.0693026 0.1 0.008607015207090722
1.09375 1600 0.9996 0.0871392 1.14604 0.0760351 0.1 0.008521369713886751
1.09375 1700 0.9986 0.105294 1.12041 0.0939783 0.1 0.008436576449978266
1.09375 1800 0.9978 0.0945059 1.09638 0.0861982 0.1 0.008352626935120183
1.09375 1900 0.998 0.0764378 1.07709 0.0709666 0.1 0.008269512773451476
1.09375 2000 0.9918 0.0707049 1.06356 0.0664792 0.1 0.008187225652655481
1.09375 2100 0.9958 0.0757137 1.05091 0.0720462 0.1 0.008105757343128598
1.09375 2200 0.9956 0.0846333 1.04088 0.081309 0.1 0.008025099697157206
1.09375 2300 0.9958 0.0769637 1.02939 0.0747663 0.1 0.007945244648102822
1.09375 2400 0.9996 0.103628 1.02354 0.101244 0.1 0.007866184209595362
1.09375 2500 0.9988 0.0727173 1.01794 0.0714359 0.1 0.007787910474734398
1.09375 2600 0.9988 0.0855576 1.01476 0.0843135 0.1 0.007710415615298401
1.09375 2700 0.9986 0.0982982 1.00923 0.0973993 0.1 0.0076336918809618085
1.09375 2800 0.9996 0.0782684 1.0049 0.0778864 0.1 0.007557731598519933
1.09375 2900 0.9918 0.0911126 1.00422 0.09073 0.1 0.007482527171121546
1.09375 3000 0.9918 0.0667951 1.00128 0.06671 0.1 0.007408071077509108
1.09375 3100 0.9918 0.0927139 0.999346 0.0927746 0.1 0.0073343558712665735
1.09375 3200 0.9928 0.118417 0.995921 0.118902 0.1 0.007261374180074655
1.09375 3300 0.9974 0.0642858 0.996064 0.0645399 0.1 0.007189118704973517
1.09375 3400 0.9996 0.0817654 0.994918 0.082183 0.1 0.007117582219632801
1.09375 3500 0.9982 0.0771687 0.994895 0.0775647 0.1 0.007046757569628924
1.09375 3600 0.9994 0.0875444 0.993563 0.0881115 0.1 0.00697663767172953
1.09375 3700 0.9956 0.1157 0.991652 0.116674 0.1 0.006907215513185129
1.09375 3800 0.993 0.0990112 0.992794 0.0997298 0.1 0.00683848415102772
1.09375 3900 0.9936 0.069112 0.99212 0.0696609 0.1 0.006770436711376421
1.09375 4000 0.9944 0.0608894 0.991761 0.0613953 0.1 0.006703066388750011
1.09375 4100 0.9934 0.0742103 0.989494 0.0749982 0.1 0.006636366445386311
1.09375 4200 0.9918 0.106966 0.990727 0.107968 0.1 0.006570330210568327
1.09375 4300 0.9956 0.0878408 0.990955 0.0886426 0.1 0.006504951079957117
1.09375 4400 0.9978 0.0875893 0.991082 0.0883774 0.1 0.006440222514931274
1.09375 4500 0.9986 0.141354 0.990593 0.142697 0.1 0.006376138041932989
# Train result: 1.09375 0.997483
# Test result: 1.09375 0.9973
# 45361 entries between 1.0 and 1.25
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
1.125 100 0.9516 0.442192 3.1459 0.140562 0.1 0.009900493386913728
1.125 200 0.9832 0.230207 2.89652 0.0794773 0.1 0.009801976930432239
1.125 300 0.9818 0.152248 2.6705 0.057011 0.1 0.00970444077784252
1.125 400 0.9872 0.123899 2.44771 0.0506183 0.1 0.009607875174472565
1.125 500 0.9958 0.120075 2.23984 0.0536089 0.1 0.009512270462715812
1.125 600 0.9984 0.118341 2.05443 0.0576026 0.1 0.009417617081065264
1.125 700 0.998 0.107056 1.89332 0.0565442 0.1 0.009323905563157238
1.125 800 0.9936 0.0792728 1.75585 0.0451478 0.1 0.009231126536824622
1.125 900 0.9986 0.10015 1.63949 0.061086 0.1 0.009139270723159591
1.125 1000 0.9938 0.115881 1.53981 0.0752563 0.1 0.009048328935585565
1.125 1100 0.9986 0.0931741 1.45782 0.0639134 0.1 0.008958292078938489
1.125 1200 0.986 0.0904602 1.38766 0.0651891 0.1 0.0088691511485572
1.125 1300 0.9962 0.0853006 1.33013 0.0641293 0.1 0.008780897229382877
1.125 1400 0.9982 0.0989474 1.28253 0.0771499 0.1 0.008693521495067419
1.125 1500 0.9964 0.110841 1.24088 0.0893245 0.1 0.008607015207090722
1.125 1600 0.9936 0.069923 1.20842 0.0578634 0.1 0.008521369713886751
1.125 1700 0.9846 0.0779182 1.18142 0.0659532 0.1 0.008436576449978266
1.125 1800 0.9932 0.093086 1.15929 0.0802956 0.1 0.008352626935120183
1.125 1900 0.9936 0.105479 1.13883 0.0926205 0.1 0.008269512773451476
1.125 2000 0.9932 0.119825 1.12498 0.106513 0.1 0.008187225652655481
1.125 2100 0.9976 0.118529 1.11016 0.106767 0.1 0.008105757343128598
1.125 2200 0.9918 0.0764625 1.1003 0.0694925 0.1 0.008025099697157206
1.125 2300 0.9998 0.0979817 1.09147 0.0897704 0.1 0.007945244648102822
1.125 2400 0.991 0.0600163 1.08219 0.0554581 0.1 0.007866184209595362
1.125 2500 0.9934 0.101328 1.07706 0.0940778 0.1 0.007787910474734398
1.125 2600 0.9908 0.0809342 1.07244 0.075467 0.1 0.007710415615298401
1.125 2700 0.9906 0.0923874 1.06829 0.0864816 0.1 0.0076336918809618085
1.125 2800 0.984 0.0730703 1.06357 0.0687026 0.1 0.007557731598519933
1.125 2900 0.9994 0.111852 1.06129 0.105393 0.1 0.007482527171121546
1.125 3000 0.9952 0.133999 1.05737 0.126729 0.1 0.007408071077509108
1.125 3100 0.991 0.0839111 1.05668 0.0794099 0.1 0.0073343558712665735
1.125 3200 0.998 0.107049 1.05417 0.101549 0.1 0.007261374180074655
1.125 3300 0.9896 0.0823043 1.0519 0.0782431 0.1 0.007189118704973517
1.125 3400 0.9938 0.0764811 1.05187 0.0727096 0.1 0.007117582219632801
1.125 3500 0.9912 0.108229 1.05043 0.103033 0.1 0.007046757569628924
1.125 3600 0.9958 0.0809036 1.04917 0.0771122 0.1 0.00697663767172953
1.125 3700 0.9926 0.0989184 1.04795 0.0943922 0.1 0.006907215513185129
1.125 3800 0.998 0.080305 1.04804 0.0766241 0.1 0.00683848415102772
1.125 3900 0.9998 0.0869605 1.04548 0.0831775 0.1 0.006770436711376421
1.125 4000 0.9898 0.101176 1.0464 0.0966894 0.1 0.006703066388750011
1.125 4100 0.9968 0.106205 1.04551 0.101582 0.1 0.006636366445386311
1.125 4200 0.9932 0.0819433 1.0443 0.0784675 0.1 0.006570330210568327
1.125 4300 0.9992 0.0857959 1.04526 0.0820805 0.1 0.006504951079957117
1.125 4400 0.9976 0.103219 1.04458 0.0988145 0.1 0.006440222514931274
1.125 4500 0.9916 0.100151 1.04445 0.0958888 0.1 0.006376138041932989
# Train result: 1.125 0.994327
# Test result: 1.125 0.9947
# 45361 entries between 1.03125 and 1.28125
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
1.15625 100 0.9534 0.476731 3.12223 0.152689 0.1 0.009900493386913728
1.15625 200 0.9898 0.264395 2.87355 0.0920097 0.1 0.009801976930432239
1.15625 300 0.9802 0.176692 2.66803 0.0662257 0.1 0.00970444077784252
1.15625 400 0.989 0.163184 2.46327 0.0662468 0.1 0.009607875174472565
1.15625 500 0.9932 0.141286 2.26903 0.0622672 0.1 0.009512270462715812
1.15625 600 0.9924 0.084506 2.0951 0.040335 0.1 0.009417617081065264
1.15625 700 0.9862 0.117384 1.94019 0.0605013 0.1 0.009323905563157238
1.15625 800 0.9918 0.130071 1.80743 0.0719647 0.1 0.009231126536824622
1.15625 900 0.995 0.125177 1.69277 0.0739481 0.1 0.009139270723159591
1.15625 1000 0.9802 0.103693 1.59867 0.064862 0.1 0.009048328935585565
1.15625 1100 0.9924 0.127467 1.51638 0.0840601 0.1 0.008958292078938489
1.15625 1200 0.9952 0.103426 1.44849 0.0714025 0.1 0.0088691511485572
1.15625 1300 0.99 0.102878 1.39226 0.0738928 0.1 0.008780897229382877
1.15625 1400 0.9924 0.0790626 1.34476 0.0587931 0.1 0.008693521495067419
1.15625 1500 0.9996 0.0898996 1.30623 0.0688235 0.1 0.008607015207090722
1.15625 1600 0.9906 0.0809802 1.27252 0.0636374 0.1 0.008521369713886751
1.15625 1700 0.9982 0.114034 1.2457 0.0915416 0.1 0.008436576449978266
1.15625 1800 0.9906 0.120608 1.22222 0.0986799 0.1 0.008352626935120183
1.15625 1900 0.9928 0.0785674 1.20574 0.0651613 0.1 0.008269512773451476
1.15625 2000 0.9902 0.117681 1.18891 0.0989827 0.1 0.008187225652655481
1.15625 2100 0.995 0.118538 1.1764 0.100763 0.1 0.008105757343128598
1.15625 2200 0.9952 0.0826736 1.16622 0.0708906 0.1 0.008025099697157206
1.15625 2300 0.9978 0.105432 1.15731 0.0911012 0.1 0.007945244648102822
1.15625 2400 0.9892 0.108707 1.15039 0.0944955 0.1 0.007866184209595362
1.15625 2500 0.993 0.119216 1.14252 0.104345 0.1 0.007787910474734398
1.15625 2600 0.9924 0.0859865 1.13876 0.0755089 0.1 0.007710415615298401
1.15625 2700 0.9914 0.105439 1.13353 0.0930184 0.1 0.0076336918809618085
1.15625 2800 0.9916 0.117472 1.13155 0.103815 0.1 0.007557731598519933
1.15625 2900 0.9906 0.0912606 1.12683 0.0809887 0.1 0.007482527171121546
1.15625 3000 0.9892 0.110443 1.1254 0.0981362 0.1 0.007408071077509108
1.15625 3100 0.9958 0.116154 1.12295 0.103436 0.1 0.0073343558712665735
1.15625 3200 0.9942 0.126625 1.12133 0.112924 0.1 0.007261374180074655
1.15625 3300 0.994 0.0995949 1.12031 0.0888992 0.1 0.007189118704973517
1.15625 3400 0.9982 0.094992 1.1174 0.0850119 0.1 0.007117582219632801
1.15625 3500 0.9948 0.122575 1.11756 0.109681 0.1 0.007046757569628924
1.15625 3600 0.993 0.0865262 1.11549 0.0775676 0.1 0.00697663767172953
1.15625 3700 0.9924 0.127876 1.11599 0.114585 0.1 0.006907215513185129
1.15625 3800 0.9932 0.114426 1.11399 0.102717 0.1 0.00683848415102772
1.15625 3900 0.995 0.116517 1.11343 0.104647 0.1 0.006770436711376421
1.15625 4000 0.997 0.096757 1.11304 0.0869304 0.1 0.006703066388750011
1.15625 4100 0.9894 0.107776 1.11315 0.096821 0.1 0.006636366445386311
1.15625 4200 0.9922 0.108117 1.11252 0.0971816 0.1 0.006570330210568327
1.15625 4300 0.9892 0.102391 1.11097 0.0921639 0.1 0.006504951079957117
1.15625 4400 0.9924 0.0855129 1.11241 0.0768716 0.1 0.006440222514931274
1.15625 4500 0.9942 0.0895827 1.11088 0.080641 0.1 0.006376138041932989
# Train result: 1.15625 0.983819
# Test result: 1.15625 0.9833
# 45361 entries between 1.0625 and 1.3125
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
1.1875 100 0.9204 0.558566 3.04393 0.183502 0.1 0.009900493386913728
1.1875 200 0.9632 0.33736 2.76961 0.121808 0.1 0.009801976930432239
1.1875 300 0.9752 0.2472 2.60175 0.0950128 0.1 0.00970444077784252
1.1875 400 0.9772 0.171341 2.43415 0.0703906 0.1 0.009607875174472565
1.1875 500 0.9878 0.135055 2.27136 0.0594603 0.1 0.009512270462715812
1.1875 600 0.9858 0.136192 2.11961 0.0642533 0.1 0.009417617081065264
1.1875 700 0.983 0.133142 1.98112 0.0672053 0.1 0.009323905563157238
1.1875 800 0.9914 0.130416 1.85868 0.0701658 0.1 0.009231126536824622
1.1875 900 0.989 0.129102 1.75319 0.0736384 0.1 0.009139270723159591
1.1875 1000 0.9892 0.134565 1.66471 0.0808339 0.1 0.009048328935585565
1.1875 1100 0.997 0.132742 1.58975 0.0834985 0.1 0.008958292078938489
1.1875 1200 0.9894 0.115469 1.52323 0.0758057 0.1 0.0088691511485572
1.1875 1300 0.9804 0.11121 1.4684 0.0757353 0.1 0.008780897229382877
1.1875 1400 0.9784 0.085248 1.42413 0.0598595 0.1 0.008693521495067419
1.1875 1500 0.9934 0.123096 1.38626 0.0887974 0.1 0.008607015207090722
1.1875 1600 0.9932 0.141663 1.35499 0.104549 0.1 0.008521369713886751
1.1875 1700 0.9864 0.112602 1.32893 0.0847313 0.1 0.008436576449978266
1.1875 1800 0.9978 0.0865338 1.30475 0.0663222 0.1 0.008352626935120183
1.1875 1900 0.983 0.0923065 1.28931 0.0715939 0.1 0.008269512773451476
1.1875 2000 0.9922 0.102493 1.27561 0.080348 0.1 0.008187225652655481
1.1875 2100 0.983 0.108504 1.26085 0.0860562 0.1 0.008105757343128598
1.1875 2200 0.9884 0.0988219 1.24928 0.0791028 0.1 0.008025099697157206
1.1875 2300 0.995 0.110127 1.24213 0.0886601 0.1 0.007945244648102822
1.1875 2400 0.9962 0.108729 1.2355 0.0880038 0.1 0.007866184209595362
1.1875 2500 0.9868 0.122754 1.22908 0.0998743 0.1 0.007787910474734398
1.1875 2600 0.998 0.119103 1.22412 0.0972969 0.1 0.007710415615298401
1.1875 2700 0.9798 0.107307 1.21764 0.0881265 0.1 0.0076336918809618085
1.1875 2800 0.9842 0.104762 1.21659 0.0861113 0.1 0.007557731598519933
1.1875 2900 0.9862 0.107118 1.21509 0.0881568 0.1 0.007482527171121546
1.1875 3000 0.9866 0.128328 1.20998 0.106058 0.1 0.007408071077509108
1.1875 3100 0.9928 0.117243 1.20687 0.0971469 0.1 0.0073343558712665735
1.1875 3200 0.984 0.119685 1.20605 0.0992373 0.1 0.007261374180074655
1.1875 3300 0.9918 0.0978507 1.2054 0.0811767 0.1 0.007189118704973517
1.1875 3400 0.9842 0.0978701 1.2043 0.0812669 0.1 0.007117582219632801
1.1875 3500 0.9864 0.0996396 1.20295 0.0828293 0.1 0.007046757569628924
1.1875 3600 0.9992 0.116463 1.19966 0.0970796 0.1 0.00697663767172953
1.1875 3700 0.998 0.104955 1.1994 0.0875062 0.1 0.006907215513185129
1.1875 3800 0.9892 0.109784 1.20131 0.0913869 0.1 0.00683848415102772
1.1875 3900 0.9926 0.123142 1.19809 0.102782 0.1 0.006770436711376421
1.1875 4000 0.9894 0.129128 1.1972 0.107858 0.1 0.006703066388750011
1.1875 4100 0.995 0.129543 1.19666 0.108254 0.1 0.006636366445386311
1.1875 4200 0.9892 0.12452 1.19855 0.103893 0.1 0.006570330210568327
1.1875 4300 0.9972 0.108667 1.19793 0.0907122 0.1 0.006504951079957117
1.1875 4400 0.9934 0.128034 1.19671 0.106988 0.1 0.006440222514931274
1.1875 4500 0.9956 0.114378 1.19446 0.0957574 0.1 0.006376138041932989
# Train result: 1.1875 0.992605
# Test result: 1.1875 0.9928
# 45361 entries between 1.09375 and 1.34375
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
1.21875 100 0.8552 0.616635 3.03663 0.203065 0.1 0.009900493386913728
1.21875 200 0.9578 0.44065 2.70011 0.163197 0.1 0.009801976930432239
1.21875 300 0.9726 0.275385 2.54313 0.108286 0.1 0.00970444077784252
1.21875 400 0.9802 0.230482 2.41626 0.0953881 0.1 0.009607875174472565
1.21875 500 0.9786 0.164617 2.28766 0.0719586 0.1 0.009512270462715812
1.21875 600 0.999 0.192509 2.16247 0.0890227 0.1 0.009417617081065264
1.21875 700 0.984 0.140595 2.04277 0.0688258 0.1 0.009323905563157238
1.21875 800 0.9876 0.144031 1.93785 0.0743249 0.1 0.009231126536824622
1.21875 900 0.9896 0.158043 1.84282 0.0857617 0.1 0.009139270723159591
1.21875 1000 0.9808 0.113617 1.76121 0.064511 0.1 0.009048328935585565
1.21875 1100 0.977 0.135806 1.69002 0.0803575 0.1 0.008958292078938489
1.21875 1200 0.9898 0.149126 1.62964 0.0915084 0.1 0.0088691511485572
1.21875 1300 0.9962 0.153317 1.57983 0.0970463 0.1 0.008780897229382877
1.21875 1400 0.9988 0.129468 1.53561 0.0843105 0.1 0.008693521495067419
1.21875 1500 0.988 0.136069 1.50077 0.0906665 0.1 0.008607015207090722
1.21875 1600 0.9876 0.121769 1.46883 0.0829023 0.1 0.008521369713886751
1.21875 1700 0.9898 0.141084 1.44507 0.0976313 0.1 0.008436576449978266
1.21875 1800 0.986 0.111815 1.42428 0.0785067 0.1 0.008352626935120183
1.21875 1900 0.9892 0.130016 1.40541 0.0925113 0.1 0.008269512773451476
1.21875 2000 0.997 0.108857 1.39124 0.0782447 0.1 0.008187225652655481
1.21875 2100 0.992 0.0872471 1.37888 0.0632738 0.1 0.008105757343128598
1.21875 2200 0.9802 0.145854 1.37037 0.106435 0.1 0.008025099697157206
1.21875 2300 0.9962 0.144416 1.3605 0.10615 0.1 0.007945244648102822
1.21875 2400 0.9818 0.12531 1.35426 0.0925301 0.1 0.007866184209595362
1.21875 2500 0.9876 0.108158 1.34731 0.0802767 0.1 0.007787910474734398
1.21875 2600 0.9876 0.116515 1.34338 0.0867334 0.1 0.007710415615298401
1.21875 2700 0.9968 0.144335 1.33918 0.107778 0.1 0.0076336918809618085
1.21875 2800 0.979 0.129411 1.33475 0.0969554 0.1 0.007557731598519933
1.21875 2900 0.9714 0.105608 1.33349 0.0791965 0.1 0.007482527171121546
1.21875 3000 0.984 0.103408 1.33012 0.0777437 0.1 0.007408071077509108
1.21875 3100 0.9834 0.109419 1.32899 0.0823323 0.1 0.0073343558712665735
1.21875 3200 0.9878 0.122434 1.32648 0.0923004 0.1 0.007261374180074655
1.21875 3300 0.9878 0.127962 1.32456 0.0966068 0.1 0.007189118704973517
1.21875 3400 0.9826 0.105761 1.32392 0.0798845 0.1 0.007117582219632801
1.21875 3500 0.9876 0.104027 1.32297 0.0786308 0.1 0.007046757569628924
1.21875 3600 0.9894 0.130523 1.3217 0.0987538 0.1 0.00697663767172953
1.21875 3700 0.9928 0.128032 1.31989 0.0970021 0.1 0.006907215513185129
1.21875 3800 0.9982 0.119864 1.32064 0.0907616 0.1 0.00683848415102772
1.21875 3900 0.9894 0.128262 1.3189 0.0972493 0.1 0.006770436711376421
1.21875 4000 0.9828 0.128205 1.31956 0.0971574 0.1 0.006703066388750011
1.21875 4100 0.982 0.127276 1.31756 0.0965998 0.1 0.006636366445386311
1.21875 4200 0.9948 0.126497 1.31807 0.0959719 0.1 0.006570330210568327
1.21875 4300 0.9902 0.161157 1.31779 0.122293 0.1 0.006504951079957117
1.21875 4400 0.9958 0.106336 1.31743 0.0807145 0.1 0.006440222514931274
1.21875 4500 0.9794 0.144997 1.31665 0.110125 0.1 0.006376138041932989
# Train result: 1.21875 0.974172
# Test result: 1.21875 0.9768
# 45361 entries between 1.125 and 1.375
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
1.25 100 0.8144 0.649384 3.01502 0.215383 0.1 0.009900493386913728
1.25 200 0.9658 0.537339 2.60906 0.205951 0.1 0.009801976930432239
1.25 300 0.9772 0.379094 2.41776 0.156796 0.1 0.00970444077784252
1.25 400 0.945 0.295754 2.31708 0.127641 0.1 0.009607875174472565
1.25 500 0.9372 0.204018 2.23248 0.0913863 0.1 0.009512270462715812
1.25 600 0.9582 0.198315 2.14918 0.0922747 0.1 0.009417617081065264
1.25 700 0.9962 0.20806 2.06452 0.100779 0.1 0.009323905563157238
1.25 800 0.9796 0.170207 1.98709 0.0856566 0.1 0.009231126536824622
1.25 900 0.9692 0.142375 1.91296 0.0744268 0.1 0.009139270723159591
1.25 1000 0.9884 0.158074 1.84821 0.0855278 0.1 0.009048328935585565
1.25 1100 0.9812 0.156959 1.78942 0.0877151 0.1 0.008958292078938489
1.25 1200 0.984 0.142017 1.73948 0.0816433 0.1 0.0088691511485572
1.25 1300 0.95 0.127346 1.69686 0.0750483 0.1 0.008780897229382877
1.25 1400 0.9924 0.167256 1.65856 0.100844 0.1 0.008693521495067419
1.25 1500 0.9642 0.110704 1.62824 0.0679896 0.1 0.008607015207090722
1.25 1600 0.973 0.169026 1.59962 0.105666 0.1 0.008521369713886751
1.25 1700 0.988 0.169182 1.57756 0.107243 0.1 0.008436576449978266
1.25 1800 0.9446 0.106848 1.5572 0.0686155 0.1 0.008352626935120183
1.25 1900 0.9632 0.123624 1.54132 0.0802065 0.1 0.008269512773451476
1.25 2000 0.9926 0.136072 1.52683 0.0891202 0.1 0.008187225652655481
1.25 2100 0.9608 0.155075 1.51671 0.102244 0.1 0.008105757343128598
1.25 2200 0.9862 0.15569 1.5079 0.10325 0.1 0.008025099697157206
1.25 2300 0.9888 0.135247 1.49894 0.0902286 0.1 0.007945244648102822
1.25 2400 0.9864 0.159911 1.49424 0.107018 0.1 0.007866184209595362
1.25 2500 0.9938 0.175177 1.48675 0.117825 0.1 0.007787910474734398
1.25 2600 0.995 0.13119 1.48314 0.0884547 0.1 0.007710415615298401
1.25 2700 0.9962 0.162389 1.47798 0.109872 0.1 0.0076336918809618085
1.25 2800 0.9892 0.152411 1.47493 0.103334 0.1 0.007557731598519933
1.25 2900 0.9768 0.166795 1.47213 0.113302 0.1 0.007482527171121546
1.25 3000 0.989 0.178097 1.47007 0.121149 0.1 0.007408071077509108
1.25 3100 0.9364 0.187172 1.47052 0.127282 0.1 0.0073343558712665735
1.25 3200 0.9946 0.137767 1.4666 0.0939359 0.1 0.007261374180074655
1.25 3300 0.9914 0.151023 1.46654 0.102979 0.1 0.007189118704973517
1.25 3400 0.9798 0.124986 1.46359 0.0853969 0.1 0.007117582219632801
1.25 3500 0.9548 0.142704 1.46483 0.0974202 0.1 0.007046757569628924
1.25 3600 0.9776 0.122809 1.46171 0.0840173 0.1 0.00697663767172953
1.25 3700 0.9594 0.147546 1.46094 0.100994 0.1 0.006907215513185129
1.25 3800 0.9834 0.174834 1.46035 0.11972 0.1 0.00683848415102772
1.25 3900 0.999 0.157356 1.46005 0.107774 0.1 0.006770436711376421
1.25 4000 0.9856 0.13708 1.46074 0.0938428 0.1 0.006703066388750011
1.25 4100 0.9952 0.143964 1.4582 0.0987269 0.1 0.006636366445386311
1.25 4200 0.9692 0.13271 1.46004 0.0908943 0.1 0.006570330210568327
1.25 4300 0.9952 0.146977 1.45766 0.10083 0.1 0.006504951079957117
1.25 4400 0.982 0.152433 1.45881 0.104492 0.1 0.006440222514931274
1.25 4500 0.9378 0.10669 1.45774 0.0731887 0.1 0.006376138041932989
# Train result: 1.25 0.948366
# Test result: 1.25 0.9504
# 45361 entries between 1.15625 and 1.40625
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
1.28125 100 0.8178 0.671017 2.9898 0.224435 0.1 0.009900493386913728
1.28125 200 0.925 0.617503 2.50691 0.24632 0.1 0.009801976930432239
1.28125 300 0.8824 0.526568 2.2094 0.238331 0.1 0.00970444077784252
1.28125 400 0.9116 0.427857 2.07702 0.205996 0.1 0.009607875174472565
1.28125 500 0.9434 0.347115 2.03354 0.170695 0.1 0.009512270462715812
1.28125 600 0.9408 0.282119 2.01251 0.140183 0.1 0.009417617081065264
1.28125 700 0.9448 0.262102 1.99169 0.131598 0.1 0.009323905563157238
1.28125 800 0.9858 0.214839 1.96767 0.109185 0.1 0.009231126536824622
1.28125 900 0.8642 0.223528 1.94225 0.115087 0.1 0.009139270723159591
1.28125 1000 0.9854 0.196083 1.90977 0.102674 0.1 0.009048328935585565
1.28125 1100 0.9742 0.19235 1.87928 0.102353 0.1 0.008958292078938489
1.28125 1200 0.9384 0.186077 1.84954 0.100607 0.1 0.0088691511485572
1.28125 1300 0.9498 0.16622 1.82215 0.091222 0.1 0.008780897229382877
1.28125 1400 0.9996 0.178912 1.79836 0.0994863 0.1 0.008693521495067419
1.28125 1500 0.99 0.161375 1.77354 0.0909904 0.1 0.008607015207090722
1.28125 1600 0.9636 0.184152 1.75661 0.104834 0.1 0.008521369713886751
1.28125 1700 0.982 0.170375 1.73962 0.0979381 0.1 0.008436576449978266
1.28125 1800 0.9772 0.17914 1.72539 0.103826 0.1 0.008352626935120183
1.28125 1900 0.963 0.142855 1.71259 0.0834144 0.1 0.008269512773451476
1.28125 2000 0.951 0.137316 1.70235 0.0806628 0.1 0.008187225652655481
1.28125 2100 0.9764 0.181872 1.69248 0.107459 0.1 0.008105757343128598
1.28125 2200 0.9688 0.136834 1.68515 0.0811996 0.1 0.008025099697157206
1.28125 2300 0.9544 0.156465 1.68056 0.0931029 0.1 0.007945244648102822
1.28125 2400 0.9908 0.179049 1.67209 0.107081 0.1 0.007866184209595362
1.28125 2500 0.9748 0.157395 1.67007 0.0942444 0.1 0.007787910474734398
1.28125 2600 0.9588 0.14651 1.66661 0.0879093 0.1 0.007710415615298401
1.28125 2700 0.995 0.13986 1.66375 0.0840631 0.1 0.0076336918809618085
1.28125 2800 0.9536 0.163365 1.66146 0.0983259 0.1 0.007557731598519933
1.28125 2900 0.953 0.143924 1.65815 0.0867978 0.1 0.007482527171121546
1.28125 3000 0.9978 0.212495 1.65616 0.128306 0.1 0.007408071077509108
1.28125 3100 0.9808 0.147602 1.65536 0.0891658 0.1 0.0073343558712665735
1.28125 3200 0.9636 0.163281 1.65553 0.098628 0.1 0.007261374180074655
1.28125 3300 0.979 0.136763 1.65126 0.0828236 0.1 0.007189118704973517
1.28125 3400 0.973 0.161935 1.65258 0.0979891 0.1 0.007117582219632801
1.28125 3500 0.966 0.162809 1.65221 0.0985397 0.1 0.007046757569628924
1.28125 3600 0.9516 0.151453 1.65199 0.0916787 0.1 0.00697663767172953
1.28125 3700 0.9666 0.153687 1.65073 0.0931029 0.1 0.006907215513185129
1.28125 3800 0.973 0.188123 1.6485 0.114118 0.1 0.00683848415102772
1.28125 3900 0.9746 0.139466 1.64921 0.0845655 0.1 0.006770436711376421
1.28125 4000 0.9804 0.15375 1.64963 0.0932028 0.1 0.006703066388750011
1.28125 4100 0.9764 0.163226 1.64908 0.0989804 0.1 0.006636366445386311
1.28125 4200 0.9622 0.142468 1.64625 0.0865407 0.1 0.006570330210568327
1.28125 4300 0.9922 0.170862 1.64833 0.103658 0.1 0.006504951079957117
1.28125 4400 0.9386 0.170127 1.64912 0.103163 0.1 0.006440222514931274
1.28125 4500 0.9886 0.15581 1.64849 0.0945167 0.1 0.006376138041932989
# Train result: 1.28125 0.97011
# Test result: 1.28125 0.9731
# 45361 entries between 1.1875 and 1.4375
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
1.3125 100 0.6444 0.679553 2.98358 0.227764 0.1 0.009900493386913728
1.3125 200 0.843 0.654623 2.47779 0.264196 0.1 0.009801976930432239
1.3125 300 0.8554 0.606 2.11308 0.286786 0.1 0.00970444077784252
1.3125 400 0.9164 0.530037 1.89843 0.279198 0.1 0.009607875174472565
1.3125 500 0.9534 0.454268 1.81748 0.249944 0.1 0.009512270462715812
1.3125 600 0.937 0.394333 1.81589 0.217157 0.1 0.009417617081065264
1.3125 700 0.9136 0.332855 1.84082 0.180819 0.1 0.009323905563157238
1.3125 800 0.943 0.265834 1.86439 0.142585 0.1 0.009231126536824622
1.3125 900 0.9836 0.250393 1.87913 0.13325 0.1 0.009139270723159591
1.3125 1000 0.8978 0.272312 1.88444 0.144506 0.1 0.009048328935585565
1.3125 1100 0.974 0.200231 1.88007 0.106502 0.1 0.008958292078938489
1.3125 1200 0.9332 0.211961 1.87703 0.112924 0.1 0.0088691511485572
1.3125 1300 0.9816 0.215323 1.86925 0.115192 0.1 0.008780897229382877
1.3125 1400 0.973 0.221479 1.85737 0.119244 0.1 0.008693521495067419
1.3125 1500 0.9726 0.207475 1.84815 0.112261 0.1 0.008607015207090722
1.3125 1600 0.9678 0.242312 1.83699 0.131907 0.1 0.008521369713886751
1.3125 1700 0.9386 0.231191 1.82996 0.126337 0.1 0.008436576449978266
1.3125 1800 0.996 0.192585 1.8212 0.105747 0.1 0.008352626935120183
1.3125 1900 0.998 0.213976 1.81214 0.118079 0.1 0.008269512773451476
1.3125 2000 0.9014 0.220871 1.80421 0.122419 0.1 0.008187225652655481
1.3125 2100 0.9972 0.185796 1.80114 0.103155 0.1 0.008105757343128598
1.3125 2200 0.9874 0.191467 1.79771 0.106506 0.1 0.008025099697157206
1.3125 2300 0.9806 0.17339 1.79205 0.0967551 0.1 0.007945244648102822
1.3125 2400 0.9464 0.183146 1.78778 0.102443 0.1 0.007866184209595362
1.3125 2500 0.9714 0.175812 1.78359 0.098572 0.1 0.007787910474734398
1.3125 2600 0.9418 0.213509 1.78259 0.119774 0.1 0.007710415615298401
1.3125 2700 0.9906 0.212049 1.78013 0.11912 0.1 0.0076336918809618085
1.3125 2800 0.981 0.170747 1.77712 0.0960805 0.1 0.007557731598519933
1.3125 2900 0.8552 0.302647 1.77527 0.17048 0.1 0.007482527171121546
1.3125 3000 0.9812 0.201143 1.7771 0.113186 0.1 0.007408071077509108
1.3125 3100 0.9978 0.199442 1.77738 0.112212 0.1 0.0073343558712665735
1.3125 3200 0.847 0.302497 1.77723 0.170207 0.1 0.007261374180074655
1.3125 3300 0.9678 0.172082 1.77356 0.0970263 0.1 0.007189118704973517
1.3125 3400 0.9958 0.196773 1.77115 0.111099 0.1 0.007117582219632801
1.3125 3500 0.9734 0.196443 1.77325 0.110781 0.1 0.007046757569628924
1.3125 3600 0.8618 0.3006 1.77444 0.169405 0.1 0.00697663767172953
1.3125 3700 0.9678 0.155619 1.77205 0.0878187 0.1 0.006907215513185129
1.3125 3800 0.9934 0.180728 1.77044 0.102081 0.1 0.00683848415102772
1.3125 3900 0.9772 0.189005 1.77277 0.106616 0.1 0.006770436711376421
1.3125 4000 0.9816 0.185431 1.77499 0.104469 0.1 0.006703066388750011
1.3125 4100 0.9782 0.212446 1.77284 0.119833 0.1 0.006636366445386311
1.3125 4200 0.9906 0.217808 1.77104 0.122983 0.1 0.006570330210568327
1.3125 4300 0.9222 0.221019 1.76848 0.124977 0.1 0.006504951079957117
1.3125 4400 0.8936 0.203556 1.77245 0.114844 0.1 0.006440222514931274
1.3125 4500 0.9446 0.192647 1.77351 0.108625 0.1 0.006376138041932989
# Train result: 1.3125 0.931369
# Test result: 1.3125 0.9274
# 45361 entries between 1.21875 and 1.46875
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
1.34375 100 0.5262 0.680665 3.00379 0.226602 0.1 0.009900493386913728
1.34375 200 0.9782 0.667141 2.48431 0.268541 0.1 0.009801976930432239
1.34375 300 0.81 0.631395 2.09207 0.301804 0.1 0.00970444077784252
1.34375 400 0.9026 0.589891 1.82686 0.322899 0.1 0.009607875174472565
1.34375 500 0.825 0.518114 1.69458 0.305748 0.1 0.009512270462715812
1.34375 600 0.901 0.440807 1.66724 0.264394 0.1 0.009417617081065264
1.34375 700 0.898 0.379041 1.69359 0.22381 0.1 0.009323905563157238
1.34375 800 0.9624 0.342199 1.73138 0.197645 0.1 0.009231126536824622
1.34375 900 0.8146 0.3947 1.77517 0.222345 0.1 0.009139270723159591
1.34375 1000 0.8344 0.338155 1.80705 0.187131 0.1 0.009048328935585565
1.34375 1100 0.9654 0.254294 1.82394 0.13942 0.1 0.008958292078938489
1.34375 1200 0.8876 0.306534 1.84285 0.166337 0.1 0.0088691511485572
1.34375 1300 0.986 0.247313 1.85 0.133683 0.1 0.008780897229382877
1.34375 1400 0.946 0.232714 1.85853 0.125214 0.1 0.008693521495067419
1.34375 1500 0.9428 0.203647 1.86066 0.109448 0.1 0.008607015207090722
1.34375 1600 0.9762 0.244546 1.85789 0.131625 0.1 0.008521369713886751
1.34375 1700 0.9928 0.219795 1.85645 0.118395 0.1 0.008436576449978266
1.34375 1800 0.9868 0.197334 1.85914 0.106143 0.1 0.008352626935120183
1.34375 1900 0.8954 0.280937 1.85351 0.15157 0.1 0.008269512773451476
1.34375 2000 0.8054 0.336426 1.85078 0.181775 0.1 0.008187225652655481
1.34375 2100 0.9302 0.276199 1.85018 0.149282 0.1 0.008105757343128598
1.34375 2200 0.9288 0.222051 1.84554 0.120318 0.1 0.008025099697157206
1.34375 2300 0.961 0.232717 1.84441 0.126174 0.1 0.007945244648102822
1.34375 2400 0.9572 0.191799 1.84306 0.104066 0.1 0.007866184209595362
1.34375 2500 0.9454 0.197383 1.83782 0.1074 0.1 0.007787910474734398
1.34375 2600 0.7994 0.414628 1.83771 0.225622 0.1 0.007710415615298401
1.34375 2700 0.9642 0.184027 1.83978 0.100027 0.1 0.0076336918809618085
1.34375 2800 0.9754 0.190161 1.83514 0.103622 0.1 0.007557731598519933
1.34375 2900 0.934 0.204228 1.83477 0.11131 0.1 0.007482527171121546
1.34375 3000 0.9332 0.22749 1.83507 0.123968 0.1 0.007408071077509108
1.34375 3100 0.9726 0.158307 1.83333 0.0863494 0.1 0.0073343558712665735
1.34375 3200 0.9676 0.205579 1.83382 0.112104 0.1 0.007261374180074655
1.34375 3300 0.9424 0.222565 1.83308 0.121416 0.1 0.007189118704973517
1.34375 3400 0.8234 0.307073 1.83198 0.167617 0.1 0.007117582219632801
1.34375 3500 0.8104 0.429633 1.83291 0.2344 0.1 0.007046757569628924
1.34375 3600 0.9924 0.197519 1.83402 0.107698 0.1 0.00697663767172953
1.34375 3700 0.9634 0.243314 1.83118 0.132872 0.1 0.006907215513185129
1.34375 3800 0.9578 0.228895 1.83047 0.125047 0.1 0.00683848415102772
1.34375 3900 0.9456 0.177365 1.83206 0.0968116 0.1 0.006770436711376421
1.34375 4000 0.9574 0.236382 1.83121 0.129085 0.1 0.006703066388750011
1.34375 4100 0.887 0.243739 1.83272 0.132993 0.1 0.006636366445386311
1.34375 4200 0.9692 0.18376 1.83078 0.100373 0.1 0.006570330210568327
1.34375 4300 0.8588 0.294322 1.83065 0.160775 0.1 0.006504951079957117
1.34375 4400 0.9054 0.275211 1.83353 0.150099 0.1 0.006440222514931274
1.34375 4500 0.965 0.204119 1.83238 0.111395 0.1 0.006376138041932989
# Train result: 1.34375 0.884018
# Test result: 1.34375 0.8832
# 45361 entries between 1.25 and 1.5
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
1.375 100 0.6096 0.68467 3.00684 0.227704 0.1 0.009900493386913728
1.375 200 0.5682 0.658224 2.49148 0.26419 0.1 0.009801976930432239
1.375 300 0.9028 0.625529 2.11072 0.296359 0.1 0.00970444077784252
1.375 400 0.9304 0.562776 1.87309 0.300453 0.1 0.009607875174472565
1.375 500 0.7516 0.480364 1.77087 0.271259 0.1 0.009512270462715812
1.375 600 0.9998 0.384 1.76189 0.217947 0.1 0.009417617081065264
1.375 700 0.9974 0.37185 1.77776 0.209167 0.1 0.009323905563157238
1.375 800 0.8522 0.337678 1.81442 0.186108 0.1 0.009231126536824622
1.375 900 0.9692 0.277183 1.8366 0.150922 0.1 0.009139270723159591
1.375 1000 0.8826 0.316134 1.85016 0.170869 0.1 0.009048328935585565
1.375 1100 0.9396 0.247447 1.86649 0.132573 0.1 0.008958292078938489
1.375 1200 0.8516 0.363662 1.87244 0.194218 0.1 0.0088691511485572
1.375 1300 0.9924 0.220512 1.87618 0.117533 0.1 0.008780897229382877
1.375 1400 0.7962 0.366821 1.87722 0.195407 0.1 0.008693521495067419
1.375 1500 0.9798 0.205634 1.87753 0.109524 0.1 0.008607015207090722
1.375 1600 0.9886 0.230521 1.87026 0.123256 0.1 0.008521369713886751
1.375 1700 0.9412 0.21731 1.8717 0.116103 0.1 0.008436576449978266
1.375 1800 0.9246 0.24344 1.86926 0.130233 0.1 0.008352626935120183
1.375 1900 0.8674 0.261386 1.8609 0.140462 0.1 0.008269512773451476
1.375 2000 0.9046 0.260224 1.85781 0.14007 0.1 0.008187225652655481
1.375 2100 0.9572 0.229902 1.85185 0.124147 0.1 0.008105757343128598
1.375 2200 0.8938 0.259281 1.84944 0.140194 0.1 0.008025099697157206
1.375 2300 0.6526 0.549476 1.84983 0.297041 0.1 0.007945244648102822
1.375 2400 0.9472 0.191102 1.84343 0.103667 0.1 0.007866184209595362
1.375 2500 0.8092 0.448489 1.83862 0.243927 0.1 0.007787910474734398
1.375 2600 0.9494 0.202363 1.83694 0.110163 0.1 0.007710415615298401
1.375 2700 0.9922 0.205968 1.8391 0.111994 0.1 0.0076336918809618085
1.375 2800 0.8166 0.439448 1.83452 0.239545 0.1 0.007557731598519933
1.375 2900 0.9496 0.182143 1.8331 0.0993632 0.1 0.007482527171121546
1.375 3000 0.9742 0.231733 1.82967 0.126653 0.1 0.007408071077509108
1.375 3100 0.892 0.225166 1.83004 0.123038 0.1 0.0073343558712665735
1.375 3200 0.961 0.207977 1.8314 0.113561 0.1 0.007261374180074655
1.375 3300 0.9692 0.199305 1.82834 0.109008 0.1 0.007189118704973517
1.375 3400 0.9198 0.20814 1.82697 0.113926 0.1 0.007117582219632801
1.375 3500 0.8232 0.259519 1.82492 0.142208 0.1 0.007046757569628924
1.375 3600 0.8482 0.280767 1.82918 0.153493 0.1 0.00697663767172953
1.375 3700 0.9212 0.190597 1.82544 0.104411 0.1 0.006907215513185129
1.375 3800 0.902 0.243847 1.82568 0.133566 0.1 0.00683848415102772
1.375 3900 0.9998 0.191599 1.82279 0.105113 0.1 0.006770436711376421
1.375 4000 0.9994 0.185399 1.82334 0.101681 0.1 0.006703066388750011
1.375 4100 0.7584 0.487298 1.82816 0.26655 0.1 0.006636366445386311
1.375 4200 0.975 0.173919 1.82385 0.095358 0.1 0.006570330210568327
1.375 4300 0.9902 0.208685 1.82216 0.114526 0.1 0.006504951079957117
1.375 4400 0.928 0.203848 1.81959 0.112029 0.1 0.006440222514931274
1.375 4500 0.9784 0.202969 1.82528 0.111199 0.1 0.006376138041932989
# Train result: 1.375 0.957219
# Test result: 1.375 0.9557
# 45361 entries between 1.28125 and 1.53125
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
1.40625 100 0.4958 0.68422 2.99639 0.228348 0.1 0.009900493386913728
1.40625 200 0.8644 0.668804 2.47606 0.270109 0.1 0.009801976930432239
1.40625 300 0.9756 0.633758 2.092 0.302943 0.1 0.00970444077784252
1.40625 400 0.9936 0.569349 1.86037 0.306041 0.1 0.009607875174472565
1.40625 500 0.8876 0.478658 1.7729 0.269986 0.1 0.009512270462715812
1.40625 600 0.8452 0.449818 1.77427 0.253523 0.1 0.009417617081065264
1.40625 700 0.8992 0.389048 1.80576 0.215448 0.1 0.009323905563157238
1.40625 800 0.9312 0.287654 1.83153 0.157056 0.1 0.009231126536824622
1.40625 900 0.9468 0.251114 1.85087 0.135674 0.1 0.009139270723159591
1.40625 1000 0.868 0.29687 1.86932 0.158812 0.1 0.009048328935585565
1.40625 1100 0.8788 0.287956 1.87067 0.153932 0.1 0.008958292078938489
1.40625 1200 0.8672 0.231643 1.87218 0.123729 0.1 0.0088691511485572
1.40625 1300 0.976 0.188206 1.87199 0.100538 0.1 0.008780897229382877
1.40625 1400 0.8158 0.329177 1.86388 0.176608 0.1 0.008693521495067419
1.40625 1500 0.9034 0.24549 1.85388 0.132419 0.1 0.008607015207090722
1.40625 1600 0.959 0.199464 1.8415 0.108316 0.1 0.008521369713886751
1.40625 1700 0.9662 0.185367 1.83626 0.100948 0.1 0.008436576449978266
1.40625 1800 0.941 0.252726 1.8261 0.138397 0.1 0.008352626935120183
1.40625 1900 0.9276 0.159395 1.81822 0.0876654 0.1 0.008269512773451476
1.40625 2000 0.9532 0.172987 1.80615 0.0957766 0.1 0.008187225652655481
1.40625 2100 0.9102 0.252197 1.79775 0.140285 0.1 0.008105757343128598
1.40625 2200 0.9152 0.233536 1.79976 0.129759 0.1 0.008025099697157206
1.40625 2300 0.9156 0.222423 1.79198 0.124122 0.1 0.007945244648102822
1.40625 2400 0.8452 0.262407 1.78652 0.146882 0.1 0.007866184209595362
1.40625 2500 0.965 0.167865 1.77847 0.0943874 0.1 0.007787910474734398
1.40625 2600 0.9036 0.180607 1.77884 0.101531 0.1 0.007710415615298401
1.40625 2700 0.9102 0.174221 1.77611 0.0980912 0.1 0.0076336918809618085
1.40625 2800 0.9694 0.159183 1.77426 0.0897181 0.1 0.007557731598519933
1.40625 2900 0.9906 0.172576 1.76629 0.0977055 0.1 0.007482527171121546
1.40625 3000 0.9742 0.166094 1.76307 0.0942074 0.1 0.007408071077509108
1.40625 3100 0.8586 0.291016 1.76871 0.164536 0.1 0.0073343558712665735
1.40625 3200 0.87 0.303261 1.76631 0.171691 0.1 0.007261374180074655
1.40625 3300 0.9676 0.191563 1.76407 0.108592 0.1 0.007189118704973517
1.40625 3400 0.9716 0.174616 1.75916 0.0992606 0.1 0.007117582219632801
1.40625 3500 0.9404 0.209284 1.76198 0.118778 0.1 0.007046757569628924
1.40625 3600 0.9936 0.179916 1.76215 0.1021 0.1 0.00697663767172953
1.40625 3700 0.9726 0.182601 1.76117 0.103682 0.1 0.006907215513185129
1.40625 3800 0.982 0.152893 1.75494 0.0871216 0.1 0.00683848415102772
1.40625 3900 0.8478 0.321549 1.75342 0.183383 0.1 0.006770436711376421
1.40625 4000 0.968 0.202316 1.75895 0.115021 0.1 0.006703066388750011
1.40625 4100 0.9394 0.217774 1.75742 0.123917 0.1 0.006636366445386311
1.40625 4200 0.9254 0.215696 1.75776 0.122711 0.1 0.006570330210568327
1.40625 4300 0.9776 0.194848 1.75291 0.111157 0.1 0.006504951079957117
1.40625 4400 0.9994 0.221843 1.75574 0.126353 0.1 0.006440222514931274
1.40625 4500 0.9418 0.192907 1.75708 0.109789 0.1 0.006376138041932989
# Train result: 1.40625 0.847351
# Test result: 1.40625 0.8492
# 45361 entries between 1.3125 and 1.5625
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
1.4375 100 0.8288 0.684317 3.02302 0.226369 0.1 0.009900493386913728
1.4375 200 0.9672 0.665562 2.50245 0.265965 0.1 0.009801976930432239
1.4375 300 0.9514 0.616624 2.1303 0.289454 0.1 0.00970444077784252
1.4375 400 0.9626 0.524948 1.92637 0.272507 0.1 0.009607875174472565
1.4375 500 0.9982 0.432635 1.86388 0.232116 0.1 0.009512270462715812
1.4375 600 0.755 0.412267 1.87821 0.2195 0.1 0.009417617081065264
1.4375 700 0.9864 0.283294 1.90112 0.149014 0.1 0.009323905563157238
1.4375 800 0.9798 0.276183 1.92048 0.143809 0.1 0.009231126536824622
1.4375 900 0.9972 0.217638 1.93462 0.112497 0.1 0.009139270723159591
1.4375 1000 0.88 0.296203 1.93582 0.153012 0.1 0.009048328935585565
1.4375 1100 0.8764 0.246928 1.92574 0.128225 0.1 0.008958292078938489
1.4375 1200 0.9454 0.205076 1.91034 0.107351 0.1 0.0088691511485572
1.4375 1300 0.9286 0.227897 1.89464 0.120285 0.1 0.008780897229382877
1.4375 1400 0.9228 0.216808 1.88419 0.115067 0.1 0.008693521495067419
1.4375 1500 0.965 0.184297 1.864 0.0988715 0.1 0.008607015207090722
1.4375 1600 0.9332 0.177332 1.84967 0.0958723 0.1 0.008521369713886751
1.4375 1700 0.985 0.183986 1.83127 0.100469 0.1 0.008436576449978266
1.4375 1800 0.7628 0.458933 1.81862 0.252353 0.1 0.008352626935120183
1.4375 1900 0.9822 0.162822 1.81158 0.0898785 0.1 0.008269512773451476
1.4375 2000 0.96 0.161269 1.80168 0.0895102 0.1 0.008187225652655481
1.4375 2100 0.9688 0.191046 1.78843 0.106824 0.1 0.008105757343128598
1.4375 2200 0.8154 0.345768 1.77928 0.19433 0.1 0.008025099697157206
1.4375 2300 0.9284 0.206682 1.78133 0.116027 0.1 0.007945244648102822
1.4375 2400 0.9668 0.129104 1.76995 0.0729423 0.1 0.007866184209595362
1.4375 2500 0.9598 0.167169 1.76771 0.0945678 0.1 0.007787910474734398
1.4375 2600 0.9904 0.163401 1.75969 0.0928577 0.1 0.007710415615298401
1.4375 2700 0.9576 0.17722 1.75286 0.101103 0.1 0.0076336918809618085
1.4375 2800 0.952 0.207492 1.75708 0.118089 0.1 0.007557731598519933
1.4375 2900 0.933 0.198194 1.75539 0.112906 0.1 0.007482527171121546
1.4375 3000 0.9764 0.178687 1.74952 0.102134 0.1 0.007408071077509108
1.4375 3100 0.9396 0.153579 1.74399 0.0880622 0.1 0.0073343558712665735
1.4375 3200 0.8542 0.349638 1.75002 0.199791 0.1 0.007261374180074655
1.4375 3300 0.9732 0.139119 1.74524 0.0797133 0.1 0.007189118704973517
1.4375 3400 0.919 0.203401 1.74702 0.116427 0.1 0.007117582219632801
1.4375 3500 0.9738 0.146064 1.74183 0.083857 0.1 0.007046757569628924
1.4375 3600 0.9604 0.149075 1.73735 0.0858059 0.1 0.00697663767172953
1.4375 3700 0.9824 0.154552 1.74429 0.0886045 0.1 0.006907215513185129
1.4375 3800 0.7992 0.373871 1.74263 0.214544 0.1 0.00683848415102772
1.4375 3900 0.9034 0.203785 1.73935 0.117162 0.1 0.006770436711376421
1.4375 4000 0.9722 0.153213 1.73489 0.0883133 0.1 0.006703066388750011
1.4375 4100 0.7648 0.436349 1.74018 0.250749 0.1 0.006636366445386311
1.4375 4200 0.9982 0.161584 1.73889 0.0929239 0.1 0.006570330210568327
1.4375 4300 0.9728 0.161072 1.74077 0.092529 0.1 0.006504951079957117
1.4375 4400 0.955 0.162087 1.73617 0.0933586 0.1 0.006440222514931274
1.4375 4500 0.9636 0.158842 1.73249 0.0916842 0.1 0.006376138041932989
# Train result: 1.4375 0.954128
# Test result: 1.4375 0.9528
# 45361 entries between 1.34375 and 1.59375
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
1.46875 100 0.5518 0.685697 2.98378 0.229808 0.1 0.009900493386913728
1.46875 200 0.789 0.667863 2.46768 0.270644 0.1 0.009801976930432239
1.46875 300 0.994 0.622273 2.09606 0.296878 0.1 0.00970444077784252
1.46875 400 0.9346 0.538147 1.89426 0.284093 0.1 0.009607875174472565
1.46875 500 0.7606 0.478738 1.83878 0.260356 0.1 0.009512270462715812
1.46875 600 0.8638 0.380861 1.84904 0.205977 0.1 0.009417617081065264
1.46875 700 0.9022 0.306282 1.8833 0.16263 0.1 0.009323905563157238
1.46875 800 0.9162 0.275258 1.90266 0.14467 0.1 0.009231126536824622
1.46875 900 0.908 0.30559 1.91796 0.159331 0.1 0.009139270723159591
1.46875 1000 0.9726 0.209704 1.92441 0.10897 0.1 0.009048328935585565
1.46875 1100 0.9954 0.202388 1.92212 0.105294 0.1 0.008958292078938489
1.46875 1200 0.7512 0.435081 1.92033 0.226566 0.1 0.0088691511485572
1.46875 1300 0.965 0.185002 1.90747 0.0969882 0.1 0.008780897229382877
1.46875 1400 0.8446 0.253349 1.89648 0.133589 0.1 0.008693521495067419
1.46875 1500 0.9546 0.205277 1.88203 0.109072 0.1 0.008607015207090722
1.46875 1600 0.8784 0.250197 1.86789 0.133946 0.1 0.008521369713886751
1.46875 1700 0.9396 0.173461 1.86234 0.0931415 0.1 0.008436576449978266
1.46875 1800 0.9662 0.192084 1.84941 0.103862 0.1 0.008352626935120183
1.46875 1900 0.9818 0.172202 1.84226 0.0934732 0.1 0.008269512773451476
1.46875 2000 0.9882 0.131302 1.82978 0.0717584 0.1 0.008187225652655481
1.46875 2100 0.726 0.44446 1.82453 0.243603 0.1 0.008105757343128598
1.46875 2200 0.9812 0.141142 1.81592 0.0777248 0.1 0.008025099697157206
1.46875 2300 0.9368 0.194017 1.81035 0.107171 0.1 0.007945244648102822
1.46875 2400 0.9904 0.143371 1.8065 0.0793643 0.1 0.007866184209595362
1.46875 2500 0.9276 0.181011 1.7973 0.100712 0.1 0.007787910474734398
1.46875 2600 0.889 0.2693 1.80239 0.149413 0.1 0.007710415615298401
1.46875 2700 0.9968 0.19148 1.7972 0.106543 0.1 0.0076336918809618085
1.46875 2800 0.9728 0.182655 1.79812 0.101581 0.1 0.007557731598519933
1.46875 2900 0.9154 0.1953 1.79177 0.108999 0.1 0.007482527171121546
1.46875 3000 0.8724 0.250542 1.78886 0.140057 0.1 0.007408071077509108
1.46875 3100 0.9848 0.153137 1.78821 0.0856368 0.1 0.0073343558712665735
1.46875 3200 0.8054 0.313139 1.78652 0.175279 0.1 0.007261374180074655
1.46875 3300 0.9466 0.149717 1.78697 0.0837828 0.1 0.007189118704973517
1.46875 3400 0.9784 0.152523 1.78077 0.08565 0.1 0.007117582219632801
1.46875 3500 0.9064 0.179436 1.7836 0.100603 0.1 0.007046757569628924
1.46875 3600 0.9316 0.205461 1.78479 0.115117 0.1 0.00697663767172953
1.46875 3700 0.924 0.169861 1.78723 0.0950414 0.1 0.006907215513185129
1.46875 3800 0.7634 0.386653 1.78497 0.216616 0.1 0.00683848415102772
1.46875 3900 0.9494 0.150428 1.7794 0.0845388 0.1 0.006770436711376421
1.46875 4000 0.9838 0.173589 1.78193 0.0974167 0.1 0.006703066388750011
1.46875 4100 0.906 0.228499 1.78003 0.128368 0.1 0.006636366445386311
1.46875 4200 0.9062 0.211556 1.78169 0.118739 0.1 0.006570330210568327
1.46875 4300 0.9338 0.194862 1.77645 0.109692 0.1 0.006504951079957117
1.46875 4400 0.969 0.178602 1.78051 0.10031 0.1 0.006440222514931274
1.46875 4500 0.8892 0.341066 1.78059 0.191546 0.1 0.006376138041932989
# Train result: 1.46875 0.939117
# Test result: 1.46875 0.9364
# 45361 entries between 1.375 and 1.625
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
1.5 100 0.8846 0.685106 2.97521 0.230271 0.1 0.009900493386913728
1.5 200 0.6602 0.657735 2.46474 0.266858 0.1 0.009801976930432239
1.5 300 0.8096 0.606781 2.10316 0.288509 0.1 0.00970444077784252
1.5 400 0.7346 0.523268 1.90907 0.274096 0.1 0.009607875174472565
1.5 500 0.771 0.499902 1.84958 0.270279 0.1 0.009512270462715812
1.5 600 0.9952 0.353523 1.83606 0.192544 0.1 0.009417617081065264
1.5 700 0.8152 0.358987 1.84406 0.194672 0.1 0.009323905563157238
1.5 800 0.8918 0.290191 1.84787 0.157041 0.1 0.009231126536824622
1.5 900 0.921 0.296661 1.85112 0.16026 0.1 0.009139270723159591
1.5 1000 0.7932 0.382868 1.84982 0.206976 0.1 0.009048328935585565
1.5 1100 0.7652 0.368315 1.83957 0.200219 0.1 0.008958292078938489
1.5 1200 0.9012 0.229317 1.8287 0.125399 0.1 0.0088691511485572
1.5 1300 0.936 0.221884 1.82023 0.121899 0.1 0.008780897229382877
1.5 1400 0.92 0.259696 1.80326 0.144015 0.1 0.008693521495067419
1.5 1500 0.932 0.236095 1.79081 0.131837 0.1 0.008607015207090722
1.5 1600 0.8606 0.236559 1.78071 0.132845 0.1 0.008521369713886751
1.5 1700 0.8848 0.332221 1.76763 0.187947 0.1 0.008436576449978266
1.5 1800 0.92 0.22591 1.75566 0.128675 0.1 0.008352626935120183
1.5 1900 0.9436 0.220596 1.74611 0.126336 0.1 0.008269512773451476
1.5 2000 0.8724 0.250995 1.73749 0.144458 0.1 0.008187225652655481
1.5 2100 0.844 0.355574 1.72828 0.205739 0.1 0.008105757343128598
1.5 2200 0.9976 0.186891 1.72549 0.108312 0.1 0.008025099697157206
1.5 2300 0.9192 0.216708 1.71567 0.126311 0.1 0.007945244648102822
1.5 2400 0.922 0.242177 1.71183 0.141472 0.1 0.007866184209595362
1.5 2500 0.9612 0.20997 1.70934 0.122837 0.1 0.007787910474734398
1.5 2600 0.9478 0.187907 1.70568 0.110165 0.1 0.007710415615298401
1.5 2700 0.9286 0.176408 1.70234 0.103627 0.1 0.0076336918809618085
1.5 2800 0.8506 0.300669 1.70021 0.176842 0.1 0.007557731598519933
1.5 2900 0.9198 0.255144 1.6969 0.150358 0.1 0.007482527171121546
1.5 3000 0.8912 0.238184 1.69354 0.140643 0.1 0.007408071077509108
1.5 3100 0.9616 0.222924 1.69395 0.1316 0.1 0.0073343558712665735
1.5 3200 0.956 0.172671 1.68839 0.102269 0.1 0.007261374180074655
1.5 3300 0.886 0.258671 1.68834 0.153211 0.1 0.007189118704973517
1.5 3400 0.9992 0.186695 1.68852 0.110567 0.1 0.007117582219632801
1.5 3500 0.9224 0.225126 1.6875 0.133407 0.1 0.007046757569628924
1.5 3600 0.9478 0.208918 1.68694 0.123844 0.1 0.00697663767172953
1.5 3700 0.9342 0.196984 1.68757 0.116726 0.1 0.006907215513185129
1.5 3800 0.9638 0.200385 1.68531 0.118901 0.1 0.00683848415102772
1.5 3900 0.964 0.186235 1.68308 0.110652 0.1 0.006770436711376421
1.5 4000 0.9416 0.228107 1.68536 0.135346 0.1 0.006703066388750011
1.5 4100 0.9932 0.16124 1.68013 0.0959689 0.1 0.006636366445386311
1.5 4200 0.857 0.308798 1.68162 0.183631 0.1 0.006570330210568327
1.5 4300 0.9152 0.245858 1.68261 0.146117 0.1 0.006504951079957117
1.5 4400 0.9914 0.156064 1.68096 0.0928424 0.1 0.006440222514931274
1.5 4500 0.9676 0.179174 1.68168 0.106544 0.1 0.006376138041932989
# Train result: 1.5 0.93426
# Test result: 1.5 0.9352
# 45361 entries between 1.40625 and 1.65625
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
1.53125 100 0.5108 0.679651 3.00649 0.226061 0.1 0.009900493386913728
1.53125 200 0.781 0.625783 2.51782 0.248541 0.1 0.009801976930432239
1.53125 300 0.9094 0.545535 2.22115 0.245609 0.1 0.00970444077784252
1.53125 400 0.8736 0.412688 2.10646 0.195916 0.1 0.009607875174472565
1.53125 500 0.7542 0.362799 2.07047 0.175225 0.1 0.009512270462715812
1.53125 600 0.9606 0.245142 2.05685 0.119183 0.1 0.009417617081065264
1.53125 700 0.9338 0.245499 2.03887 0.12041 0.1 0.009323905563157238
1.53125 800 0.9742 0.18572 2.00832 0.0924754 0.1 0.009231126536824622
1.53125 900 0.8708 0.280352 1.98174 0.141468 0.1 0.009139270723159591
1.53125 1000 0.8442 0.337559 1.9474 0.173338 0.1 0.009048328935585565
1.53125 1100 0.9842 0.175598 1.91581 0.0916573 0.1 0.008958292078938489
1.53125 1200 0.9544 0.165407 1.88616 0.0876947 0.1 0.0088691511485572
1.53125 1300 0.9632 0.176845 1.85602 0.0952817 0.1 0.008780897229382877
1.53125 1400 0.9704 0.145719 1.82599 0.079803 0.1 0.008693521495067419
1.53125 1500 0.9536 0.155892 1.80596 0.0863209 0.1 0.008607015207090722
1.53125 1600 0.941 0.224531 1.78472 0.125808 0.1 0.008521369713886751
1.53125 1700 0.9964 0.166101 1.76619 0.0940447 0.1 0.008436576449978266
1.53125 1800 0.9532 0.200071 1.75033 0.114304 0.1 0.008352626935120183
1.53125 1900 0.9744 0.147923 1.73528 0.0852443 0.1 0.008269512773451476
1.53125 2000 0.9968 0.156614 1.72559 0.0907595 0.1 0.008187225652655481
1.53125 2100 0.982 0.173066 1.71808 0.100732 0.1 0.008105757343128598
1.53125 2200 0.9532 0.14926 1.70585 0.087499 0.1 0.008025099697157206
1.53125 2300 0.9998 0.147064 1.69639 0.0866922 0.1 0.007945244648102822
1.53125 2400 0.9306 0.159645 1.69394 0.0942451 0.1 0.007866184209595362
1.53125 2500 0.8994 0.230724 1.68753 0.136723 0.1 0.007787910474734398
1.53125 2600 0.9436 0.173123 1.68369 0.102824 0.1 0.007710415615298401
1.53125 2700 0.9868 0.17617 1.67871 0.104944 0.1 0.0076336918809618085
1.53125 2800 0.9622 0.18594 1.67506 0.111005 0.1 0.007557731598519933
1.53125 2900 0.949 0.173637 1.67474 0.10368 0.1 0.007482527171121546
1.53125 3000 0.9102 0.25591 1.67457 0.152821 0.1 0.007408071077509108
1.53125 3100 0.9878 0.146252 1.66879 0.0876396 0.1 0.0073343558712665735
1.53125 3200 0.985 0.177486 1.66494 0.106602 0.1 0.007261374180074655
1.53125 3300 0.9164 0.16905 1.66519 0.10152 0.1 0.007189118704973517
1.53125 3400 0.9558 0.143235 1.66391 0.0860833 0.1 0.007117582219632801
1.53125 3500 0.8248 0.244035 1.66585 0.146492 0.1 0.007046757569628924
1.53125 3600 0.855 0.254547 1.66224 0.153135 0.1 0.00697663767172953
1.53125 3700 0.95 0.180233 1.65924 0.108624 0.1 0.006907215513185129
1.53125 3800 0.9792 0.196606 1.66198 0.118296 0.1 0.00683848415102772
1.53125 3900 0.9488 0.210102 1.65897 0.126646 0.1 0.006770436711376421
1.53125 4000 0.9358 0.145007 1.65859 0.0874281 0.1 0.006703066388750011
1.53125 4100 0.9358 0.161304 1.65642 0.0973809 0.1 0.006636366445386311
1.53125 4200 0.9378 0.1404 1.65747 0.0847076 0.1 0.006570330210568327
1.53125 4300 0.9266 0.189067 1.65754 0.114065 0.1 0.006504951079957117
1.53125 4400 0.9258 0.200562 1.65844 0.120934 0.1 0.006440222514931274
1.53125 4500 0.984 0.150573 1.65455 0.0910051 0.1 0.006376138041932989
# Train result: 1.53125 0.982671
# Test result: 1.53125 0.9826
# 45361 entries between 1.4375 and 1.6875
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
1.5625 100 0.808 0.676334 3.03368 0.222942 0.1 0.009900493386913728
1.5625 200 0.9892 0.617515 2.55511 0.241678 0.1 0.009801976930432239
1.5625 300 0.937 0.489891 2.29269 0.213675 0.1 0.00970444077784252
1.5625 400 0.9232 0.332416 2.20203 0.150959 0.1 0.009607875174472565
1.5625 500 0.9778 0.279495 2.15858 0.129481 0.1 0.009512270462715812
1.5625 600 0.996 0.228661 2.1187 0.107925 0.1 0.009417617081065264
1.5625 700 0.9832 0.210469 2.07409 0.101475 0.1 0.009323905563157238
1.5625 800 0.9872 0.185383 2.02113 0.0917226 0.1 0.009231126536824622
1.5625 900 0.9646 0.185038 1.96706 0.0940683 0.1 0.009139270723159591
1.5625 1000 0.9608 0.140824 1.91303 0.0736131 0.1 0.009048328935585565
1.5625 1100 0.965 0.190981 1.86392 0.102462 0.1 0.008958292078938489
1.5625 1200 0.9362 0.218373 1.81955 0.120015 0.1 0.0088691511485572
1.5625 1300 0.9684 0.173533 1.7803 0.0974738 0.1 0.008780897229382877
1.5625 1400 0.9702 0.157971 1.74498 0.0905289 0.1 0.008693521495067419
1.5625 1500 0.8992 0.22983 1.71445 0.134055 0.1 0.008607015207090722
1.5625 1600 0.982 0.166775 1.68814 0.0987921 0.1 0.008521369713886751
1.5625 1700 0.864 0.287713 1.66632 0.172664 0.1 0.008436576449978266
1.5625 1800 0.9116 0.198052 1.64627 0.120303 0.1 0.008352626935120183
1.5625 1900 0.848 0.258288 1.62986 0.158473 0.1 0.008269512773451476
1.5625 2000 0.9548 0.16665 1.61506 0.103185 0.1 0.008187225652655481
1.5625 2100 0.9878 0.165398 1.60442 0.103088 0.1 0.008105757343128598
1.5625 2200 0.9588 0.163265 1.59438 0.102401 0.1 0.008025099697157206
1.5625 2300 0.941 0.172064 1.58636 0.108465 0.1 0.007945244648102822
1.5625 2400 0.9832 0.146142 1.57785 0.092621 0.1 0.007866184209595362
1.5625 2500 0.9862 0.170239 1.57298 0.108227 0.1 0.007787910474734398
1.5625 2600 0.9582 0.138444 1.5679 0.0882988 0.1 0.007710415615298401
1.5625 2700 0.9242 0.177952 1.56338 0.113825 0.1 0.0076336918809618085
1.5625 2800 0.9736 0.131228 1.55893 0.0841784 0.1 0.007557731598519933
1.5625 2900 0.8448 0.294709 1.55686 0.189298 0.1 0.007482527171121546
1.5625 3000 0.988 0.135404 1.55463 0.0870977 0.1 0.007408071077509108
1.5625 3100 0.9632 0.137433 1.55144 0.0885846 0.1 0.0073343558712665735
1.5625 3200 0.8908 0.188139 1.55003 0.121377 0.1 0.007261374180074655
1.5625 3300 0.9408 0.158261 1.54701 0.102301 0.1 0.007189118704973517
1.5625 3400 0.999 0.158713 1.54634 0.102638 0.1 0.007117582219632801
1.5625 3500 0.9872 0.162575 1.54543 0.105197 0.1 0.007046757569628924
1.5625 3600 0.9886 0.149911 1.54323 0.097141 0.1 0.00697663767172953
1.5625 3700 0.9768 0.135514 1.54145 0.0879129 0.1 0.006907215513185129
1.5625 3800 0.9984 0.189853 1.54099 0.123202 0.1 0.00683848415102772
1.5625 3900 0.8922 0.206061 1.54225 0.133611 0.1 0.006770436711376421
1.5625 4000 0.9822 0.125629 1.53998 0.0815783 0.1 0.006703066388750011
1.5625 4100 0.9642 0.157788 1.53892 0.102532 0.1 0.006636366445386311
1.5625 4200 0.9028 0.202419 1.53812 0.131601 0.1 0.006570330210568327
1.5625 4300 0.9498 0.177214 1.53658 0.11533 0.1 0.006504951079957117
1.5625 4400 0.9858 0.143765 1.53662 0.0935593 0.1 0.006440222514931274
1.5625 4500 0.9758 0.144517 1.53581 0.0940982 0.1 0.006376138041932989
# Train result: 1.5625 0.959845
# Test result: 1.5625 0.9629
# 45361 entries between 1.46875 and 1.71875
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
1.59375 100 0.8968 0.667711 3.04503 0.219279 0.1 0.009900493386913728
1.59375 200 0.966 0.581018 2.59257 0.224109 0.1 0.009801976930432239
1.59375 300 0.8924 0.421739 2.37871 0.177297 0.1 0.00970444077784252
1.59375 400 0.9136 0.329162 2.29435 0.143466 0.1 0.009607875174472565
1.59375 500 0.9342 0.246982 2.23069 0.11072 0.1 0.009512270462715812
1.59375 600 0.9316 0.222761 2.16183 0.103043 0.1 0.009417617081065264
1.59375 700 0.968 0.193446 2.09031 0.0925441 0.1 0.009323905563157238
1.59375 800 0.9446 0.218968 2.01424 0.10871 0.1 0.009231126536824622
1.59375 900 0.9096 0.178618 1.9412 0.0920142 0.1 0.009139270723159591
1.59375 1000 0.994 0.166461 1.87744 0.0886642 0.1 0.009048328935585565
1.59375 1100 0.9674 0.160433 1.82106 0.0880989 0.1 0.008958292078938489
1.59375 1200 0.9444 0.135388 1.76943 0.0765152 0.1 0.0088691511485572
1.59375 1300 0.9664 0.188931 1.72063 0.109803 0.1 0.008780897229382877
1.59375 1400 0.953 0.159532 1.68157 0.0948707 0.1 0.008693521495067419
1.59375 1500 0.9446 0.14928 1.64979 0.0904847 0.1 0.008607015207090722
1.59375 1600 0.9878 0.187532 1.62412 0.115467 0.1 0.008521369713886751
1.59375 1700 0.9846 0.170575 1.59701 0.106809 0.1 0.008436576449978266
1.59375 1800 0.9714 0.134083 1.57483 0.0851413 0.1 0.008352626935120183
1.59375 1900 0.9944 0.146524 1.56021 0.0939133 0.1 0.008269512773451476
1.59375 2000 0.9816 0.13513 1.54733 0.0873311 0.1 0.008187225652655481
1.59375 2100 0.978 0.130145 1.53613 0.0847228 0.1 0.008105757343128598
1.59375 2200 0.9946 0.140327 1.52127 0.0922435 0.1 0.008025099697157206
1.59375 2300 0.9544 0.177558 1.51305 0.11735 0.1 0.007945244648102822
1.59375 2400 0.9846 0.135796 1.50788 0.0900577 0.1 0.007866184209595362
1.59375 2500 0.9554 0.168613 1.50338 0.112156 0.1 0.007787910474734398
1.59375 2600 0.9962 0.123495 1.49678 0.0825068 0.1 0.007710415615298401
1.59375 2700 0.9768 0.160555 1.48991 0.107762 0.1 0.0076336918809618085
1.59375 2800 0.9568 0.162443 1.48809 0.109163 0.1 0.007557731598519933
1.59375 2900 0.9738 0.170106 1.48718 0.114381 0.1 0.007482527171121546
1.59375 3000 0.9728 0.133185 1.48489 0.0896932 0.1 0.007408071077509108
1.59375 3100 0.8404 0.284266 1.47943 0.192146 0.1 0.0073343558712665735
1.59375 3200 0.8882 0.241266 1.47736 0.163309 0.1 0.007261374180074655
1.59375 3300 1.0 0.155065 1.47646 0.105024 0.1 0.007189118704973517
1.59375 3400 0.9902 0.166663 1.47724 0.11282 0.1 0.007117582219632801
1.59375 3500 0.917 0.148824 1.47381 0.100979 0.1 0.007046757569628924
1.59375 3600 0.9784 0.162558 1.47032 0.110559 0.1 0.00697663767172953
1.59375 3700 0.977 0.164854 1.47091 0.112076 0.1 0.006907215513185129
1.59375 3800 0.929 0.170229 1.4722 0.115629 0.1 0.00683848415102772
1.59375 3900 0.9468 0.14401 1.47131 0.0978787 0.1 0.006770436711376421
1.59375 4000 0.9626 0.147604 1.46576 0.100702 0.1 0.006703066388750011
1.59375 4100 0.9364 0.158067 1.46709 0.107742 0.1 0.006636366445386311
1.59375 4200 0.9214 0.185981 1.4671 0.126768 0.1 0.006570330210568327
1.59375 4300 0.9966 0.172609 1.46871 0.117524 0.1 0.006504951079957117
1.59375 4400 0.96 0.13354 1.46636 0.0910694 0.1 0.006440222514931274
1.59375 4500 0.9762 0.149356 1.4627 0.10211 0.1 0.006376138041932989
# Train result: 1.59375 0.862848
# Test result: 1.59375 0.8591
# 45361 entries between 1.5 and 1.75
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
1.625 100 0.6614 0.656308 3.0227 0.217126 0.1 0.009900493386913728
1.625 200 0.9648 0.574976 2.58006 0.222853 0.1 0.009801976930432239
1.625 300 0.919 0.397313 2.37879 0.167023 0.1 0.00970444077784252
1.625 400 0.9862 0.311717 2.29518 0.135814 0.1 0.009607875174472565
1.625 500 0.8832 0.230682 2.22894 0.103494 0.1 0.009512270462715812
1.625 600 0.999 0.194288 2.1554 0.09014 0.1 0.009417617081065264
1.625 700 0.9912 0.190331 2.07459 0.0917438 0.1 0.009323905563157238
1.625 800 0.9884 0.16393 1.99694 0.0820903 0.1 0.009231126536824622
1.625 900 0.966 0.150866 1.92406 0.0784103 0.1 0.009139270723159591
1.625 1000 0.9876 0.1413 1.85949 0.0759884 0.1 0.009048328935585565
1.625 1100 0.9936 0.147016 1.79963 0.0816921 0.1 0.008958292078938489
1.625 1200 0.9688 0.146543 1.74376 0.0840383 0.1 0.0088691511485572
1.625 1300 0.9688 0.149222 1.69821 0.0878704 0.1 0.008780897229382877
1.625 1400 0.9674 0.148164 1.6599 0.0892608 0.1 0.008693521495067419
1.625 1500 0.9586 0.178778 1.62842 0.109787 0.1 0.008607015207090722
1.625 1600 0.9936 0.154404 1.59717 0.0966733 0.1 0.008521369713886751
1.625 1700 0.988 0.191923 1.57149 0.122128 0.1 0.008436576449978266
1.625 1800 0.9668 0.159689 1.5503 0.103006 0.1 0.008352626935120183
1.625 1900 0.9604 0.155759 1.53475 0.101488 0.1 0.008269512773451476
1.625 2000 0.9148 0.173183 1.52208 0.11378 0.1 0.008187225652655481
1.625 2100 0.9934 0.158097 1.50629 0.104958 0.1 0.008105757343128598
1.625 2200 0.9922 0.140541 1.49623 0.0939298 0.1 0.008025099697157206
1.625 2300 0.9932 0.133381 1.48819 0.0896261 0.1 0.007945244648102822
1.625 2400 0.9534 0.152899 1.48321 0.103086 0.1 0.007866184209595362
1.625 2500 0.9394 0.173523 1.47466 0.117669 0.1 0.007787910474734398
1.625 2600 0.9788 0.121257 1.46764 0.0826207 0.1 0.007710415615298401
1.625 2700 0.9688 0.160702 1.46173 0.109939 0.1 0.0076336918809618085
1.625 2800 0.9924 0.161748 1.46039 0.110757 0.1 0.007557731598519933
1.625 2900 0.9804 0.125766 1.45922 0.0861871 0.1 0.007482527171121546
1.625 3000 0.9706 0.128041 1.45338 0.0880985 0.1 0.007408071077509108
1.625 3100 0.9678 0.12761 1.45133 0.0879263 0.1 0.0073343558712665735
1.625 3200 0.9818 0.152295 1.44958 0.105061 0.1 0.007261374180074655
1.625 3300 0.9468 0.133375 1.4504 0.0919571 0.1 0.007189118704973517
1.625 3400 0.9482 0.16132 1.44662 0.111515 0.1 0.007117582219632801
1.625 3500 0.9604 0.131359 1.44341 0.0910061 0.1 0.007046757569628924
1.625 3600 0.988 0.13666 1.44089 0.0948444 0.1 0.00697663767172953
1.625 3700 0.979 0.125705 1.44122 0.0872213 0.1 0.006907215513185129
1.625 3800 0.9228 0.174586 1.44292 0.120995 0.1 0.00683848415102772
1.625 3900 0.967 0.152837 1.43946 0.106177 0.1 0.006770436711376421
1.625 4000 0.9964 0.159391 1.43852 0.110802 0.1 0.006703066388750011
1.625 4100 0.9464 0.170974 1.43808 0.11889 0.1 0.006636366445386311
1.625 4200 0.9946 0.153959 1.4401 0.106909 0.1 0.006570330210568327
1.625 4300 0.9806 0.141288 1.43773 0.0982719 0.1 0.006504951079957117
1.625 4400 0.9988 0.130708 1.43482 0.0910968 0.1 0.006440222514931274
1.625 4500 0.9918 0.141494 1.43341 0.0987118 0.1 0.006376138041932989
# Train result: 1.625 0.995011
# Test result: 1.625 0.9947
# 45361 entries between 1.53125 and 1.78125
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
1.65625 100 0.812 0.652182 3.03215 0.215089 0.1 0.009900493386913728
1.65625 200 0.943 0.524235 2.62546 0.199673 0.1 0.009801976930432239
1.65625 300 0.995 0.355365 2.44798 0.145167 0.1 0.00970444077784252
1.65625 400 0.9916 0.28548 2.35485 0.12123 0.1 0.009607875174472565
1.65625 500 0.9808 0.241226 2.26695 0.10641 0.1 0.009512270462715812
1.65625 600 0.978 0.17065 2.17663 0.0784011 0.1 0.009417617081065264
1.65625 700 0.9688 0.169593 2.08446 0.0813604 0.1 0.009323905563157238
1.65625 800 0.981 0.188989 1.99346 0.0948046 0.1 0.009231126536824622
1.65625 900 0.97 0.169484 1.91073 0.0887013 0.1 0.009139270723159591
1.65625 1000 0.9666 0.150377 1.83864 0.081787 0.1 0.009048328935585565
1.65625 1100 0.97 0.156063 1.77506 0.0879198 0.1 0.008958292078938489
1.65625 1200 0.9638 0.136456 1.72004 0.0793334 0.1 0.0088691511485572
1.65625 1300 0.983 0.125477 1.66957 0.0751551 0.1 0.008780897229382877
1.65625 1400 0.9522 0.172398 1.62841 0.105869 0.1 0.008693521495067419
1.65625 1500 0.9876 0.1243 1.59545 0.077909 0.1 0.008607015207090722
1.65625 1600 0.9996 0.125198 1.5663 0.079932 0.1 0.008521369713886751
1.65625 1700 0.9668 0.139578 1.53973 0.0906511 0.1 0.008436576449978266
1.65625 1800 0.9744 0.12652 1.5172 0.0833904 0.1 0.008352626935120183
1.65625 1900 0.9804 0.147177 1.50059 0.0980792 0.1 0.008269512773451476
1.65625 2000 0.9878 0.129326 1.48667 0.0869908 0.1 0.008187225652655481
1.65625 2100 0.9942 0.13595 1.47479 0.092183 0.1 0.008105757343128598
1.65625 2200 0.9944 0.163003 1.46349 0.11138 0.1 0.008025099697157206
1.65625 2300 0.9948 0.115268 1.45335 0.0793118 0.1 0.007945244648102822
1.65625 2400 0.993 0.151087 1.44799 0.104342 0.1 0.007866184209595362
1.65625 2500 0.9916 0.159023 1.44311 0.110195 0.1 0.007787910474734398
1.65625 2600 0.9928 0.137664 1.4356 0.0958929 0.1 0.007710415615298401
1.65625 2700 0.9818 0.0985494 1.43042 0.0688955 0.1 0.0076336918809618085
1.65625 2800 0.9878 0.152369 1.42775 0.10672 0.1 0.007557731598519933
1.65625 2900 0.9814 0.165276 1.4247 0.116007 0.1 0.007482527171121546
1.65625 3000 0.968 0.134479 1.42334 0.0944815 0.1 0.007408071077509108
1.65625 3100 0.9982 0.126676 1.42007 0.0892043 0.1 0.0073343558712665735
1.65625 3200 0.9452 0.105987 1.41714 0.0747897 0.1 0.007261374180074655
1.65625 3300 0.9906 0.122283 1.41684 0.0863069 0.1 0.007189118704973517
1.65625 3400 0.939 0.143754 1.41581 0.101535 0.1 0.007117582219632801
1.65625 3500 0.9986 0.168442 1.41255 0.119246 0.1 0.007046757569628924
1.65625 3600 0.9906 0.110118 1.41105 0.0780401 0.1 0.00697663767172953
1.65625 3700 0.9878 0.161675 1.41055 0.114618 0.1 0.006907215513185129
1.65625 3800 0.9716 0.108491 1.4105 0.0769167 0.1 0.00683848415102772
1.65625 3900 0.9916 0.141457 1.4105 0.100289 0.1 0.006770436711376421
1.65625 4000 0.976 0.157592 1.40945 0.111811 0.1 0.006703066388750011
1.65625 4100 0.9692 0.15384 1.40671 0.109361 0.1 0.006636366445386311
1.65625 4200 0.96 0.151305 1.40777 0.107479 0.1 0.006570330210568327
1.65625 4300 0.9662 0.148009 1.40763 0.105147 0.1 0.006504951079957117
1.65625 4400 0.9606 0.154303 1.40512 0.109815 0.1 0.006440222514931274
1.65625 4500 0.9838 0.159981 1.40493 0.113871 0.1 0.006376138041932989
# Train result: 1.65625 0.99819
# Test result: 1.65625 0.9976
# 45361 entries between 1.5625 and 1.8125
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
1.6875 100 0.8106 0.641058 3.00758 0.213147 0.1 0.009900493386913728
1.6875 200 0.9726 0.494473 2.6344 0.187698 0.1 0.009801976930432239
1.6875 300 0.9444 0.331617 2.47946 0.133745 0.1 0.00970444077784252
1.6875 400 0.9658 0.252779 2.37843 0.10628 0.1 0.009607875174472565
1.6875 500 0.9722 0.225411 2.27817 0.0989437 0.1 0.009512270462715812
1.6875 600 0.9564 0.169166 2.17422 0.0778053 0.1 0.009417617081065264
1.6875 700 0.9842 0.16518 2.07427 0.0796325 0.1 0.009323905563157238
1.6875 800 0.9874 0.163362 1.97638 0.082657 0.1 0.009231126536824622
1.6875 900 0.9624 0.159057 1.88805 0.0842443 0.1 0.009139270723159591
1.6875 1000 0.973 0.155413 1.81042 0.0858437 0.1 0.009048328935585565
1.6875 1100 0.9784 0.150538 1.74601 0.0862187 0.1 0.008958292078938489
1.6875 1200 0.9994 0.135148 1.68789 0.080069 0.1 0.0088691511485572
1.6875 1300 0.9848 0.130224 1.63678 0.079561 0.1 0.008780897229382877
1.6875 1400 0.9548 0.149944 1.59317 0.0941171 0.1 0.008693521495067419
1.6875 1500 0.9926 0.145264 1.55958 0.0931426 0.1 0.008607015207090722
1.6875 1600 0.9784 0.147333 1.53161 0.0961952 0.1 0.008521369713886751
1.6875 1700 0.961 0.150895 1.50469 0.100283 0.1 0.008436576449978266
1.6875 1800 0.999 0.151837 1.48144 0.102493 0.1 0.008352626935120183
1.6875 1900 0.9964 0.133849 1.46334 0.0914683 0.1 0.008269512773451476
1.6875 2000 0.983 0.128661 1.45077 0.0886844 0.1 0.008187225652655481
1.6875 2100 0.9976 0.119697 1.43856 0.0832059 0.1 0.008105757343128598
1.6875 2200 0.981 0.152322 1.42693 0.106748 0.1 0.008025099697157206
1.6875 2300 0.9862 0.119991 1.4164 0.0847152 0.1 0.007945244648102822
1.6875 2400 0.991 0.133346 1.41161 0.0944641 0.1 0.007866184209595362
1.6875 2500 0.9798 0.137672 1.40717 0.0978358 0.1 0.007787910474734398
1.6875 2600 0.9786 0.128733 1.40069 0.0919064 0.1 0.007710415615298401
1.6875 2700 0.98 0.150346 1.39417 0.107839 0.1 0.0076336918809618085
1.6875 2800 0.9766 0.157909 1.38954 0.113641 0.1 0.007557731598519933
1.6875 2900 0.9858 0.136302 1.38888 0.0981378 0.1 0.007482527171121546
1.6875 3000 0.9558 0.126596 1.3869 0.0912795 0.1 0.007408071077509108
1.6875 3100 0.9816 0.124348 1.38326 0.0898947 0.1 0.0073343558712665735
1.6875 3200 0.9964 0.154304 1.37962 0.111845 0.1 0.007261374180074655
1.6875 3300 0.9908 0.146061 1.38014 0.10583 0.1 0.007189118704973517
1.6875 3400 0.9944 0.122325 1.38013 0.0886329 0.1 0.007117582219632801
1.6875 3500 0.9966 0.115843 1.37862 0.0840283 0.1 0.007046757569628924
1.6875 3600 0.9846 0.134461 1.375 0.0977901 0.1 0.00697663767172953
1.6875 3700 0.96 0.14989 1.37346 0.109133 0.1 0.006907215513185129
1.6875 3800 0.9338 0.177728 1.37432 0.12932 0.1 0.00683848415102772
1.6875 3900 0.9908 0.153763 1.37359 0.111942 0.1 0.006770436711376421
1.6875 4000 0.9726 0.132463 1.37254 0.0965095 0.1 0.006703066388750011
1.6875 4100 0.9476 0.128197 1.37012 0.0935661 0.1 0.006636366445386311
1.6875 4200 0.9964 0.1449 1.37087 0.105699 0.1 0.006570330210568327
1.6875 4300 0.991 0.111675 1.37201 0.081395 0.1 0.006504951079957117
1.6875 4400 0.9964 0.11254 1.3714 0.0820618 0.1 0.006440222514931274
1.6875 4500 0.9874 0.163312 1.36842 0.119343 0.1 0.006376138041932989
# Train result: 1.6875 0.974261
# Test result: 1.6875 0.9729
# 45361 entries between 1.59375 and 1.84375
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
1.71875 100 0.9296 0.64876 3.01345 0.215288 0.1 0.009900493386913728
1.71875 200 0.9982 0.47171 2.64241 0.178515 0.1 0.009801976930432239
1.71875 300 0.9814 0.304497 2.48726 0.122423 0.1 0.00970444077784252
1.71875 400 0.9858 0.221707 2.38012 0.0931493 0.1 0.009607875174472565
1.71875 500 0.9782 0.177269 2.27075 0.0780664 0.1 0.009512270462715812
1.71875 600 0.9984 0.160441 2.15802 0.0743463 0.1 0.009417617081065264
1.71875 700 0.9868 0.154042 2.04908 0.0751764 0.1 0.009323905563157238
1.71875 800 0.9936 0.138215 1.94878 0.0709237 0.1 0.009231126536824622
1.71875 900 0.9838 0.14789 1.85675 0.0796497 0.1 0.009139270723159591
1.71875 1000 0.9894 0.116979 1.77924 0.0657465 0.1 0.009048328935585565
1.71875 1100 0.991 0.116591 1.70834 0.0682479 0.1 0.008958292078938489
1.71875 1200 0.9772 0.127447 1.65155 0.0771682 0.1 0.0088691511485572
1.71875 1300 0.9962 0.126068 1.59869 0.0788574 0.1 0.008780897229382877
1.71875 1400 0.9878 0.150495 1.55663 0.0966803 0.1 0.008693521495067419
1.71875 1500 0.9946 0.132655 1.52044 0.087248 0.1 0.008607015207090722
1.71875 1600 0.9834 0.129899 1.49064 0.0871434 0.1 0.008521369713886751
1.71875 1700 0.9948 0.154116 1.46533 0.105174 0.1 0.008436576449978266
1.71875 1800 0.9954 0.123068 1.44182 0.0853559 0.1 0.008352626935120183
1.71875 1900 0.988 0.141101 1.4257 0.0989695 0.1 0.008269512773451476
1.71875 2000 0.9688 0.144375 1.40888 0.102475 0.1 0.008187225652655481
1.71875 2100 0.9908 0.107932 1.39909 0.0771446 0.1 0.008105757343128598
1.71875 2200 0.9876 0.132429 1.38579 0.0955618 0.1 0.008025099697157206
1.71875 2300 0.9696 0.144217 1.37754 0.104691 0.1 0.007945244648102822
1.71875 2400 0.9906 0.13041 1.3701 0.0951827 0.1 0.007866184209595362
1.71875 2500 0.961 0.105541 1.36515 0.077311 0.1 0.007787910474734398
1.71875 2600 0.9634 0.0953124 1.36054 0.0700551 0.1 0.007710415615298401
1.71875 2700 0.9936 0.127236 1.35318 0.0940274 0.1 0.0076336918809618085
1.71875 2800 0.9936 0.141991 1.35158 0.105056 0.1 0.007557731598519933
1.71875 2900 0.987 0.126332 1.3474 0.0937599 0.1 0.007482527171121546
1.71875 3000 0.9878 0.11382 1.34661 0.0845236 0.1 0.007408071077509108
1.71875 3100 0.9942 0.131326 1.3421 0.097851 0.1 0.0073343558712665735
1.71875 3200 0.9618 0.106767 1.34036 0.0796559 0.1 0.007261374180074655
1.71875 3300 0.9848 0.103039 1.33826 0.0769943 0.1 0.007189118704973517
1.71875 3400 0.972 0.134511 1.33734 0.100581 0.1 0.007117582219632801
1.71875 3500 0.9904 0.127448 1.33626 0.0953766 0.1 0.007046757569628924
1.71875 3600 0.9944 0.133021 1.33301 0.0997905 0.1 0.00697663767172953
1.71875 3700 0.9776 0.104407 1.33402 0.0782652 0.1 0.006907215513185129
1.71875 3800 0.9734 0.123684 1.33198 0.092857 0.1 0.00683848415102772
1.71875 3900 0.9838 0.128749 1.33328 0.096565 0.1 0.006770436711376421
1.71875 4000 0.9942 0.153553 1.33019 0.115437 0.1 0.006703066388750011
1.71875 4100 0.9722 0.145717 1.32894 0.10965 0.1 0.006636366445386311
1.71875 4200 0.9996 0.104078 1.32934 0.0782931 0.1 0.006570330210568327
1.71875 4300 0.9972 0.136265 1.32884 0.102544 0.1 0.006504951079957117
1.71875 4400 0.9972 0.12535 1.32866 0.0943436 0.1 0.006440222514931274
1.71875 4500 0.9982 0.119678 1.32582 0.0902675 0.1 0.006376138041932989
# Train result: 1.71875 0.991678
# Test result: 1.71875 0.9918
# 45361 entries between 1.625 and 1.875
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
1.75 100 0.9064 0.623085 3.03253 0.205467 0.1 0.009900493386913728
1.75 200 0.9936 0.432642 2.69181 0.160725 0.1 0.009801976930432239
1.75 300 0.9738 0.30001 2.5399 0.118119 0.1 0.00970444077784252
1.75 400 0.9944 0.203549 2.4161 0.0842472 0.1 0.009607875174472565
1.75 500 0.9954 0.203427 2.2879 0.0889145 0.1 0.009512270462715812
1.75 600 0.9912 0.151069 2.16143 0.0698931 0.1 0.009417617081065264
1.75 700 0.9974 0.150312 2.04314 0.0735694 0.1 0.009323905563157238
1.75 800 0.9996 0.165923 1.93718 0.0856517 0.1 0.009231126536824622
1.75 900 0.9628 0.115885 1.84041 0.0629671 0.1 0.009139270723159591
1.75 1000 0.9966 0.135821 1.75426 0.0774239 0.1 0.009048328935585565
1.75 1100 0.9938 0.121346 1.68285 0.0721077 0.1 0.008958292078938489
1.75 1200 0.994 0.155932 1.62193 0.0961395 0.1 0.0088691511485572
1.75 1300 0.9832 0.138527 1.57129 0.0881613 0.1 0.008780897229382877
1.75 1400 0.979 0.103739 1.52579 0.06799 0.1 0.008693521495067419
1.75 1500 0.9936 0.120848 1.48728 0.0812544 0.1 0.008607015207090722
1.75 1600 0.9866 0.15126 1.45508 0.103953 0.1 0.008521369713886751
1.75 1700 0.9804 0.127333 1.43158 0.0889463 0.1 0.008436576449978266
1.75 1800 0.9854 0.126691 1.40778 0.0899941 0.1 0.008352626935120183
1.75 1900 0.981 0.117733 1.38723 0.0848692 0.1 0.008269512773451476
1.75 2000 0.9862 0.0852806 1.37217 0.0621501 0.1 0.008187225652655481
1.75 2100 0.9998 0.141768 1.35974 0.104261 0.1 0.008105757343128598
1.75 2200 0.981 0.102235 1.35059 0.0756961 0.1 0.008025099697157206
1.75 2300 0.995 0.123646 1.34104 0.0922016 0.1 0.007945244648102822
1.75 2400 0.9964 0.163382 1.33179 0.122679 0.1 0.007866184209595362
1.75 2500 0.9998 0.109481 1.32436 0.0826677 0.1 0.007787910474734398
1.75 2600 0.9924 0.120209 1.32196 0.0909321 0.1 0.007710415615298401
1.75 2700 0.9906 0.118582 1.31566 0.0901317 0.1 0.0076336918809618085
1.75 2800 0.9522 0.0890964 1.3103 0.067997 0.1 0.007557731598519933
1.75 2900 0.9712 0.103627 1.30741 0.0792615 0.1 0.007482527171121546
1.75 3000 0.9702 0.125381 1.30476 0.0960952 0.1 0.007408071077509108
1.75 3100 0.9974 0.137016 1.30418 0.10506 0.1 0.0073343558712665735
1.75 3200 0.9896 0.130657 1.30094 0.100433 0.1 0.007261374180074655
1.75 3300 0.9956 0.115849 1.29711 0.0893133 0.1 0.007189118704973517
1.75 3400 0.9912 0.134724 1.2949 0.104042 0.1 0.007117582219632801
1.75 3500 0.9964 0.101881 1.29558 0.0786377 0.1 0.007046757569628924
1.75 3600 0.9978 0.115817 1.29383 0.0895148 0.1 0.00697663767172953
1.75 3700 0.9618 0.144346 1.29146 0.111769 0.1 0.006907215513185129
1.75 3800 0.9998 0.134459 1.29115 0.104139 0.1 0.00683848415102772
1.75 3900 0.9824 0.160411 1.28951 0.124396 0.1 0.006770436711376421
1.75 4000 0.9782 0.119586 1.29163 0.0925855 0.1 0.006703066388750011
1.75 4100 0.9998 0.127304 1.28923 0.0987445 0.1 0.006636366445386311
1.75 4200 0.9924 0.112629 1.28645 0.08755 0.1 0.006570330210568327
1.75 4300 0.9972 0.122924 1.28609 0.0955789 0.1 0.006504951079957117
1.75 4400 0.9974 0.142374 1.28681 0.110641 0.1 0.006440222514931274
1.75 4500 0.9954 0.137235 1.28646 0.106677 0.1 0.006376138041932989
# Train result: 1.75 0.994481
# Test result: 1.75 0.9938
# 45361 entries between 1.65625 and 1.90625
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
1.78125 100 0.934 0.603927 3.02829 0.199428 0.1 0.009900493386913728
1.78125 200 1.0 0.390637 2.7288 0.143154 0.1 0.009801976930432239
1.78125 300 0.9698 0.249246 2.57863 0.0966583 0.1 0.00970444077784252
1.78125 400 0.9998 0.178338 2.43212 0.0733261 0.1 0.009607875174472565
1.78125 500 0.987 0.154204 2.28188 0.0675775 0.1 0.009512270462715812
1.78125 600 0.9946 0.144338 2.13828 0.0675017 0.1 0.009417617081065264
1.78125 700 0.9936 0.124116 2.00875 0.0617875 0.1 0.009323905563157238
1.78125 800 0.9672 0.0864928 1.89239 0.0457057 0.1 0.009231126536824622
1.78125 900 0.995 0.134423 1.78997 0.0750982 0.1 0.009139270723159591
1.78125 1000 0.9948 0.127937 1.70106 0.0752103 0.1 0.009048328935585565
1.78125 1100 0.987 0.142005 1.62699 0.0872807 0.1 0.008958292078938489
1.78125 1200 0.9852 0.142753 1.56469 0.0912338 0.1 0.0088691511485572
1.78125 1300 0.9884 0.123461 1.51113 0.0817007 0.1 0.008780897229382877
1.78125 1400 0.9844 0.106793 1.46613 0.0728402 0.1 0.008693521495067419
1.78125 1500 0.981 0.115102 1.42738 0.0806385 0.1 0.008607015207090722
1.78125 1600 0.9966 0.126953 1.39759 0.0908369 0.1 0.008521369713886751
1.78125 1700 0.996 0.12402 1.37164 0.0904174 0.1 0.008436576449978266
1.78125 1800 1.0 0.121348 1.34985 0.0898974 0.1 0.008352626935120183
1.78125 1900 0.9854 0.102006 1.33001 0.0766954 0.1 0.008269512773451476
1.78125 2000 0.998 0.118296 1.31599 0.0898916 0.1 0.008187225652655481
1.78125 2100 0.998 0.121514 1.30389 0.0931941 0.1 0.008105757343128598
1.78125 2200 0.9902 0.115162 1.29372 0.0890163 0.1 0.008025099697157206
1.78125 2300 0.9834 0.123557 1.28494 0.0961583 0.1 0.007945244648102822
1.78125 2400 0.998 0.117678 1.27623 0.0922076 0.1 0.007866184209595362
1.78125 2500 0.9966 0.139655 1.2717 0.109817 0.1 0.007787910474734398
1.78125 2600 0.9944 0.109269 1.26717 0.0862312 0.1 0.007710415615298401
1.78125 2700 0.9814 0.121034 1.26216 0.0958942 0.1 0.0076336918809618085
1.78125 2800 0.9966 0.108983 1.25774 0.0866502 0.1 0.007557731598519933
1.78125 2900 0.9902 0.121391 1.25525 0.0967064 0.1 0.007482527171121546
1.78125 3000 0.9998 0.108218 1.25345 0.086336 0.1 0.007408071077509108
1.78125 3100 0.9944 0.113736 1.2511 0.0909084 0.1 0.0073343558712665735
1.78125 3200 0.9842 0.124725 1.24899 0.0998608 0.1 0.007261374180074655
1.78125 3300 0.9874 0.0998698 1.24591 0.080158 0.1 0.007189118704973517
1.78125 3400 0.998 0.14534 1.24659 0.11659 0.1 0.007117582219632801
1.78125 3500 0.994 0.130263 1.24571 0.104569 0.1 0.007046757569628924
1.78125 3600 0.9892 0.11925 1.24415 0.0958481 0.1 0.00697663767172953
1.78125 3700 0.981 0.118886 1.2428 0.09566 0.1 0.006907215513185129
1.78125 3800 0.9826 0.109353 1.24159 0.088075 0.1 0.00683848415102772
1.78125 3900 0.9974 0.105667 1.24186 0.0850876 0.1 0.006770436711376421
1.78125 4000 0.9942 0.135181 1.24129 0.108904 0.1 0.006703066388750011
1.78125 4100 0.9824 0.114464 1.24016 0.0922979 0.1 0.006636366445386311
1.78125 4200 0.9904 0.122983 1.23877 0.0992789 0.1 0.006570330210568327
1.78125 4300 0.9946 0.113805 1.23907 0.0918466 0.1 0.006504951079957117
1.78125 4400 0.9962 0.0906596 1.23958 0.0731374 0.1 0.006440222514931274
1.78125 4500 0.998 0.108811 1.23831 0.0878703 0.1 0.006376138041932989
# Train result: 1.78125 0.987881
# Test result: 1.78125 0.9868
# 45361 entries between 1.6875 and 1.9375
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
1.8125 100 0.9586 0.563092 3.06062 0.18398 0.1 0.009900493386913728
1.8125 200 0.9914 0.348511 2.78922 0.124949 0.1 0.009801976930432239
1.8125 300 0.991 0.240591 2.61986 0.0918337 0.1 0.00970444077784252
1.8125 400 0.983 0.183264 2.45197 0.0747414 0.1 0.009607875174472565
1.8125 500 0.9938 0.146794 2.28885 0.0641343 0.1 0.009512270462715812
1.8125 600 0.9908 0.130271 2.13367 0.0610552 0.1 0.009417617081065264
1.8125 700 0.9918 0.134177 1.99722 0.0671819 0.1 0.009323905563157238
1.8125 800 0.9928 0.128902 1.87469 0.0687592 0.1 0.009231126536824622
1.8125 900 0.9988 0.127618 1.77001 0.0720998 0.1 0.009139270723159591
1.8125 1000 0.9934 0.141242 1.68031 0.0840572 0.1 0.009048328935585565
1.8125 1100 0.9902 0.12283 1.6027 0.076639 0.1 0.008958292078938489
1.8125 1200 0.9958 0.109593 1.53781 0.0712657 0.1 0.0088691511485572
1.8125 1300 0.9998 0.0986027 1.48178 0.0665434 0.1 0.008780897229382877
1.8125 1400 0.9974 0.114073 1.43735 0.0793631 0.1 0.008693521495067419
1.8125 1500 0.9926 0.115199 1.3971 0.0824557 0.1 0.008607015207090722
1.8125 1600 0.9928 0.0954954 1.36727 0.0698438 0.1 0.008521369713886751
1.8125 1700 0.9998 0.131009 1.33928 0.0978206 0.1 0.008436576449978266
1.8125 1800 0.9962 0.0952028 1.31713 0.0722805 0.1 0.008352626935120183
1.8125 1900 0.9936 0.113497 1.29942 0.0873446 0.1 0.008269512773451476
1.8125 2000 0.9978 0.0996363 1.28289 0.0776654 0.1 0.008187225652655481
1.8125 2100 0.9978 0.131095 1.26945 0.10327 0.1 0.008105757343128598
1.8125 2200 0.9968 0.103602 1.25742 0.0823924 0.1 0.008025099697157206
1.8125 2300 0.9998 0.123982 1.2496 0.099217 0.1 0.007945244648102822
1.8125 2400 0.99 0.126657 1.2406 0.102093 0.1 0.007866184209595362
1.8125 2500 0.9996 0.126237 1.23606 0.102129 0.1 0.007787910474734398
1.8125 2600 0.9916 0.110506 1.2287 0.0899374 0.1 0.007710415615298401
1.8125 2700 0.9792 0.107796 1.22436 0.0880421 0.1 0.0076336918809618085
1.8125 2800 0.99 0.0920669 1.22124 0.0753878 0.1 0.007557731598519933
1.8125 2900 0.9826 0.114344 1.21707 0.0939504 0.1 0.007482527171121546
1.8125 3000 0.996 0.134348 1.21352 0.11071 0.1 0.007408071077509108
1.8125 3100 0.9836 0.0920945 1.21064 0.0760708 0.1 0.0073343558712665735
1.8125 3200 0.99 0.105183 1.20946 0.0869668 0.1 0.007261374180074655
1.8125 3300 0.9916 0.132464 1.20711 0.109737 0.1 0.007189118704973517
1.8125 3400 0.999 0.116995 1.20609 0.0970037 0.1 0.007117582219632801
1.8125 3500 0.9902 0.120434 1.20312 0.100102 0.1 0.007046757569628924
1.8125 3600 0.9972 0.112067 1.20183 0.0932469 0.1 0.00697663767172953
1.8125 3700 0.9782 0.110107 1.20272 0.0915483 0.1 0.006907215513185129
1.8125 3800 0.9908 0.119411 1.20023 0.0994896 0.1 0.00683848415102772
1.8125 3900 0.9872 0.110772 1.19837 0.0924355 0.1 0.006770436711376421
1.8125 4000 0.9956 0.117965 1.19735 0.0985215 0.1 0.006703066388750011
1.8125 4100 0.9916 0.0923678 1.19787 0.0771099 0.1 0.006636366445386311
1.8125 4200 0.9998 0.157003 1.19656 0.131212 0.1 0.006570330210568327
1.8125 4300 0.9958 0.125338 1.19637 0.104765 0.1 0.006504951079957117
1.8125 4400 0.9918 0.122916 1.19459 0.102894 0.1 0.006440222514931274
1.8125 4500 0.9962 0.0854976 1.19355 0.0716328 0.1 0.006376138041932989
# Train result: 1.8125 0.989603
# Test result: 1.8125 0.9903
# 45361 entries between 1.71875 and 1.96875
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
1.84375 100 0.992 0.541968 3.04374 0.17806 0.1 0.009900493386913728
1.84375 200 0.9976 0.30645 2.78234 0.110141 0.1 0.009801976930432239
1.84375 300 0.9976 0.195625 2.60484 0.0751006 0.1 0.00970444077784252
1.84375 400 0.9984 0.177154 2.42698 0.0729936 0.1 0.009607875174472565
1.84375 500 0.9908 0.132184 2.2513 0.0587146 0.1 0.009512270462715812
1.84375 600 0.9862 0.0959133 2.09024 0.0458863 0.1 0.009417617081065264
1.84375 700 0.9968 0.10857 1.9479 0.0557369 0.1 0.009323905563157238
1.84375 800 0.9926 0.119512 1.82155 0.0656098 0.1 0.009231126536824622
1.84375 900 0.9878 0.104811 1.71397 0.061151 0.1 0.009139270723159591
1.84375 1000 0.9932 0.0990891 1.61977 0.0611748 0.1 0.009048328935585565
1.84375 1100 0.9922 0.106896 1.5443 0.0692195 0.1 0.008958292078938489
1.84375 1200 0.9978 0.108167 1.47725 0.073222 0.1 0.0088691511485572
1.84375 1300 0.995 0.0987114 1.42218 0.0694086 0.1 0.008780897229382877
1.84375 1400 0.9932 0.0864398 1.37323 0.0629465 0.1 0.008693521495067419
1.84375 1500 0.9922 0.100927 1.33519 0.0755896 0.1 0.008607015207090722
1.84375 1600 0.992 0.0958205 1.30494 0.0734289 0.1 0.008521369713886751
1.84375 1700 0.988 0.112715 1.27731 0.088244 0.1 0.008436576449978266
1.84375 1800 0.9848 0.117277 1.25582 0.0933868 0.1 0.008352626935120183
1.84375 1900 0.9946 0.119525 1.23552 0.0967402 0.1 0.008269512773451476
1.84375 2000 0.9958 0.153656 1.22225 0.125716 0.1 0.008187225652655481
1.84375 2100 0.997 0.106383 1.2084 0.0880366 0.1 0.008105757343128598
1.84375 2200 0.9962 0.118184 1.19786 0.0986624 0.1 0.008025099697157206
1.84375 2300 1.0 0.122691 1.18749 0.103319 0.1 0.007945244648102822
1.84375 2400 0.9834 0.102692 1.18018 0.087014 0.1 0.007866184209595362
1.84375 2500 0.9932 0.102928 1.17513 0.0875884 0.1 0.007787910474734398
1.84375 2600 0.9994 0.120933 1.1693 0.103424 0.1 0.007710415615298401
1.84375 2700 0.998 0.0921894 1.1653 0.0791123 0.1 0.0076336918809618085
1.84375 2800 0.9988 0.0996449 1.16027 0.085881 0.1 0.007557731598519933
1.84375 2900 0.9968 0.124997 1.15846 0.107899 0.1 0.007482527171121546
1.84375 3000 0.9996 0.105361 1.15564 0.0911712 0.1 0.007408071077509108
1.84375 3100 1.0 0.123648 1.15356 0.107188 0.1 0.0073343558712665735
1.84375 3200 0.989 0.0964235 1.15029 0.0838252 0.1 0.007261374180074655
1.84375 3300 0.9914 0.094223 1.14882 0.082017 0.1 0.007189118704973517
1.84375 3400 0.9984 0.109684 1.14817 0.0955293 0.1 0.007117582219632801
1.84375 3500 0.9958 0.0898888 1.14673 0.0783872 0.1 0.007046757569628924
1.84375 3600 0.9928 0.084115 1.14637 0.073375 0.1 0.00697663767172953
1.84375 3700 1.0 0.119358 1.14387 0.104346 0.1 0.006907215513185129
1.84375 3800 0.9952 0.0935266 1.14394 0.0817586 0.1 0.00683848415102772
1.84375 3900 0.9992 0.104604 1.14398 0.0914389 0.1 0.006770436711376421
1.84375 4000 0.998 0.120809 1.14249 0.105741 0.1 0.006703066388750011
1.84375 4100 0.995 0.116727 1.1411 0.102294 0.1 0.006636366445386311
1.84375 4200 0.9972 0.109879 1.14127 0.0962775 0.1 0.006570330210568327
1.84375 4300 0.9884 0.105125 1.14157 0.0920882 0.1 0.006504951079957117
1.84375 4400 0.9932 0.0747642 1.1407 0.0655425 0.1 0.006440222514931274
1.84375 4500 0.9946 0.0944225 1.14126 0.0827352 0.1 0.006376138041932989
# Train result: 1.84375 0.991391
# Test result: 1.84375 0.9918
# 45360 entries between 1.75 and 2.0
# nstep accuracy cross_entropy L2_loss c.e./L2 beta rLearn
1.875 100 0.9466 0.498309 3.0885 0.161344 0.1 0.009900493386913728
1.875 200 0.9984 0.270238 2.84332 0.0950432 0.1 0.009801976930432239
1.875 300 0.9894 0.162702 2.64269 0.0615667 0.1 0.00970444077784252
1.875 400 0.9914 0.149772 2.43936 0.0613979 0.1 0.009607875174472565
1.875 500 0.9868 0.112366 2.24622 0.0500246 0.1 0.009512270462715812
1.875 600 0.9982 0.121467 2.07268 0.058604 0.1 0.009417617081065264
1.875 700 0.9974 0.113177 1.92114 0.0589112 0.1 0.009323905563157238
1.875 800 0.9952 0.127508 1.78705 0.0713512 0.1 0.009231126536824622
1.875 900 0.9836 0.0896894 1.67379 0.0535848 0.1 0.009139270723159591
1.875 1000 0.9906 0.102405 1.57914 0.0648487 0.1 0.009048328935585565
1.875 1100 0.9964 0.0981244 1.4986 0.0654772 0.1 0.008958292078938489
1.875 1200 0.9974 0.134755 1.43086 0.0941781 0.1 0.0088691511485572
1.875 1300 0.999 0.0974258 1.37379 0.0709174 0.1 0.008780897229382877
1.875 1400 0.991 0.107113 1.32644 0.0807526 0.1 0.008693521495067419
1.875 1500 0.9952 0.105892 1.28735 0.0822563 0.1 0.008607015207090722
1.875 1600 1.0 0.0967458 1.25627 0.0770104 0.1 0.008521369713886751
1.875 1700 0.9922 0.094479 1.22784 0.0769471 0.1 0.008436576449978266
1.875 1800 0.9978 0.0885872 1.20459 0.0735416 0.1 0.008352626935120183
1.875 1900 0.998 0.0941812 1.18668 0.0793652 0.1 0.008269512773451476
1.875 2000 0.9952 0.0866723 1.17255 0.0739178 0.1 0.008187225652655481
1.875 2100 0.999 0.0981657 1.15872 0.084719 0.1 0.008105757343128598
1.875 2200 0.9932 0.096247 1.14688 0.0839207 0.1 0.008025099697157206
1.875 2300 0.999 0.0950036 1.13858 0.0834407 0.1 0.007945244648102822
1.875 2400 0.9968 0.10941 1.13093 0.0967433 0.1 0.007866184209595362
1.875 2500 0.9978 0.0853361 1.1266 0.0757464 0.1 0.007787910474734398
1.875 2600 0.9924 0.130046 1.12025 0.116086 0.1 0.007710415615298401
1.875 2700 0.9938 0.113784 1.11544 0.102008 0.1 0.0076336918809618085
1.875 2800 0.999 0.0993792 1.11184 0.0893825 0.1 0.007557731598519933
1.875 2900 0.9918 0.0977061 1.11018 0.0880093 0.1 0.007482527171121546
1.875 3000 0.999 0.0932182 1.10683 0.0842211 0.1 0.007408071077509108
1.875 3100 0.9978 0.0968407 1.10291 0.0878043 0.1 0.0073343558712665735
1.875 3200 0.9856 0.0836287 1.10165 0.0759119 0.1 0.007261374180074655
1.875 3300 0.9938 0.0979353 1.1003 0.0890076 0.1 0.007189118704973517
1.875 3400 0.9982 0.110776 1.10074 0.100638 0.1 0.007117582219632801
1.875 3500 0.992 0.100912 1.09766 0.0919335 0.1 0.007046757569628924
1.875 3600 0.9954 0.107073 1.09658 0.0976424 0.1 0.00697663767172953
1.875 3700 0.9966 0.0926181 1.09571 0.0845279 0.1 0.006907215513185129
1.875 3800 0.9974 0.102415 1.09543 0.0934928 0.1 0.00683848415102772
1.875 3900 0.9938 0.0876004 1.09534 0.0799754 0.1 0.006770436711376421
1.875 4000 0.9994 0.0868891 1.09247 0.0795348 0.1 0.006703066388750011
1.875 4100 0.9966 0.0996222 1.09244 0.0911921 0.1 0.006636366445386311
1.875 4200 0.9986 0.115903 1.09274 0.106066 0.1 0.006570330210568327
1.875 4300 0.991 0.100323 1.0938 0.0917197 0.1 0.006504951079957117
1.875 4400 0.99 0.0787017 1.09194 0.0720748 0.1 0.006440222514931274
1.875 4500 0.9924 0.105383 1.09155 0.0965448 0.1 0.006376138041932989
# Train result: 1.875 0.98936
# Test result: 1.875 0.9899
